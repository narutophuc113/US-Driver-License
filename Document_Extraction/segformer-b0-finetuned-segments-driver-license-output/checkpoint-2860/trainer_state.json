{
  "best_metric": 0.0009406174067407846,
  "best_model_checkpoint": "segformer-b0-finetuned-segments-driver-license-output\\checkpoint-2300",
  "epoch": 49.310344827586206,
  "eval_steps": 20,
  "global_step": 2860,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.017241379310344827,
      "grad_norm": 3.71669340133667,
      "learning_rate": 5.9979310344827585e-05,
      "loss": 0.6782,
      "step": 1
    },
    {
      "epoch": 0.034482758620689655,
      "grad_norm": 3.1591970920562744,
      "learning_rate": 5.9958620689655175e-05,
      "loss": 0.6418,
      "step": 2
    },
    {
      "epoch": 0.05172413793103448,
      "grad_norm": 3.095588207244873,
      "learning_rate": 5.993793103448276e-05,
      "loss": 0.5943,
      "step": 3
    },
    {
      "epoch": 0.06896551724137931,
      "grad_norm": 2.8534996509552,
      "learning_rate": 5.991724137931034e-05,
      "loss": 0.6517,
      "step": 4
    },
    {
      "epoch": 0.08620689655172414,
      "grad_norm": 4.737993240356445,
      "learning_rate": 5.989655172413794e-05,
      "loss": 0.5881,
      "step": 5
    },
    {
      "epoch": 0.10344827586206896,
      "grad_norm": 4.009639263153076,
      "learning_rate": 5.987586206896552e-05,
      "loss": 0.6476,
      "step": 6
    },
    {
      "epoch": 0.1206896551724138,
      "grad_norm": 3.582529306411743,
      "learning_rate": 5.9855172413793104e-05,
      "loss": 0.6117,
      "step": 7
    },
    {
      "epoch": 0.13793103448275862,
      "grad_norm": 3.1347124576568604,
      "learning_rate": 5.9834482758620694e-05,
      "loss": 0.6159,
      "step": 8
    },
    {
      "epoch": 0.15517241379310345,
      "grad_norm": 2.7253270149230957,
      "learning_rate": 5.981379310344828e-05,
      "loss": 0.5738,
      "step": 9
    },
    {
      "epoch": 0.1724137931034483,
      "grad_norm": 2.801370620727539,
      "learning_rate": 5.979310344827586e-05,
      "loss": 0.612,
      "step": 10
    },
    {
      "epoch": 0.1896551724137931,
      "grad_norm": 3.0042331218719482,
      "learning_rate": 5.977241379310345e-05,
      "loss": 0.4788,
      "step": 11
    },
    {
      "epoch": 0.20689655172413793,
      "grad_norm": 2.6728198528289795,
      "learning_rate": 5.975172413793103e-05,
      "loss": 0.5814,
      "step": 12
    },
    {
      "epoch": 0.22413793103448276,
      "grad_norm": 2.8238120079040527,
      "learning_rate": 5.973103448275862e-05,
      "loss": 0.4823,
      "step": 13
    },
    {
      "epoch": 0.2413793103448276,
      "grad_norm": 2.4993982315063477,
      "learning_rate": 5.9710344827586206e-05,
      "loss": 0.4943,
      "step": 14
    },
    {
      "epoch": 0.25862068965517243,
      "grad_norm": 3.064419746398926,
      "learning_rate": 5.9689655172413796e-05,
      "loss": 0.5347,
      "step": 15
    },
    {
      "epoch": 0.27586206896551724,
      "grad_norm": 2.4070773124694824,
      "learning_rate": 5.9668965517241386e-05,
      "loss": 0.4892,
      "step": 16
    },
    {
      "epoch": 0.29310344827586204,
      "grad_norm": 2.674672842025757,
      "learning_rate": 5.964827586206897e-05,
      "loss": 0.5235,
      "step": 17
    },
    {
      "epoch": 0.3103448275862069,
      "grad_norm": 2.9877891540527344,
      "learning_rate": 5.962758620689655e-05,
      "loss": 0.4239,
      "step": 18
    },
    {
      "epoch": 0.3275862068965517,
      "grad_norm": 2.5013015270233154,
      "learning_rate": 5.960689655172414e-05,
      "loss": 0.4487,
      "step": 19
    },
    {
      "epoch": 0.3448275862068966,
      "grad_norm": 2.957850933074951,
      "learning_rate": 5.9586206896551725e-05,
      "loss": 0.4763,
      "step": 20
    },
    {
      "epoch": 0.3448275862068966,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.6550407409667969,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.0838,
      "eval_samples_per_second": 3.192,
      "eval_steps_per_second": 1.651,
      "step": 20
    },
    {
      "epoch": 0.3620689655172414,
      "grad_norm": 3.14090895652771,
      "learning_rate": 5.956551724137931e-05,
      "loss": 0.5447,
      "step": 21
    },
    {
      "epoch": 0.3793103448275862,
      "grad_norm": 3.023175001144409,
      "learning_rate": 5.95448275862069e-05,
      "loss": 0.4827,
      "step": 22
    },
    {
      "epoch": 0.39655172413793105,
      "grad_norm": 2.4241786003112793,
      "learning_rate": 5.952413793103448e-05,
      "loss": 0.5204,
      "step": 23
    },
    {
      "epoch": 0.41379310344827586,
      "grad_norm": 2.5595743656158447,
      "learning_rate": 5.950344827586207e-05,
      "loss": 0.4463,
      "step": 24
    },
    {
      "epoch": 0.43103448275862066,
      "grad_norm": 3.7236781120300293,
      "learning_rate": 5.948275862068966e-05,
      "loss": 0.4818,
      "step": 25
    },
    {
      "epoch": 0.4482758620689655,
      "grad_norm": 3.406303882598877,
      "learning_rate": 5.9462068965517244e-05,
      "loss": 0.5769,
      "step": 26
    },
    {
      "epoch": 0.46551724137931033,
      "grad_norm": 2.254209041595459,
      "learning_rate": 5.944137931034483e-05,
      "loss": 0.3945,
      "step": 27
    },
    {
      "epoch": 0.4827586206896552,
      "grad_norm": 2.9410760402679443,
      "learning_rate": 5.942068965517242e-05,
      "loss": 0.4136,
      "step": 28
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.7887802124023438,
      "learning_rate": 5.94e-05,
      "loss": 0.4869,
      "step": 29
    },
    {
      "epoch": 0.5172413793103449,
      "grad_norm": 4.097235679626465,
      "learning_rate": 5.9379310344827584e-05,
      "loss": 0.4572,
      "step": 30
    },
    {
      "epoch": 0.5344827586206896,
      "grad_norm": 2.7908105850219727,
      "learning_rate": 5.9358620689655174e-05,
      "loss": 0.474,
      "step": 31
    },
    {
      "epoch": 0.5517241379310345,
      "grad_norm": 2.8145835399627686,
      "learning_rate": 5.933793103448276e-05,
      "loss": 0.4328,
      "step": 32
    },
    {
      "epoch": 0.5689655172413793,
      "grad_norm": 2.586517810821533,
      "learning_rate": 5.9317241379310347e-05,
      "loss": 0.414,
      "step": 33
    },
    {
      "epoch": 0.5862068965517241,
      "grad_norm": 2.6705563068389893,
      "learning_rate": 5.9296551724137936e-05,
      "loss": 0.4369,
      "step": 34
    },
    {
      "epoch": 0.603448275862069,
      "grad_norm": 2.7072501182556152,
      "learning_rate": 5.927586206896552e-05,
      "loss": 0.3813,
      "step": 35
    },
    {
      "epoch": 0.6206896551724138,
      "grad_norm": 2.1934409141540527,
      "learning_rate": 5.92551724137931e-05,
      "loss": 0.3874,
      "step": 36
    },
    {
      "epoch": 0.6379310344827587,
      "grad_norm": 2.383831262588501,
      "learning_rate": 5.923448275862069e-05,
      "loss": 0.4346,
      "step": 37
    },
    {
      "epoch": 0.6551724137931034,
      "grad_norm": 2.1799120903015137,
      "learning_rate": 5.9213793103448276e-05,
      "loss": 0.3905,
      "step": 38
    },
    {
      "epoch": 0.6724137931034483,
      "grad_norm": 2.1538267135620117,
      "learning_rate": 5.9193103448275866e-05,
      "loss": 0.3686,
      "step": 39
    },
    {
      "epoch": 0.6896551724137931,
      "grad_norm": 2.0700936317443848,
      "learning_rate": 5.917241379310345e-05,
      "loss": 0.3745,
      "step": 40
    },
    {
      "epoch": 0.6896551724137931,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.39902031421661377,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.5663,
      "eval_samples_per_second": 3.385,
      "eval_steps_per_second": 1.751,
      "step": 40
    },
    {
      "epoch": 0.7068965517241379,
      "grad_norm": 2.5799121856689453,
      "learning_rate": 5.915172413793103e-05,
      "loss": 0.402,
      "step": 41
    },
    {
      "epoch": 0.7241379310344828,
      "grad_norm": 2.228029251098633,
      "learning_rate": 5.913103448275862e-05,
      "loss": 0.3383,
      "step": 42
    },
    {
      "epoch": 0.7413793103448276,
      "grad_norm": 2.916969060897827,
      "learning_rate": 5.911034482758621e-05,
      "loss": 0.4031,
      "step": 43
    },
    {
      "epoch": 0.7586206896551724,
      "grad_norm": 2.1935923099517822,
      "learning_rate": 5.9089655172413795e-05,
      "loss": 0.3676,
      "step": 44
    },
    {
      "epoch": 0.7758620689655172,
      "grad_norm": 2.2225115299224854,
      "learning_rate": 5.9068965517241385e-05,
      "loss": 0.3102,
      "step": 45
    },
    {
      "epoch": 0.7931034482758621,
      "grad_norm": 2.0356359481811523,
      "learning_rate": 5.904827586206897e-05,
      "loss": 0.3287,
      "step": 46
    },
    {
      "epoch": 0.8103448275862069,
      "grad_norm": 2.252814769744873,
      "learning_rate": 5.902758620689655e-05,
      "loss": 0.3784,
      "step": 47
    },
    {
      "epoch": 0.8275862068965517,
      "grad_norm": 2.0337917804718018,
      "learning_rate": 5.900689655172414e-05,
      "loss": 0.3034,
      "step": 48
    },
    {
      "epoch": 0.8448275862068966,
      "grad_norm": 1.9755470752716064,
      "learning_rate": 5.8986206896551724e-05,
      "loss": 0.3331,
      "step": 49
    },
    {
      "epoch": 0.8620689655172413,
      "grad_norm": 2.115366220474243,
      "learning_rate": 5.896551724137931e-05,
      "loss": 0.3446,
      "step": 50
    },
    {
      "epoch": 0.8793103448275862,
      "grad_norm": 2.0108704566955566,
      "learning_rate": 5.89448275862069e-05,
      "loss": 0.3134,
      "step": 51
    },
    {
      "epoch": 0.896551724137931,
      "grad_norm": 2.9411728382110596,
      "learning_rate": 5.892413793103449e-05,
      "loss": 0.37,
      "step": 52
    },
    {
      "epoch": 0.9137931034482759,
      "grad_norm": 1.8443992137908936,
      "learning_rate": 5.890344827586207e-05,
      "loss": 0.3058,
      "step": 53
    },
    {
      "epoch": 0.9310344827586207,
      "grad_norm": 2.0619242191314697,
      "learning_rate": 5.888275862068966e-05,
      "loss": 0.3364,
      "step": 54
    },
    {
      "epoch": 0.9482758620689655,
      "grad_norm": 2.0537655353546143,
      "learning_rate": 5.886206896551724e-05,
      "loss": 0.3159,
      "step": 55
    },
    {
      "epoch": 0.9655172413793104,
      "grad_norm": 1.928839921951294,
      "learning_rate": 5.8841379310344826e-05,
      "loss": 0.2784,
      "step": 56
    },
    {
      "epoch": 0.9827586206896551,
      "grad_norm": 1.8016281127929688,
      "learning_rate": 5.8820689655172416e-05,
      "loss": 0.2915,
      "step": 57
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.9127863645553589,
      "learning_rate": 5.88e-05,
      "loss": 0.3154,
      "step": 58
    },
    {
      "epoch": 1.0172413793103448,
      "grad_norm": 2.041782855987549,
      "learning_rate": 5.877931034482758e-05,
      "loss": 0.3048,
      "step": 59
    },
    {
      "epoch": 1.0344827586206897,
      "grad_norm": 1.8383077383041382,
      "learning_rate": 5.875862068965517e-05,
      "loss": 0.2955,
      "step": 60
    },
    {
      "epoch": 1.0344827586206897,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.23316875100135803,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.644,
      "eval_samples_per_second": 3.355,
      "eval_steps_per_second": 1.735,
      "step": 60
    },
    {
      "epoch": 1.0517241379310345,
      "grad_norm": 1.8212924003601074,
      "learning_rate": 5.8737931034482756e-05,
      "loss": 0.2967,
      "step": 61
    },
    {
      "epoch": 1.0689655172413792,
      "grad_norm": 1.9468661546707153,
      "learning_rate": 5.871724137931035e-05,
      "loss": 0.2969,
      "step": 62
    },
    {
      "epoch": 1.0862068965517242,
      "grad_norm": 2.1044819355010986,
      "learning_rate": 5.8696551724137935e-05,
      "loss": 0.3067,
      "step": 63
    },
    {
      "epoch": 1.103448275862069,
      "grad_norm": 2.1448299884796143,
      "learning_rate": 5.867586206896552e-05,
      "loss": 0.3172,
      "step": 64
    },
    {
      "epoch": 1.1206896551724137,
      "grad_norm": 2.255342721939087,
      "learning_rate": 5.865517241379311e-05,
      "loss": 0.3278,
      "step": 65
    },
    {
      "epoch": 1.1379310344827587,
      "grad_norm": 1.7874197959899902,
      "learning_rate": 5.863448275862069e-05,
      "loss": 0.2991,
      "step": 66
    },
    {
      "epoch": 1.1551724137931034,
      "grad_norm": 1.9165176153182983,
      "learning_rate": 5.8613793103448275e-05,
      "loss": 0.2897,
      "step": 67
    },
    {
      "epoch": 1.1724137931034484,
      "grad_norm": 3.1619365215301514,
      "learning_rate": 5.8593103448275865e-05,
      "loss": 0.2417,
      "step": 68
    },
    {
      "epoch": 1.1896551724137931,
      "grad_norm": 1.783244013786316,
      "learning_rate": 5.857241379310345e-05,
      "loss": 0.2906,
      "step": 69
    },
    {
      "epoch": 1.206896551724138,
      "grad_norm": 3.987394332885742,
      "learning_rate": 5.855172413793103e-05,
      "loss": 0.3041,
      "step": 70
    },
    {
      "epoch": 1.2241379310344827,
      "grad_norm": 1.7669938802719116,
      "learning_rate": 5.853103448275863e-05,
      "loss": 0.2797,
      "step": 71
    },
    {
      "epoch": 1.2413793103448276,
      "grad_norm": 4.1406941413879395,
      "learning_rate": 5.851034482758621e-05,
      "loss": 0.2598,
      "step": 72
    },
    {
      "epoch": 1.2586206896551724,
      "grad_norm": 2.1380035877227783,
      "learning_rate": 5.8489655172413794e-05,
      "loss": 0.2937,
      "step": 73
    },
    {
      "epoch": 1.2758620689655173,
      "grad_norm": 1.8936501741409302,
      "learning_rate": 5.8468965517241384e-05,
      "loss": 0.2475,
      "step": 74
    },
    {
      "epoch": 1.293103448275862,
      "grad_norm": 1.6819270849227905,
      "learning_rate": 5.844827586206897e-05,
      "loss": 0.2523,
      "step": 75
    },
    {
      "epoch": 1.3103448275862069,
      "grad_norm": 1.5420722961425781,
      "learning_rate": 5.842758620689655e-05,
      "loss": 0.2272,
      "step": 76
    },
    {
      "epoch": 1.3275862068965516,
      "grad_norm": 1.8309684991836548,
      "learning_rate": 5.840689655172414e-05,
      "loss": 0.2735,
      "step": 77
    },
    {
      "epoch": 1.3448275862068966,
      "grad_norm": 1.42916738986969,
      "learning_rate": 5.838620689655172e-05,
      "loss": 0.1928,
      "step": 78
    },
    {
      "epoch": 1.3620689655172413,
      "grad_norm": 1.8003689050674438,
      "learning_rate": 5.8365517241379306e-05,
      "loss": 0.2754,
      "step": 79
    },
    {
      "epoch": 1.3793103448275863,
      "grad_norm": 1.962602972984314,
      "learning_rate": 5.8344827586206896e-05,
      "loss": 0.237,
      "step": 80
    },
    {
      "epoch": 1.3793103448275863,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.18063555657863617,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.933,
      "eval_samples_per_second": 3.246,
      "eval_steps_per_second": 1.679,
      "step": 80
    },
    {
      "epoch": 1.396551724137931,
      "grad_norm": 1.609325885772705,
      "learning_rate": 5.8324137931034486e-05,
      "loss": 0.2339,
      "step": 81
    },
    {
      "epoch": 1.4137931034482758,
      "grad_norm": 1.7625477313995361,
      "learning_rate": 5.830344827586207e-05,
      "loss": 0.2563,
      "step": 82
    },
    {
      "epoch": 1.4310344827586206,
      "grad_norm": 1.6563949584960938,
      "learning_rate": 5.828275862068966e-05,
      "loss": 0.2324,
      "step": 83
    },
    {
      "epoch": 1.4482758620689655,
      "grad_norm": 1.6208504438400269,
      "learning_rate": 5.826206896551724e-05,
      "loss": 0.2508,
      "step": 84
    },
    {
      "epoch": 1.4655172413793103,
      "grad_norm": 1.800473928451538,
      "learning_rate": 5.824137931034483e-05,
      "loss": 0.2167,
      "step": 85
    },
    {
      "epoch": 1.4827586206896552,
      "grad_norm": 1.446201205253601,
      "learning_rate": 5.8220689655172415e-05,
      "loss": 0.2054,
      "step": 86
    },
    {
      "epoch": 1.5,
      "grad_norm": 1.8959403038024902,
      "learning_rate": 5.82e-05,
      "loss": 0.2388,
      "step": 87
    },
    {
      "epoch": 1.5172413793103448,
      "grad_norm": 2.211918830871582,
      "learning_rate": 5.817931034482759e-05,
      "loss": 0.249,
      "step": 88
    },
    {
      "epoch": 1.5344827586206895,
      "grad_norm": 1.747666358947754,
      "learning_rate": 5.815862068965517e-05,
      "loss": 0.2627,
      "step": 89
    },
    {
      "epoch": 1.5517241379310345,
      "grad_norm": 1.707114815711975,
      "learning_rate": 5.813793103448276e-05,
      "loss": 0.2521,
      "step": 90
    },
    {
      "epoch": 1.5689655172413794,
      "grad_norm": 1.9388028383255005,
      "learning_rate": 5.811724137931035e-05,
      "loss": 0.1861,
      "step": 91
    },
    {
      "epoch": 1.5862068965517242,
      "grad_norm": 1.3670016527175903,
      "learning_rate": 5.8096551724137934e-05,
      "loss": 0.1947,
      "step": 92
    },
    {
      "epoch": 1.603448275862069,
      "grad_norm": 1.7291853427886963,
      "learning_rate": 5.807586206896552e-05,
      "loss": 0.2338,
      "step": 93
    },
    {
      "epoch": 1.6206896551724137,
      "grad_norm": 1.8656047582626343,
      "learning_rate": 5.805517241379311e-05,
      "loss": 0.2181,
      "step": 94
    },
    {
      "epoch": 1.6379310344827587,
      "grad_norm": 2.1514644622802734,
      "learning_rate": 5.803448275862069e-05,
      "loss": 0.2796,
      "step": 95
    },
    {
      "epoch": 1.6551724137931034,
      "grad_norm": 1.493828296661377,
      "learning_rate": 5.8013793103448274e-05,
      "loss": 0.1903,
      "step": 96
    },
    {
      "epoch": 1.6724137931034484,
      "grad_norm": 1.4076955318450928,
      "learning_rate": 5.7993103448275864e-05,
      "loss": 0.2163,
      "step": 97
    },
    {
      "epoch": 1.6896551724137931,
      "grad_norm": 1.6903940439224243,
      "learning_rate": 5.797241379310345e-05,
      "loss": 0.2117,
      "step": 98
    },
    {
      "epoch": 1.706896551724138,
      "grad_norm": 1.663884162902832,
      "learning_rate": 5.795172413793104e-05,
      "loss": 0.2031,
      "step": 99
    },
    {
      "epoch": 1.7241379310344827,
      "grad_norm": 1.4368952512741089,
      "learning_rate": 5.7931034482758627e-05,
      "loss": 0.1622,
      "step": 100
    },
    {
      "epoch": 1.7241379310344827,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.13996583223342896,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.1589,
      "eval_samples_per_second": 3.166,
      "eval_steps_per_second": 1.638,
      "step": 100
    },
    {
      "epoch": 1.7413793103448276,
      "grad_norm": 1.7359246015548706,
      "learning_rate": 5.791034482758621e-05,
      "loss": 0.2181,
      "step": 101
    },
    {
      "epoch": 1.7586206896551724,
      "grad_norm": 1.4928580522537231,
      "learning_rate": 5.788965517241379e-05,
      "loss": 0.213,
      "step": 102
    },
    {
      "epoch": 1.7758620689655173,
      "grad_norm": 1.5421860218048096,
      "learning_rate": 5.786896551724138e-05,
      "loss": 0.1991,
      "step": 103
    },
    {
      "epoch": 1.793103448275862,
      "grad_norm": 1.427653431892395,
      "learning_rate": 5.7848275862068966e-05,
      "loss": 0.2012,
      "step": 104
    },
    {
      "epoch": 1.8103448275862069,
      "grad_norm": 1.5004531145095825,
      "learning_rate": 5.782758620689655e-05,
      "loss": 0.2156,
      "step": 105
    },
    {
      "epoch": 1.8275862068965516,
      "grad_norm": 1.2724390029907227,
      "learning_rate": 5.780689655172414e-05,
      "loss": 0.179,
      "step": 106
    },
    {
      "epoch": 1.8448275862068966,
      "grad_norm": 1.610019564628601,
      "learning_rate": 5.778620689655172e-05,
      "loss": 0.2009,
      "step": 107
    },
    {
      "epoch": 1.8620689655172413,
      "grad_norm": 1.4194047451019287,
      "learning_rate": 5.776551724137931e-05,
      "loss": 0.2093,
      "step": 108
    },
    {
      "epoch": 1.8793103448275863,
      "grad_norm": 1.317928433418274,
      "learning_rate": 5.77448275862069e-05,
      "loss": 0.1855,
      "step": 109
    },
    {
      "epoch": 1.896551724137931,
      "grad_norm": 1.463489055633545,
      "learning_rate": 5.7724137931034485e-05,
      "loss": 0.1743,
      "step": 110
    },
    {
      "epoch": 1.9137931034482758,
      "grad_norm": 1.4002881050109863,
      "learning_rate": 5.7703448275862075e-05,
      "loss": 0.186,
      "step": 111
    },
    {
      "epoch": 1.9310344827586206,
      "grad_norm": 1.3095396757125854,
      "learning_rate": 5.768275862068966e-05,
      "loss": 0.1443,
      "step": 112
    },
    {
      "epoch": 1.9482758620689655,
      "grad_norm": 1.5527658462524414,
      "learning_rate": 5.766206896551724e-05,
      "loss": 0.2055,
      "step": 113
    },
    {
      "epoch": 1.9655172413793105,
      "grad_norm": 1.3713860511779785,
      "learning_rate": 5.764137931034483e-05,
      "loss": 0.2177,
      "step": 114
    },
    {
      "epoch": 1.9827586206896552,
      "grad_norm": 1.2066690921783447,
      "learning_rate": 5.7620689655172414e-05,
      "loss": 0.1528,
      "step": 115
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.2971127033233643,
      "learning_rate": 5.76e-05,
      "loss": 0.1853,
      "step": 116
    },
    {
      "epoch": 2.0172413793103448,
      "grad_norm": 1.7233874797821045,
      "learning_rate": 5.757931034482759e-05,
      "loss": 0.2017,
      "step": 117
    },
    {
      "epoch": 2.0344827586206895,
      "grad_norm": 1.2670555114746094,
      "learning_rate": 5.755862068965518e-05,
      "loss": 0.1719,
      "step": 118
    },
    {
      "epoch": 2.0517241379310347,
      "grad_norm": 1.3774598836898804,
      "learning_rate": 5.753793103448276e-05,
      "loss": 0.2032,
      "step": 119
    },
    {
      "epoch": 2.0689655172413794,
      "grad_norm": 1.1402981281280518,
      "learning_rate": 5.751724137931035e-05,
      "loss": 0.1565,
      "step": 120
    },
    {
      "epoch": 2.0689655172413794,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.14552922546863556,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.5943,
      "eval_samples_per_second": 3.023,
      "eval_steps_per_second": 1.563,
      "step": 120
    },
    {
      "epoch": 2.086206896551724,
      "grad_norm": 1.1877508163452148,
      "learning_rate": 5.7496551724137933e-05,
      "loss": 0.1438,
      "step": 121
    },
    {
      "epoch": 2.103448275862069,
      "grad_norm": 1.4004234075546265,
      "learning_rate": 5.7475862068965517e-05,
      "loss": 0.1808,
      "step": 122
    },
    {
      "epoch": 2.1206896551724137,
      "grad_norm": 1.0061007738113403,
      "learning_rate": 5.7455172413793106e-05,
      "loss": 0.1249,
      "step": 123
    },
    {
      "epoch": 2.1379310344827585,
      "grad_norm": 1.2608259916305542,
      "learning_rate": 5.743448275862069e-05,
      "loss": 0.1868,
      "step": 124
    },
    {
      "epoch": 2.1551724137931036,
      "grad_norm": 1.07465398311615,
      "learning_rate": 5.741379310344827e-05,
      "loss": 0.1441,
      "step": 125
    },
    {
      "epoch": 2.1724137931034484,
      "grad_norm": 1.3132588863372803,
      "learning_rate": 5.739310344827586e-05,
      "loss": 0.1735,
      "step": 126
    },
    {
      "epoch": 2.189655172413793,
      "grad_norm": 1.2071720361709595,
      "learning_rate": 5.7372413793103446e-05,
      "loss": 0.1422,
      "step": 127
    },
    {
      "epoch": 2.206896551724138,
      "grad_norm": 1.4108830690383911,
      "learning_rate": 5.7351724137931036e-05,
      "loss": 0.1555,
      "step": 128
    },
    {
      "epoch": 2.2241379310344827,
      "grad_norm": 1.5475335121154785,
      "learning_rate": 5.7331034482758626e-05,
      "loss": 0.154,
      "step": 129
    },
    {
      "epoch": 2.2413793103448274,
      "grad_norm": 1.1122500896453857,
      "learning_rate": 5.731034482758621e-05,
      "loss": 0.1444,
      "step": 130
    },
    {
      "epoch": 2.2586206896551726,
      "grad_norm": 1.2235040664672852,
      "learning_rate": 5.728965517241379e-05,
      "loss": 0.1669,
      "step": 131
    },
    {
      "epoch": 2.2758620689655173,
      "grad_norm": 1.518455147743225,
      "learning_rate": 5.726896551724138e-05,
      "loss": 0.1614,
      "step": 132
    },
    {
      "epoch": 2.293103448275862,
      "grad_norm": 1.02388334274292,
      "learning_rate": 5.7248275862068965e-05,
      "loss": 0.1223,
      "step": 133
    },
    {
      "epoch": 2.310344827586207,
      "grad_norm": 1.4658163785934448,
      "learning_rate": 5.7227586206896555e-05,
      "loss": 0.1787,
      "step": 134
    },
    {
      "epoch": 2.3275862068965516,
      "grad_norm": 1.0412847995758057,
      "learning_rate": 5.720689655172414e-05,
      "loss": 0.1289,
      "step": 135
    },
    {
      "epoch": 2.344827586206897,
      "grad_norm": 1.1098946332931519,
      "learning_rate": 5.718620689655172e-05,
      "loss": 0.1567,
      "step": 136
    },
    {
      "epoch": 2.3620689655172415,
      "grad_norm": 1.8633977174758911,
      "learning_rate": 5.716551724137932e-05,
      "loss": 0.1844,
      "step": 137
    },
    {
      "epoch": 2.3793103448275863,
      "grad_norm": 1.0745590925216675,
      "learning_rate": 5.71448275862069e-05,
      "loss": 0.1483,
      "step": 138
    },
    {
      "epoch": 2.396551724137931,
      "grad_norm": 1.5251803398132324,
      "learning_rate": 5.7124137931034484e-05,
      "loss": 0.1423,
      "step": 139
    },
    {
      "epoch": 2.413793103448276,
      "grad_norm": 0.9581853747367859,
      "learning_rate": 5.7103448275862074e-05,
      "loss": 0.1153,
      "step": 140
    },
    {
      "epoch": 2.413793103448276,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.10419480502605438,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.2253,
      "eval_samples_per_second": 3.144,
      "eval_steps_per_second": 1.626,
      "step": 140
    },
    {
      "epoch": 2.4310344827586206,
      "grad_norm": 1.0320249795913696,
      "learning_rate": 5.708275862068966e-05,
      "loss": 0.1364,
      "step": 141
    },
    {
      "epoch": 2.4482758620689653,
      "grad_norm": 1.0705593824386597,
      "learning_rate": 5.706206896551724e-05,
      "loss": 0.1384,
      "step": 142
    },
    {
      "epoch": 2.4655172413793105,
      "grad_norm": 1.3216098546981812,
      "learning_rate": 5.704137931034483e-05,
      "loss": 0.1364,
      "step": 143
    },
    {
      "epoch": 2.4827586206896552,
      "grad_norm": 1.0665838718414307,
      "learning_rate": 5.702068965517241e-05,
      "loss": 0.1254,
      "step": 144
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.1564326286315918,
      "learning_rate": 5.6999999999999996e-05,
      "loss": 0.141,
      "step": 145
    },
    {
      "epoch": 2.5172413793103448,
      "grad_norm": 0.8904747366905212,
      "learning_rate": 5.697931034482759e-05,
      "loss": 0.1227,
      "step": 146
    },
    {
      "epoch": 2.5344827586206895,
      "grad_norm": 0.9305250644683838,
      "learning_rate": 5.6958620689655176e-05,
      "loss": 0.1257,
      "step": 147
    },
    {
      "epoch": 2.5517241379310347,
      "grad_norm": 1.3210957050323486,
      "learning_rate": 5.693793103448276e-05,
      "loss": 0.135,
      "step": 148
    },
    {
      "epoch": 2.5689655172413794,
      "grad_norm": 0.9705650210380554,
      "learning_rate": 5.691724137931035e-05,
      "loss": 0.0988,
      "step": 149
    },
    {
      "epoch": 2.586206896551724,
      "grad_norm": 0.9647497534751892,
      "learning_rate": 5.689655172413793e-05,
      "loss": 0.1263,
      "step": 150
    },
    {
      "epoch": 2.603448275862069,
      "grad_norm": 0.8814834952354431,
      "learning_rate": 5.6875862068965515e-05,
      "loss": 0.1103,
      "step": 151
    },
    {
      "epoch": 2.6206896551724137,
      "grad_norm": 2.1756672859191895,
      "learning_rate": 5.6855172413793105e-05,
      "loss": 0.1586,
      "step": 152
    },
    {
      "epoch": 2.637931034482759,
      "grad_norm": 0.9019825458526611,
      "learning_rate": 5.683448275862069e-05,
      "loss": 0.1118,
      "step": 153
    },
    {
      "epoch": 2.655172413793103,
      "grad_norm": 1.0331734418869019,
      "learning_rate": 5.681379310344827e-05,
      "loss": 0.115,
      "step": 154
    },
    {
      "epoch": 2.6724137931034484,
      "grad_norm": 0.7702242136001587,
      "learning_rate": 5.679310344827586e-05,
      "loss": 0.0892,
      "step": 155
    },
    {
      "epoch": 2.689655172413793,
      "grad_norm": 1.0714004039764404,
      "learning_rate": 5.677241379310345e-05,
      "loss": 0.1227,
      "step": 156
    },
    {
      "epoch": 2.706896551724138,
      "grad_norm": 0.9732339978218079,
      "learning_rate": 5.675172413793104e-05,
      "loss": 0.1184,
      "step": 157
    },
    {
      "epoch": 2.7241379310344827,
      "grad_norm": 1.4610857963562012,
      "learning_rate": 5.6731034482758625e-05,
      "loss": 0.1344,
      "step": 158
    },
    {
      "epoch": 2.7413793103448274,
      "grad_norm": 1.0449872016906738,
      "learning_rate": 5.671034482758621e-05,
      "loss": 0.1059,
      "step": 159
    },
    {
      "epoch": 2.7586206896551726,
      "grad_norm": 1.0369747877120972,
      "learning_rate": 5.66896551724138e-05,
      "loss": 0.1237,
      "step": 160
    },
    {
      "epoch": 2.7586206896551726,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.09384531527757645,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.4971,
      "eval_samples_per_second": 2.321,
      "eval_steps_per_second": 1.2,
      "step": 160
    },
    {
      "epoch": 2.7758620689655173,
      "grad_norm": 0.7726851105690002,
      "learning_rate": 5.666896551724138e-05,
      "loss": 0.091,
      "step": 161
    },
    {
      "epoch": 2.793103448275862,
      "grad_norm": 1.1606016159057617,
      "learning_rate": 5.6648275862068964e-05,
      "loss": 0.1057,
      "step": 162
    },
    {
      "epoch": 2.810344827586207,
      "grad_norm": 0.9674198031425476,
      "learning_rate": 5.6627586206896554e-05,
      "loss": 0.1309,
      "step": 163
    },
    {
      "epoch": 2.8275862068965516,
      "grad_norm": 0.8421165347099304,
      "learning_rate": 5.660689655172414e-05,
      "loss": 0.1099,
      "step": 164
    },
    {
      "epoch": 2.844827586206897,
      "grad_norm": 0.8580870032310486,
      "learning_rate": 5.658620689655173e-05,
      "loss": 0.1061,
      "step": 165
    },
    {
      "epoch": 2.862068965517241,
      "grad_norm": 0.7618314027786255,
      "learning_rate": 5.656551724137932e-05,
      "loss": 0.0911,
      "step": 166
    },
    {
      "epoch": 2.8793103448275863,
      "grad_norm": 0.9431270956993103,
      "learning_rate": 5.65448275862069e-05,
      "loss": 0.1103,
      "step": 167
    },
    {
      "epoch": 2.896551724137931,
      "grad_norm": 1.1063934564590454,
      "learning_rate": 5.652413793103448e-05,
      "loss": 0.1153,
      "step": 168
    },
    {
      "epoch": 2.913793103448276,
      "grad_norm": 0.8629714846611023,
      "learning_rate": 5.650344827586207e-05,
      "loss": 0.0958,
      "step": 169
    },
    {
      "epoch": 2.9310344827586206,
      "grad_norm": 1.0532697439193726,
      "learning_rate": 5.6482758620689656e-05,
      "loss": 0.0894,
      "step": 170
    },
    {
      "epoch": 2.9482758620689653,
      "grad_norm": 0.7465978264808655,
      "learning_rate": 5.646206896551724e-05,
      "loss": 0.0952,
      "step": 171
    },
    {
      "epoch": 2.9655172413793105,
      "grad_norm": 2.9305949211120605,
      "learning_rate": 5.644137931034483e-05,
      "loss": 0.1247,
      "step": 172
    },
    {
      "epoch": 2.9827586206896552,
      "grad_norm": 0.5959832668304443,
      "learning_rate": 5.642068965517241e-05,
      "loss": 0.0621,
      "step": 173
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.8086969256401062,
      "learning_rate": 5.6399999999999995e-05,
      "loss": 0.0822,
      "step": 174
    },
    {
      "epoch": 3.0172413793103448,
      "grad_norm": 0.7554581165313721,
      "learning_rate": 5.637931034482759e-05,
      "loss": 0.0886,
      "step": 175
    },
    {
      "epoch": 3.0344827586206895,
      "grad_norm": 0.7953328490257263,
      "learning_rate": 5.6358620689655175e-05,
      "loss": 0.0972,
      "step": 176
    },
    {
      "epoch": 3.0517241379310347,
      "grad_norm": 0.6282335519790649,
      "learning_rate": 5.633793103448276e-05,
      "loss": 0.0732,
      "step": 177
    },
    {
      "epoch": 3.0689655172413794,
      "grad_norm": 0.8670214414596558,
      "learning_rate": 5.631724137931035e-05,
      "loss": 0.1078,
      "step": 178
    },
    {
      "epoch": 3.086206896551724,
      "grad_norm": 0.7122248411178589,
      "learning_rate": 5.629655172413793e-05,
      "loss": 0.0894,
      "step": 179
    },
    {
      "epoch": 3.103448275862069,
      "grad_norm": 0.9371910691261292,
      "learning_rate": 5.627586206896552e-05,
      "loss": 0.092,
      "step": 180
    },
    {
      "epoch": 3.103448275862069,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.05657956749200821,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.2755,
      "eval_samples_per_second": 2.184,
      "eval_steps_per_second": 1.13,
      "step": 180
    },
    {
      "epoch": 3.1206896551724137,
      "grad_norm": 0.74242103099823,
      "learning_rate": 5.6255172413793104e-05,
      "loss": 0.0791,
      "step": 181
    },
    {
      "epoch": 3.1379310344827585,
      "grad_norm": 0.6830041408538818,
      "learning_rate": 5.623448275862069e-05,
      "loss": 0.0883,
      "step": 182
    },
    {
      "epoch": 3.1551724137931036,
      "grad_norm": 1.3912990093231201,
      "learning_rate": 5.621379310344828e-05,
      "loss": 0.0929,
      "step": 183
    },
    {
      "epoch": 3.1724137931034484,
      "grad_norm": 0.8193244934082031,
      "learning_rate": 5.619310344827587e-05,
      "loss": 0.1066,
      "step": 184
    },
    {
      "epoch": 3.189655172413793,
      "grad_norm": 0.8390568494796753,
      "learning_rate": 5.617241379310345e-05,
      "loss": 0.0994,
      "step": 185
    },
    {
      "epoch": 3.206896551724138,
      "grad_norm": 0.9176702499389648,
      "learning_rate": 5.615172413793104e-05,
      "loss": 0.0869,
      "step": 186
    },
    {
      "epoch": 3.2241379310344827,
      "grad_norm": 0.9008005857467651,
      "learning_rate": 5.6131034482758624e-05,
      "loss": 0.1042,
      "step": 187
    },
    {
      "epoch": 3.2413793103448274,
      "grad_norm": 0.6110315918922424,
      "learning_rate": 5.611034482758621e-05,
      "loss": 0.0691,
      "step": 188
    },
    {
      "epoch": 3.2586206896551726,
      "grad_norm": 0.6821939945220947,
      "learning_rate": 5.6089655172413797e-05,
      "loss": 0.0883,
      "step": 189
    },
    {
      "epoch": 3.2758620689655173,
      "grad_norm": 0.9539391994476318,
      "learning_rate": 5.606896551724138e-05,
      "loss": 0.0799,
      "step": 190
    },
    {
      "epoch": 3.293103448275862,
      "grad_norm": 0.7482500672340393,
      "learning_rate": 5.604827586206896e-05,
      "loss": 0.0803,
      "step": 191
    },
    {
      "epoch": 3.310344827586207,
      "grad_norm": 0.5017297863960266,
      "learning_rate": 5.602758620689655e-05,
      "loss": 0.0555,
      "step": 192
    },
    {
      "epoch": 3.3275862068965516,
      "grad_norm": 0.6503825187683105,
      "learning_rate": 5.6006896551724136e-05,
      "loss": 0.0671,
      "step": 193
    },
    {
      "epoch": 3.344827586206897,
      "grad_norm": 0.6532056927680969,
      "learning_rate": 5.5986206896551726e-05,
      "loss": 0.0799,
      "step": 194
    },
    {
      "epoch": 3.3620689655172415,
      "grad_norm": 0.6737744808197021,
      "learning_rate": 5.5965517241379316e-05,
      "loss": 0.0798,
      "step": 195
    },
    {
      "epoch": 3.3793103448275863,
      "grad_norm": 0.6691791415214539,
      "learning_rate": 5.59448275862069e-05,
      "loss": 0.0803,
      "step": 196
    },
    {
      "epoch": 3.396551724137931,
      "grad_norm": 0.5602226853370667,
      "learning_rate": 5.592413793103448e-05,
      "loss": 0.0599,
      "step": 197
    },
    {
      "epoch": 3.413793103448276,
      "grad_norm": 0.7268373966217041,
      "learning_rate": 5.590344827586207e-05,
      "loss": 0.0853,
      "step": 198
    },
    {
      "epoch": 3.4310344827586206,
      "grad_norm": 0.5616654753684998,
      "learning_rate": 5.5882758620689655e-05,
      "loss": 0.0647,
      "step": 199
    },
    {
      "epoch": 3.4482758620689653,
      "grad_norm": 0.712345540523529,
      "learning_rate": 5.586206896551724e-05,
      "loss": 0.0916,
      "step": 200
    },
    {
      "epoch": 3.4482758620689653,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.05856788530945778,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.5143,
      "eval_samples_per_second": 2.317,
      "eval_steps_per_second": 1.199,
      "step": 200
    },
    {
      "epoch": 3.4655172413793105,
      "grad_norm": 0.6164402365684509,
      "learning_rate": 5.584137931034483e-05,
      "loss": 0.0687,
      "step": 201
    },
    {
      "epoch": 3.4827586206896552,
      "grad_norm": 0.5589931011199951,
      "learning_rate": 5.582068965517241e-05,
      "loss": 0.0649,
      "step": 202
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.8971918821334839,
      "learning_rate": 5.58e-05,
      "loss": 0.08,
      "step": 203
    },
    {
      "epoch": 3.5172413793103448,
      "grad_norm": 0.6801175475120544,
      "learning_rate": 5.577931034482759e-05,
      "loss": 0.0678,
      "step": 204
    },
    {
      "epoch": 3.5344827586206895,
      "grad_norm": 0.8067324161529541,
      "learning_rate": 5.5758620689655174e-05,
      "loss": 0.0759,
      "step": 205
    },
    {
      "epoch": 3.5517241379310347,
      "grad_norm": 0.5845818519592285,
      "learning_rate": 5.5737931034482764e-05,
      "loss": 0.0683,
      "step": 206
    },
    {
      "epoch": 3.5689655172413794,
      "grad_norm": 0.7929644584655762,
      "learning_rate": 5.571724137931035e-05,
      "loss": 0.0859,
      "step": 207
    },
    {
      "epoch": 3.586206896551724,
      "grad_norm": 0.6099998950958252,
      "learning_rate": 5.569655172413793e-05,
      "loss": 0.067,
      "step": 208
    },
    {
      "epoch": 3.603448275862069,
      "grad_norm": 1.0962581634521484,
      "learning_rate": 5.567586206896552e-05,
      "loss": 0.0911,
      "step": 209
    },
    {
      "epoch": 3.6206896551724137,
      "grad_norm": 0.6972625851631165,
      "learning_rate": 5.56551724137931e-05,
      "loss": 0.0869,
      "step": 210
    },
    {
      "epoch": 3.637931034482759,
      "grad_norm": 0.7743116617202759,
      "learning_rate": 5.5634482758620686e-05,
      "loss": 0.0663,
      "step": 211
    },
    {
      "epoch": 3.655172413793103,
      "grad_norm": 0.6555594205856323,
      "learning_rate": 5.561379310344828e-05,
      "loss": 0.0728,
      "step": 212
    },
    {
      "epoch": 3.6724137931034484,
      "grad_norm": 0.5070855021476746,
      "learning_rate": 5.5593103448275866e-05,
      "loss": 0.0624,
      "step": 213
    },
    {
      "epoch": 3.689655172413793,
      "grad_norm": 0.7875059843063354,
      "learning_rate": 5.557241379310345e-05,
      "loss": 0.0774,
      "step": 214
    },
    {
      "epoch": 3.706896551724138,
      "grad_norm": 0.5569983720779419,
      "learning_rate": 5.555172413793104e-05,
      "loss": 0.0603,
      "step": 215
    },
    {
      "epoch": 3.7241379310344827,
      "grad_norm": 0.6753576397895813,
      "learning_rate": 5.553103448275862e-05,
      "loss": 0.0529,
      "step": 216
    },
    {
      "epoch": 3.7413793103448274,
      "grad_norm": 0.4811021387577057,
      "learning_rate": 5.5510344827586206e-05,
      "loss": 0.0496,
      "step": 217
    },
    {
      "epoch": 3.7586206896551726,
      "grad_norm": 0.5666003227233887,
      "learning_rate": 5.5489655172413796e-05,
      "loss": 0.0423,
      "step": 218
    },
    {
      "epoch": 3.7758620689655173,
      "grad_norm": 0.8736357092857361,
      "learning_rate": 5.546896551724138e-05,
      "loss": 0.069,
      "step": 219
    },
    {
      "epoch": 3.793103448275862,
      "grad_norm": 1.6259721517562866,
      "learning_rate": 5.544827586206896e-05,
      "loss": 0.094,
      "step": 220
    },
    {
      "epoch": 3.793103448275862,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.05151967704296112,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.8728,
      "eval_samples_per_second": 2.667,
      "eval_steps_per_second": 1.38,
      "step": 220
    },
    {
      "epoch": 3.810344827586207,
      "grad_norm": 1.3344191312789917,
      "learning_rate": 5.542758620689655e-05,
      "loss": 0.0798,
      "step": 221
    },
    {
      "epoch": 3.8275862068965516,
      "grad_norm": 0.9805311560630798,
      "learning_rate": 5.540689655172414e-05,
      "loss": 0.0831,
      "step": 222
    },
    {
      "epoch": 3.844827586206897,
      "grad_norm": 0.5333646535873413,
      "learning_rate": 5.5386206896551725e-05,
      "loss": 0.0625,
      "step": 223
    },
    {
      "epoch": 3.862068965517241,
      "grad_norm": 0.6226376891136169,
      "learning_rate": 5.5365517241379315e-05,
      "loss": 0.0565,
      "step": 224
    },
    {
      "epoch": 3.8793103448275863,
      "grad_norm": 0.5476487278938293,
      "learning_rate": 5.53448275862069e-05,
      "loss": 0.0469,
      "step": 225
    },
    {
      "epoch": 3.896551724137931,
      "grad_norm": 0.4683278203010559,
      "learning_rate": 5.532413793103448e-05,
      "loss": 0.0486,
      "step": 226
    },
    {
      "epoch": 3.913793103448276,
      "grad_norm": 0.423831045627594,
      "learning_rate": 5.530344827586207e-05,
      "loss": 0.0464,
      "step": 227
    },
    {
      "epoch": 3.9310344827586206,
      "grad_norm": 0.48292988538742065,
      "learning_rate": 5.5282758620689654e-05,
      "loss": 0.0509,
      "step": 228
    },
    {
      "epoch": 3.9482758620689653,
      "grad_norm": 0.6419795751571655,
      "learning_rate": 5.5262068965517244e-05,
      "loss": 0.0655,
      "step": 229
    },
    {
      "epoch": 3.9655172413793105,
      "grad_norm": 0.5921717882156372,
      "learning_rate": 5.524137931034483e-05,
      "loss": 0.0601,
      "step": 230
    },
    {
      "epoch": 3.9827586206896552,
      "grad_norm": 0.5173442959785461,
      "learning_rate": 5.522068965517242e-05,
      "loss": 0.0473,
      "step": 231
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.7864723205566406,
      "learning_rate": 5.520000000000001e-05,
      "loss": 0.0592,
      "step": 232
    },
    {
      "epoch": 4.017241379310345,
      "grad_norm": 0.4970155656337738,
      "learning_rate": 5.517931034482759e-05,
      "loss": 0.0496,
      "step": 233
    },
    {
      "epoch": 4.0344827586206895,
      "grad_norm": 0.4858390688896179,
      "learning_rate": 5.515862068965517e-05,
      "loss": 0.0571,
      "step": 234
    },
    {
      "epoch": 4.051724137931035,
      "grad_norm": 0.43570637702941895,
      "learning_rate": 5.513793103448276e-05,
      "loss": 0.0509,
      "step": 235
    },
    {
      "epoch": 4.068965517241379,
      "grad_norm": 0.5113270878791809,
      "learning_rate": 5.5117241379310346e-05,
      "loss": 0.0492,
      "step": 236
    },
    {
      "epoch": 4.086206896551724,
      "grad_norm": 0.42030760645866394,
      "learning_rate": 5.509655172413793e-05,
      "loss": 0.0509,
      "step": 237
    },
    {
      "epoch": 4.103448275862069,
      "grad_norm": 0.5436128377914429,
      "learning_rate": 5.507586206896552e-05,
      "loss": 0.0606,
      "step": 238
    },
    {
      "epoch": 4.120689655172414,
      "grad_norm": 0.40952327847480774,
      "learning_rate": 5.50551724137931e-05,
      "loss": 0.0459,
      "step": 239
    },
    {
      "epoch": 4.137931034482759,
      "grad_norm": 0.4884064495563507,
      "learning_rate": 5.5034482758620685e-05,
      "loss": 0.0478,
      "step": 240
    },
    {
      "epoch": 4.137931034482759,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.040986377745866776,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.8791,
      "eval_samples_per_second": 2.666,
      "eval_steps_per_second": 1.379,
      "step": 240
    },
    {
      "epoch": 4.155172413793103,
      "grad_norm": 0.38241177797317505,
      "learning_rate": 5.501379310344828e-05,
      "loss": 0.0352,
      "step": 241
    },
    {
      "epoch": 4.172413793103448,
      "grad_norm": 0.4856823682785034,
      "learning_rate": 5.4993103448275865e-05,
      "loss": 0.0594,
      "step": 242
    },
    {
      "epoch": 4.189655172413793,
      "grad_norm": 0.4693872928619385,
      "learning_rate": 5.497241379310345e-05,
      "loss": 0.0577,
      "step": 243
    },
    {
      "epoch": 4.206896551724138,
      "grad_norm": 0.5318753719329834,
      "learning_rate": 5.495172413793104e-05,
      "loss": 0.0441,
      "step": 244
    },
    {
      "epoch": 4.224137931034483,
      "grad_norm": 0.5638884902000427,
      "learning_rate": 5.493103448275862e-05,
      "loss": 0.0571,
      "step": 245
    },
    {
      "epoch": 4.241379310344827,
      "grad_norm": 0.6396797299385071,
      "learning_rate": 5.4910344827586205e-05,
      "loss": 0.0499,
      "step": 246
    },
    {
      "epoch": 4.258620689655173,
      "grad_norm": 0.41017502546310425,
      "learning_rate": 5.4889655172413794e-05,
      "loss": 0.0463,
      "step": 247
    },
    {
      "epoch": 4.275862068965517,
      "grad_norm": 0.4473749101161957,
      "learning_rate": 5.486896551724138e-05,
      "loss": 0.0547,
      "step": 248
    },
    {
      "epoch": 4.293103448275862,
      "grad_norm": 0.49939024448394775,
      "learning_rate": 5.484827586206896e-05,
      "loss": 0.0567,
      "step": 249
    },
    {
      "epoch": 4.310344827586207,
      "grad_norm": 0.4210761487483978,
      "learning_rate": 5.482758620689656e-05,
      "loss": 0.0422,
      "step": 250
    },
    {
      "epoch": 4.327586206896552,
      "grad_norm": 0.4980606734752655,
      "learning_rate": 5.480689655172414e-05,
      "loss": 0.0613,
      "step": 251
    },
    {
      "epoch": 4.344827586206897,
      "grad_norm": 0.35180506110191345,
      "learning_rate": 5.478620689655173e-05,
      "loss": 0.039,
      "step": 252
    },
    {
      "epoch": 4.362068965517241,
      "grad_norm": 0.4934595823287964,
      "learning_rate": 5.4765517241379314e-05,
      "loss": 0.0601,
      "step": 253
    },
    {
      "epoch": 4.379310344827586,
      "grad_norm": 0.5140576958656311,
      "learning_rate": 5.47448275862069e-05,
      "loss": 0.0558,
      "step": 254
    },
    {
      "epoch": 4.396551724137931,
      "grad_norm": 0.4205336570739746,
      "learning_rate": 5.472413793103449e-05,
      "loss": 0.0486,
      "step": 255
    },
    {
      "epoch": 4.413793103448276,
      "grad_norm": 0.3349911868572235,
      "learning_rate": 5.470344827586207e-05,
      "loss": 0.0379,
      "step": 256
    },
    {
      "epoch": 4.431034482758621,
      "grad_norm": 0.3885943591594696,
      "learning_rate": 5.468275862068965e-05,
      "loss": 0.0447,
      "step": 257
    },
    {
      "epoch": 4.448275862068965,
      "grad_norm": 0.28770047426223755,
      "learning_rate": 5.466206896551724e-05,
      "loss": 0.0264,
      "step": 258
    },
    {
      "epoch": 4.4655172413793105,
      "grad_norm": 0.37731292843818665,
      "learning_rate": 5.464137931034483e-05,
      "loss": 0.0451,
      "step": 259
    },
    {
      "epoch": 4.482758620689655,
      "grad_norm": 0.39766499400138855,
      "learning_rate": 5.4620689655172416e-05,
      "loss": 0.0385,
      "step": 260
    },
    {
      "epoch": 4.482758620689655,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.03553231805562973,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.0861,
      "eval_samples_per_second": 2.399,
      "eval_steps_per_second": 1.241,
      "step": 260
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.4647005498409271,
      "learning_rate": 5.4600000000000006e-05,
      "loss": 0.0474,
      "step": 261
    },
    {
      "epoch": 4.517241379310345,
      "grad_norm": 0.47412559390068054,
      "learning_rate": 5.457931034482759e-05,
      "loss": 0.0465,
      "step": 262
    },
    {
      "epoch": 4.5344827586206895,
      "grad_norm": 0.4859597384929657,
      "learning_rate": 5.455862068965517e-05,
      "loss": 0.054,
      "step": 263
    },
    {
      "epoch": 4.551724137931035,
      "grad_norm": 0.26806482672691345,
      "learning_rate": 5.453793103448276e-05,
      "loss": 0.0273,
      "step": 264
    },
    {
      "epoch": 4.568965517241379,
      "grad_norm": 0.5909795165061951,
      "learning_rate": 5.4517241379310345e-05,
      "loss": 0.0496,
      "step": 265
    },
    {
      "epoch": 4.586206896551724,
      "grad_norm": 0.4274117946624756,
      "learning_rate": 5.449655172413793e-05,
      "loss": 0.0384,
      "step": 266
    },
    {
      "epoch": 4.603448275862069,
      "grad_norm": 0.7243903279304504,
      "learning_rate": 5.447586206896552e-05,
      "loss": 0.0534,
      "step": 267
    },
    {
      "epoch": 4.620689655172414,
      "grad_norm": 0.6156426072120667,
      "learning_rate": 5.44551724137931e-05,
      "loss": 0.0539,
      "step": 268
    },
    {
      "epoch": 4.637931034482759,
      "grad_norm": 0.4071465730667114,
      "learning_rate": 5.443448275862069e-05,
      "loss": 0.0437,
      "step": 269
    },
    {
      "epoch": 4.655172413793103,
      "grad_norm": 0.3982180058956146,
      "learning_rate": 5.441379310344828e-05,
      "loss": 0.0424,
      "step": 270
    },
    {
      "epoch": 4.672413793103448,
      "grad_norm": 0.3860669434070587,
      "learning_rate": 5.4393103448275864e-05,
      "loss": 0.0477,
      "step": 271
    },
    {
      "epoch": 4.689655172413794,
      "grad_norm": 0.4850260019302368,
      "learning_rate": 5.437241379310345e-05,
      "loss": 0.0457,
      "step": 272
    },
    {
      "epoch": 4.706896551724138,
      "grad_norm": 0.4446166753768921,
      "learning_rate": 5.435172413793104e-05,
      "loss": 0.0398,
      "step": 273
    },
    {
      "epoch": 4.724137931034483,
      "grad_norm": 0.4214908182621002,
      "learning_rate": 5.433103448275862e-05,
      "loss": 0.0407,
      "step": 274
    },
    {
      "epoch": 4.741379310344827,
      "grad_norm": 0.5347117185592651,
      "learning_rate": 5.4310344827586204e-05,
      "loss": 0.0395,
      "step": 275
    },
    {
      "epoch": 4.758620689655173,
      "grad_norm": 0.7932695150375366,
      "learning_rate": 5.4289655172413793e-05,
      "loss": 0.0539,
      "step": 276
    },
    {
      "epoch": 4.775862068965517,
      "grad_norm": 0.5460141897201538,
      "learning_rate": 5.4268965517241377e-05,
      "loss": 0.0499,
      "step": 277
    },
    {
      "epoch": 4.793103448275862,
      "grad_norm": 0.32542985677719116,
      "learning_rate": 5.424827586206897e-05,
      "loss": 0.0285,
      "step": 278
    },
    {
      "epoch": 4.810344827586206,
      "grad_norm": 0.8238851428031921,
      "learning_rate": 5.4227586206896556e-05,
      "loss": 0.0611,
      "step": 279
    },
    {
      "epoch": 4.827586206896552,
      "grad_norm": 0.400219202041626,
      "learning_rate": 5.420689655172414e-05,
      "loss": 0.0394,
      "step": 280
    },
    {
      "epoch": 4.827586206896552,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.033477574586868286,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.1639,
      "eval_samples_per_second": 2.853,
      "eval_steps_per_second": 1.476,
      "step": 280
    },
    {
      "epoch": 4.844827586206897,
      "grad_norm": 0.33115124702453613,
      "learning_rate": 5.418620689655173e-05,
      "loss": 0.0269,
      "step": 281
    },
    {
      "epoch": 4.862068965517241,
      "grad_norm": 0.38353630900382996,
      "learning_rate": 5.416551724137931e-05,
      "loss": 0.0465,
      "step": 282
    },
    {
      "epoch": 4.879310344827586,
      "grad_norm": 0.5096092820167542,
      "learning_rate": 5.4144827586206896e-05,
      "loss": 0.0404,
      "step": 283
    },
    {
      "epoch": 4.896551724137931,
      "grad_norm": 0.4371567964553833,
      "learning_rate": 5.4124137931034486e-05,
      "loss": 0.0352,
      "step": 284
    },
    {
      "epoch": 4.913793103448276,
      "grad_norm": 0.29446449875831604,
      "learning_rate": 5.410344827586207e-05,
      "loss": 0.0305,
      "step": 285
    },
    {
      "epoch": 4.931034482758621,
      "grad_norm": 0.4623910188674927,
      "learning_rate": 5.408275862068965e-05,
      "loss": 0.05,
      "step": 286
    },
    {
      "epoch": 4.948275862068965,
      "grad_norm": 0.39413976669311523,
      "learning_rate": 5.406206896551724e-05,
      "loss": 0.0382,
      "step": 287
    },
    {
      "epoch": 4.9655172413793105,
      "grad_norm": 0.40210863947868347,
      "learning_rate": 5.404137931034483e-05,
      "loss": 0.0398,
      "step": 288
    },
    {
      "epoch": 4.982758620689655,
      "grad_norm": 0.307819664478302,
      "learning_rate": 5.4020689655172415e-05,
      "loss": 0.0331,
      "step": 289
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.28444549441337585,
      "learning_rate": 5.4000000000000005e-05,
      "loss": 0.026,
      "step": 290
    },
    {
      "epoch": 5.017241379310345,
      "grad_norm": 0.683024525642395,
      "learning_rate": 5.397931034482759e-05,
      "loss": 0.0456,
      "step": 291
    },
    {
      "epoch": 5.0344827586206895,
      "grad_norm": 0.976270854473114,
      "learning_rate": 5.395862068965517e-05,
      "loss": 0.049,
      "step": 292
    },
    {
      "epoch": 5.051724137931035,
      "grad_norm": 0.3476439416408539,
      "learning_rate": 5.393793103448276e-05,
      "loss": 0.0303,
      "step": 293
    },
    {
      "epoch": 5.068965517241379,
      "grad_norm": 0.27422472834587097,
      "learning_rate": 5.3917241379310344e-05,
      "loss": 0.0248,
      "step": 294
    },
    {
      "epoch": 5.086206896551724,
      "grad_norm": 0.3584373891353607,
      "learning_rate": 5.389655172413793e-05,
      "loss": 0.0295,
      "step": 295
    },
    {
      "epoch": 5.103448275862069,
      "grad_norm": 0.40137749910354614,
      "learning_rate": 5.387586206896552e-05,
      "loss": 0.0414,
      "step": 296
    },
    {
      "epoch": 5.120689655172414,
      "grad_norm": 0.3075878322124481,
      "learning_rate": 5.385517241379311e-05,
      "loss": 0.0308,
      "step": 297
    },
    {
      "epoch": 5.137931034482759,
      "grad_norm": 0.3426832854747772,
      "learning_rate": 5.383448275862069e-05,
      "loss": 0.0393,
      "step": 298
    },
    {
      "epoch": 5.155172413793103,
      "grad_norm": 0.3657054305076599,
      "learning_rate": 5.381379310344828e-05,
      "loss": 0.0358,
      "step": 299
    },
    {
      "epoch": 5.172413793103448,
      "grad_norm": 0.4037117063999176,
      "learning_rate": 5.379310344827586e-05,
      "loss": 0.0473,
      "step": 300
    },
    {
      "epoch": 5.172413793103448,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.02786502055823803,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.0373,
      "eval_samples_per_second": 2.627,
      "eval_steps_per_second": 1.359,
      "step": 300
    },
    {
      "epoch": 5.189655172413793,
      "grad_norm": 0.2899741232395172,
      "learning_rate": 5.377241379310345e-05,
      "loss": 0.0251,
      "step": 301
    },
    {
      "epoch": 5.206896551724138,
      "grad_norm": 0.4486085772514343,
      "learning_rate": 5.3751724137931036e-05,
      "loss": 0.0415,
      "step": 302
    },
    {
      "epoch": 5.224137931034483,
      "grad_norm": 0.28046953678131104,
      "learning_rate": 5.373103448275862e-05,
      "loss": 0.0308,
      "step": 303
    },
    {
      "epoch": 5.241379310344827,
      "grad_norm": 0.3785065710544586,
      "learning_rate": 5.371034482758621e-05,
      "loss": 0.0334,
      "step": 304
    },
    {
      "epoch": 5.258620689655173,
      "grad_norm": 0.3124459385871887,
      "learning_rate": 5.368965517241379e-05,
      "loss": 0.0303,
      "step": 305
    },
    {
      "epoch": 5.275862068965517,
      "grad_norm": 0.4521750807762146,
      "learning_rate": 5.3668965517241376e-05,
      "loss": 0.0391,
      "step": 306
    },
    {
      "epoch": 5.293103448275862,
      "grad_norm": 0.3753528892993927,
      "learning_rate": 5.364827586206897e-05,
      "loss": 0.0305,
      "step": 307
    },
    {
      "epoch": 5.310344827586207,
      "grad_norm": 0.47079795598983765,
      "learning_rate": 5.3627586206896555e-05,
      "loss": 0.0275,
      "step": 308
    },
    {
      "epoch": 5.327586206896552,
      "grad_norm": 0.3681400418281555,
      "learning_rate": 5.360689655172414e-05,
      "loss": 0.0294,
      "step": 309
    },
    {
      "epoch": 5.344827586206897,
      "grad_norm": 0.7861365079879761,
      "learning_rate": 5.358620689655173e-05,
      "loss": 0.0428,
      "step": 310
    },
    {
      "epoch": 5.362068965517241,
      "grad_norm": 0.2507886290550232,
      "learning_rate": 5.356551724137931e-05,
      "loss": 0.0266,
      "step": 311
    },
    {
      "epoch": 5.379310344827586,
      "grad_norm": 0.30066731572151184,
      "learning_rate": 5.3544827586206895e-05,
      "loss": 0.0302,
      "step": 312
    },
    {
      "epoch": 5.396551724137931,
      "grad_norm": 0.28458765149116516,
      "learning_rate": 5.3524137931034485e-05,
      "loss": 0.0166,
      "step": 313
    },
    {
      "epoch": 5.413793103448276,
      "grad_norm": 0.2952478528022766,
      "learning_rate": 5.350344827586207e-05,
      "loss": 0.0314,
      "step": 314
    },
    {
      "epoch": 5.431034482758621,
      "grad_norm": 0.365121454000473,
      "learning_rate": 5.348275862068965e-05,
      "loss": 0.034,
      "step": 315
    },
    {
      "epoch": 5.448275862068965,
      "grad_norm": 0.2931821942329407,
      "learning_rate": 5.346206896551725e-05,
      "loss": 0.0352,
      "step": 316
    },
    {
      "epoch": 5.4655172413793105,
      "grad_norm": 0.31730231642723083,
      "learning_rate": 5.344137931034483e-05,
      "loss": 0.0303,
      "step": 317
    },
    {
      "epoch": 5.482758620689655,
      "grad_norm": 0.33269211649894714,
      "learning_rate": 5.3420689655172414e-05,
      "loss": 0.0343,
      "step": 318
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.2816880941390991,
      "learning_rate": 5.3400000000000004e-05,
      "loss": 0.0292,
      "step": 319
    },
    {
      "epoch": 5.517241379310345,
      "grad_norm": 0.32201558351516724,
      "learning_rate": 5.337931034482759e-05,
      "loss": 0.0339,
      "step": 320
    },
    {
      "epoch": 5.517241379310345,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.022650472819805145,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.7808,
      "eval_samples_per_second": 2.462,
      "eval_steps_per_second": 1.273,
      "step": 320
    },
    {
      "epoch": 5.5344827586206895,
      "grad_norm": 0.33829009532928467,
      "learning_rate": 5.335862068965517e-05,
      "loss": 0.037,
      "step": 321
    },
    {
      "epoch": 5.551724137931035,
      "grad_norm": 0.44403165578842163,
      "learning_rate": 5.333793103448276e-05,
      "loss": 0.0344,
      "step": 322
    },
    {
      "epoch": 5.568965517241379,
      "grad_norm": 0.30891144275665283,
      "learning_rate": 5.331724137931034e-05,
      "loss": 0.0361,
      "step": 323
    },
    {
      "epoch": 5.586206896551724,
      "grad_norm": 0.26412686705589294,
      "learning_rate": 5.329655172413793e-05,
      "loss": 0.0281,
      "step": 324
    },
    {
      "epoch": 5.603448275862069,
      "grad_norm": 0.3058971166610718,
      "learning_rate": 5.327586206896552e-05,
      "loss": 0.0321,
      "step": 325
    },
    {
      "epoch": 5.620689655172414,
      "grad_norm": 0.33877798914909363,
      "learning_rate": 5.3255172413793106e-05,
      "loss": 0.0314,
      "step": 326
    },
    {
      "epoch": 5.637931034482759,
      "grad_norm": 0.494756281375885,
      "learning_rate": 5.3234482758620696e-05,
      "loss": 0.0369,
      "step": 327
    },
    {
      "epoch": 5.655172413793103,
      "grad_norm": 0.30220919847488403,
      "learning_rate": 5.321379310344828e-05,
      "loss": 0.0365,
      "step": 328
    },
    {
      "epoch": 5.672413793103448,
      "grad_norm": 0.2653290033340454,
      "learning_rate": 5.319310344827586e-05,
      "loss": 0.0269,
      "step": 329
    },
    {
      "epoch": 5.689655172413794,
      "grad_norm": 0.2724582850933075,
      "learning_rate": 5.317241379310345e-05,
      "loss": 0.0273,
      "step": 330
    },
    {
      "epoch": 5.706896551724138,
      "grad_norm": 0.20497731864452362,
      "learning_rate": 5.3151724137931035e-05,
      "loss": 0.0214,
      "step": 331
    },
    {
      "epoch": 5.724137931034483,
      "grad_norm": 0.5384578108787537,
      "learning_rate": 5.313103448275862e-05,
      "loss": 0.0402,
      "step": 332
    },
    {
      "epoch": 5.741379310344827,
      "grad_norm": 0.27954307198524475,
      "learning_rate": 5.311034482758621e-05,
      "loss": 0.0244,
      "step": 333
    },
    {
      "epoch": 5.758620689655173,
      "grad_norm": 0.3115442395210266,
      "learning_rate": 5.308965517241379e-05,
      "loss": 0.0307,
      "step": 334
    },
    {
      "epoch": 5.775862068965517,
      "grad_norm": 0.25160202383995056,
      "learning_rate": 5.306896551724138e-05,
      "loss": 0.0258,
      "step": 335
    },
    {
      "epoch": 5.793103448275862,
      "grad_norm": 0.3751257061958313,
      "learning_rate": 5.304827586206897e-05,
      "loss": 0.0444,
      "step": 336
    },
    {
      "epoch": 5.810344827586206,
      "grad_norm": 0.3156359791755676,
      "learning_rate": 5.3027586206896554e-05,
      "loss": 0.0312,
      "step": 337
    },
    {
      "epoch": 5.827586206896552,
      "grad_norm": 0.306465744972229,
      "learning_rate": 5.300689655172414e-05,
      "loss": 0.0274,
      "step": 338
    },
    {
      "epoch": 5.844827586206897,
      "grad_norm": 0.2862413823604584,
      "learning_rate": 5.298620689655173e-05,
      "loss": 0.0311,
      "step": 339
    },
    {
      "epoch": 5.862068965517241,
      "grad_norm": 0.25157275795936584,
      "learning_rate": 5.296551724137931e-05,
      "loss": 0.0245,
      "step": 340
    },
    {
      "epoch": 5.862068965517241,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.023083392530679703,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.4193,
      "eval_samples_per_second": 2.783,
      "eval_steps_per_second": 1.44,
      "step": 340
    },
    {
      "epoch": 5.879310344827586,
      "grad_norm": 0.2574266195297241,
      "learning_rate": 5.2944827586206894e-05,
      "loss": 0.0307,
      "step": 341
    },
    {
      "epoch": 5.896551724137931,
      "grad_norm": 0.2266436368227005,
      "learning_rate": 5.2924137931034484e-05,
      "loss": 0.0225,
      "step": 342
    },
    {
      "epoch": 5.913793103448276,
      "grad_norm": 0.34536677598953247,
      "learning_rate": 5.290344827586207e-05,
      "loss": 0.0285,
      "step": 343
    },
    {
      "epoch": 5.931034482758621,
      "grad_norm": 0.2227519005537033,
      "learning_rate": 5.2882758620689657e-05,
      "loss": 0.0223,
      "step": 344
    },
    {
      "epoch": 5.948275862068965,
      "grad_norm": 0.6141974925994873,
      "learning_rate": 5.2862068965517247e-05,
      "loss": 0.031,
      "step": 345
    },
    {
      "epoch": 5.9655172413793105,
      "grad_norm": 0.33391207456588745,
      "learning_rate": 5.284137931034483e-05,
      "loss": 0.0271,
      "step": 346
    },
    {
      "epoch": 5.982758620689655,
      "grad_norm": 0.3217594623565674,
      "learning_rate": 5.282068965517241e-05,
      "loss": 0.0236,
      "step": 347
    },
    {
      "epoch": 6.0,
      "grad_norm": 0.2823047339916229,
      "learning_rate": 5.28e-05,
      "loss": 0.0243,
      "step": 348
    },
    {
      "epoch": 6.017241379310345,
      "grad_norm": 0.14877086877822876,
      "learning_rate": 5.2779310344827586e-05,
      "loss": 0.0142,
      "step": 349
    },
    {
      "epoch": 6.0344827586206895,
      "grad_norm": 0.6070281863212585,
      "learning_rate": 5.2758620689655176e-05,
      "loss": 0.0482,
      "step": 350
    },
    {
      "epoch": 6.051724137931035,
      "grad_norm": 0.4671691358089447,
      "learning_rate": 5.273793103448276e-05,
      "loss": 0.0343,
      "step": 351
    },
    {
      "epoch": 6.068965517241379,
      "grad_norm": 0.25927630066871643,
      "learning_rate": 5.271724137931034e-05,
      "loss": 0.0255,
      "step": 352
    },
    {
      "epoch": 6.086206896551724,
      "grad_norm": 0.2636919319629669,
      "learning_rate": 5.269655172413793e-05,
      "loss": 0.0229,
      "step": 353
    },
    {
      "epoch": 6.103448275862069,
      "grad_norm": 0.27174806594848633,
      "learning_rate": 5.267586206896552e-05,
      "loss": 0.021,
      "step": 354
    },
    {
      "epoch": 6.120689655172414,
      "grad_norm": 0.23710179328918457,
      "learning_rate": 5.2655172413793105e-05,
      "loss": 0.0216,
      "step": 355
    },
    {
      "epoch": 6.137931034482759,
      "grad_norm": 0.21580813825130463,
      "learning_rate": 5.2634482758620695e-05,
      "loss": 0.0229,
      "step": 356
    },
    {
      "epoch": 6.155172413793103,
      "grad_norm": 0.18879194557666779,
      "learning_rate": 5.261379310344828e-05,
      "loss": 0.0206,
      "step": 357
    },
    {
      "epoch": 6.172413793103448,
      "grad_norm": 0.34553995728492737,
      "learning_rate": 5.259310344827586e-05,
      "loss": 0.0336,
      "step": 358
    },
    {
      "epoch": 6.189655172413793,
      "grad_norm": 0.26065224409103394,
      "learning_rate": 5.257241379310345e-05,
      "loss": 0.0305,
      "step": 359
    },
    {
      "epoch": 6.206896551724138,
      "grad_norm": 0.2570841908454895,
      "learning_rate": 5.2551724137931034e-05,
      "loss": 0.026,
      "step": 360
    },
    {
      "epoch": 6.206896551724138,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.01856156811118126,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.7534,
      "eval_samples_per_second": 2.697,
      "eval_steps_per_second": 1.395,
      "step": 360
    },
    {
      "epoch": 6.224137931034483,
      "grad_norm": 0.35646694898605347,
      "learning_rate": 5.253103448275862e-05,
      "loss": 0.0319,
      "step": 361
    },
    {
      "epoch": 6.241379310344827,
      "grad_norm": 0.3401006758213043,
      "learning_rate": 5.251034482758621e-05,
      "loss": 0.0251,
      "step": 362
    },
    {
      "epoch": 6.258620689655173,
      "grad_norm": 0.21078404784202576,
      "learning_rate": 5.24896551724138e-05,
      "loss": 0.0222,
      "step": 363
    },
    {
      "epoch": 6.275862068965517,
      "grad_norm": 0.2798086702823639,
      "learning_rate": 5.246896551724138e-05,
      "loss": 0.0294,
      "step": 364
    },
    {
      "epoch": 6.293103448275862,
      "grad_norm": 0.34711337089538574,
      "learning_rate": 5.244827586206897e-05,
      "loss": 0.0269,
      "step": 365
    },
    {
      "epoch": 6.310344827586207,
      "grad_norm": 0.21023792028427124,
      "learning_rate": 5.242758620689655e-05,
      "loss": 0.0202,
      "step": 366
    },
    {
      "epoch": 6.327586206896552,
      "grad_norm": 0.27903833985328674,
      "learning_rate": 5.2406896551724136e-05,
      "loss": 0.0207,
      "step": 367
    },
    {
      "epoch": 6.344827586206897,
      "grad_norm": 0.16616010665893555,
      "learning_rate": 5.2386206896551726e-05,
      "loss": 0.0158,
      "step": 368
    },
    {
      "epoch": 6.362068965517241,
      "grad_norm": 0.2267519235610962,
      "learning_rate": 5.236551724137931e-05,
      "loss": 0.0251,
      "step": 369
    },
    {
      "epoch": 6.379310344827586,
      "grad_norm": 0.22572468221187592,
      "learning_rate": 5.234482758620689e-05,
      "loss": 0.0256,
      "step": 370
    },
    {
      "epoch": 6.396551724137931,
      "grad_norm": 0.20722869038581848,
      "learning_rate": 5.232413793103448e-05,
      "loss": 0.0165,
      "step": 371
    },
    {
      "epoch": 6.413793103448276,
      "grad_norm": 0.23877644538879395,
      "learning_rate": 5.230344827586207e-05,
      "loss": 0.0201,
      "step": 372
    },
    {
      "epoch": 6.431034482758621,
      "grad_norm": 0.3912339508533478,
      "learning_rate": 5.228275862068966e-05,
      "loss": 0.0292,
      "step": 373
    },
    {
      "epoch": 6.448275862068965,
      "grad_norm": 0.7401291728019714,
      "learning_rate": 5.2262068965517245e-05,
      "loss": 0.0298,
      "step": 374
    },
    {
      "epoch": 6.4655172413793105,
      "grad_norm": 0.218470498919487,
      "learning_rate": 5.224137931034483e-05,
      "loss": 0.0231,
      "step": 375
    },
    {
      "epoch": 6.482758620689655,
      "grad_norm": 0.21689000725746155,
      "learning_rate": 5.222068965517242e-05,
      "loss": 0.0252,
      "step": 376
    },
    {
      "epoch": 6.5,
      "grad_norm": 0.25277864933013916,
      "learning_rate": 5.22e-05,
      "loss": 0.0257,
      "step": 377
    },
    {
      "epoch": 6.517241379310345,
      "grad_norm": 0.22812297940254211,
      "learning_rate": 5.2179310344827585e-05,
      "loss": 0.0212,
      "step": 378
    },
    {
      "epoch": 6.5344827586206895,
      "grad_norm": 0.25889113545417786,
      "learning_rate": 5.2158620689655175e-05,
      "loss": 0.0288,
      "step": 379
    },
    {
      "epoch": 6.551724137931035,
      "grad_norm": 0.2739432156085968,
      "learning_rate": 5.213793103448276e-05,
      "loss": 0.0233,
      "step": 380
    },
    {
      "epoch": 6.551724137931035,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.01761501468718052,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.287,
      "eval_samples_per_second": 2.819,
      "eval_steps_per_second": 1.458,
      "step": 380
    },
    {
      "epoch": 6.568965517241379,
      "grad_norm": 0.2223035842180252,
      "learning_rate": 5.211724137931034e-05,
      "loss": 0.0227,
      "step": 381
    },
    {
      "epoch": 6.586206896551724,
      "grad_norm": 0.4753745496273041,
      "learning_rate": 5.209655172413794e-05,
      "loss": 0.026,
      "step": 382
    },
    {
      "epoch": 6.603448275862069,
      "grad_norm": 0.15094628930091858,
      "learning_rate": 5.207586206896552e-05,
      "loss": 0.0147,
      "step": 383
    },
    {
      "epoch": 6.620689655172414,
      "grad_norm": 0.14222408831119537,
      "learning_rate": 5.2055172413793104e-05,
      "loss": 0.0136,
      "step": 384
    },
    {
      "epoch": 6.637931034482759,
      "grad_norm": 0.193654403090477,
      "learning_rate": 5.2034482758620694e-05,
      "loss": 0.0197,
      "step": 385
    },
    {
      "epoch": 6.655172413793103,
      "grad_norm": 0.20376987755298615,
      "learning_rate": 5.201379310344828e-05,
      "loss": 0.0205,
      "step": 386
    },
    {
      "epoch": 6.672413793103448,
      "grad_norm": 0.42998969554901123,
      "learning_rate": 5.199310344827586e-05,
      "loss": 0.0248,
      "step": 387
    },
    {
      "epoch": 6.689655172413794,
      "grad_norm": 0.28078165650367737,
      "learning_rate": 5.197241379310345e-05,
      "loss": 0.0274,
      "step": 388
    },
    {
      "epoch": 6.706896551724138,
      "grad_norm": 0.25852134823799133,
      "learning_rate": 5.195172413793103e-05,
      "loss": 0.0252,
      "step": 389
    },
    {
      "epoch": 6.724137931034483,
      "grad_norm": 0.438515305519104,
      "learning_rate": 5.1931034482758616e-05,
      "loss": 0.0248,
      "step": 390
    },
    {
      "epoch": 6.741379310344827,
      "grad_norm": 0.17251285910606384,
      "learning_rate": 5.191034482758621e-05,
      "loss": 0.0147,
      "step": 391
    },
    {
      "epoch": 6.758620689655173,
      "grad_norm": 0.24103064835071564,
      "learning_rate": 5.1889655172413796e-05,
      "loss": 0.0177,
      "step": 392
    },
    {
      "epoch": 6.775862068965517,
      "grad_norm": 0.21807676553726196,
      "learning_rate": 5.186896551724138e-05,
      "loss": 0.026,
      "step": 393
    },
    {
      "epoch": 6.793103448275862,
      "grad_norm": 0.16517196595668793,
      "learning_rate": 5.184827586206897e-05,
      "loss": 0.0172,
      "step": 394
    },
    {
      "epoch": 6.810344827586206,
      "grad_norm": 0.20862722396850586,
      "learning_rate": 5.182758620689655e-05,
      "loss": 0.0187,
      "step": 395
    },
    {
      "epoch": 6.827586206896552,
      "grad_norm": 0.20563340187072754,
      "learning_rate": 5.180689655172414e-05,
      "loss": 0.0211,
      "step": 396
    },
    {
      "epoch": 6.844827586206897,
      "grad_norm": 0.27035096287727356,
      "learning_rate": 5.1786206896551725e-05,
      "loss": 0.0198,
      "step": 397
    },
    {
      "epoch": 6.862068965517241,
      "grad_norm": 0.34855177998542786,
      "learning_rate": 5.176551724137931e-05,
      "loss": 0.0237,
      "step": 398
    },
    {
      "epoch": 6.879310344827586,
      "grad_norm": 0.2220216542482376,
      "learning_rate": 5.17448275862069e-05,
      "loss": 0.018,
      "step": 399
    },
    {
      "epoch": 6.896551724137931,
      "grad_norm": 0.19845208525657654,
      "learning_rate": 5.172413793103448e-05,
      "loss": 0.0225,
      "step": 400
    },
    {
      "epoch": 6.896551724137931,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.01803029142320156,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.4272,
      "eval_samples_per_second": 2.538,
      "eval_steps_per_second": 1.313,
      "step": 400
    },
    {
      "epoch": 6.913793103448276,
      "grad_norm": 0.30963897705078125,
      "learning_rate": 5.170344827586207e-05,
      "loss": 0.0222,
      "step": 401
    },
    {
      "epoch": 6.931034482758621,
      "grad_norm": 0.315242737531662,
      "learning_rate": 5.168275862068966e-05,
      "loss": 0.0212,
      "step": 402
    },
    {
      "epoch": 6.948275862068965,
      "grad_norm": 0.40622904896736145,
      "learning_rate": 5.1662068965517244e-05,
      "loss": 0.023,
      "step": 403
    },
    {
      "epoch": 6.9655172413793105,
      "grad_norm": 0.2109271138906479,
      "learning_rate": 5.164137931034483e-05,
      "loss": 0.0181,
      "step": 404
    },
    {
      "epoch": 6.982758620689655,
      "grad_norm": 0.32006901502609253,
      "learning_rate": 5.162068965517242e-05,
      "loss": 0.0299,
      "step": 405
    },
    {
      "epoch": 7.0,
      "grad_norm": 0.21014130115509033,
      "learning_rate": 5.16e-05,
      "loss": 0.0185,
      "step": 406
    },
    {
      "epoch": 7.017241379310345,
      "grad_norm": 0.26372653245925903,
      "learning_rate": 5.1579310344827584e-05,
      "loss": 0.0208,
      "step": 407
    },
    {
      "epoch": 7.0344827586206895,
      "grad_norm": 0.31574904918670654,
      "learning_rate": 5.1558620689655174e-05,
      "loss": 0.026,
      "step": 408
    },
    {
      "epoch": 7.051724137931035,
      "grad_norm": 0.1720011979341507,
      "learning_rate": 5.153793103448276e-05,
      "loss": 0.0163,
      "step": 409
    },
    {
      "epoch": 7.068965517241379,
      "grad_norm": 0.4777359664440155,
      "learning_rate": 5.151724137931035e-05,
      "loss": 0.0311,
      "step": 410
    },
    {
      "epoch": 7.086206896551724,
      "grad_norm": 0.20576970279216766,
      "learning_rate": 5.149655172413794e-05,
      "loss": 0.0168,
      "step": 411
    },
    {
      "epoch": 7.103448275862069,
      "grad_norm": 0.11086823791265488,
      "learning_rate": 5.147586206896552e-05,
      "loss": 0.0096,
      "step": 412
    },
    {
      "epoch": 7.120689655172414,
      "grad_norm": 0.19915856420993805,
      "learning_rate": 5.14551724137931e-05,
      "loss": 0.0207,
      "step": 413
    },
    {
      "epoch": 7.137931034482759,
      "grad_norm": 0.22314514219760895,
      "learning_rate": 5.143448275862069e-05,
      "loss": 0.0163,
      "step": 414
    },
    {
      "epoch": 7.155172413793103,
      "grad_norm": 1.7573009729385376,
      "learning_rate": 5.1413793103448276e-05,
      "loss": 0.0464,
      "step": 415
    },
    {
      "epoch": 7.172413793103448,
      "grad_norm": 0.17384935915470123,
      "learning_rate": 5.139310344827586e-05,
      "loss": 0.019,
      "step": 416
    },
    {
      "epoch": 7.189655172413793,
      "grad_norm": 0.1957685798406601,
      "learning_rate": 5.137241379310345e-05,
      "loss": 0.0161,
      "step": 417
    },
    {
      "epoch": 7.206896551724138,
      "grad_norm": 0.3859691619873047,
      "learning_rate": 5.135172413793103e-05,
      "loss": 0.0239,
      "step": 418
    },
    {
      "epoch": 7.224137931034483,
      "grad_norm": 0.2808227241039276,
      "learning_rate": 5.133103448275862e-05,
      "loss": 0.0218,
      "step": 419
    },
    {
      "epoch": 7.241379310344827,
      "grad_norm": 0.1558932214975357,
      "learning_rate": 5.131034482758621e-05,
      "loss": 0.0161,
      "step": 420
    },
    {
      "epoch": 7.241379310344827,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.01634497195482254,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.6141,
      "eval_samples_per_second": 2.299,
      "eval_steps_per_second": 1.189,
      "step": 420
    },
    {
      "epoch": 7.258620689655173,
      "grad_norm": 0.2244553565979004,
      "learning_rate": 5.1289655172413795e-05,
      "loss": 0.0154,
      "step": 421
    },
    {
      "epoch": 7.275862068965517,
      "grad_norm": 0.2889550030231476,
      "learning_rate": 5.1268965517241385e-05,
      "loss": 0.0252,
      "step": 422
    },
    {
      "epoch": 7.293103448275862,
      "grad_norm": 0.2518507242202759,
      "learning_rate": 5.124827586206897e-05,
      "loss": 0.0232,
      "step": 423
    },
    {
      "epoch": 7.310344827586207,
      "grad_norm": 0.641342282295227,
      "learning_rate": 5.122758620689655e-05,
      "loss": 0.0203,
      "step": 424
    },
    {
      "epoch": 7.327586206896552,
      "grad_norm": 0.20518875122070312,
      "learning_rate": 5.120689655172414e-05,
      "loss": 0.0208,
      "step": 425
    },
    {
      "epoch": 7.344827586206897,
      "grad_norm": 0.6534884572029114,
      "learning_rate": 5.1186206896551724e-05,
      "loss": 0.0229,
      "step": 426
    },
    {
      "epoch": 7.362068965517241,
      "grad_norm": 0.3376332223415375,
      "learning_rate": 5.116551724137931e-05,
      "loss": 0.027,
      "step": 427
    },
    {
      "epoch": 7.379310344827586,
      "grad_norm": 0.9862952828407288,
      "learning_rate": 5.11448275862069e-05,
      "loss": 0.033,
      "step": 428
    },
    {
      "epoch": 7.396551724137931,
      "grad_norm": 0.2077876180410385,
      "learning_rate": 5.112413793103449e-05,
      "loss": 0.0224,
      "step": 429
    },
    {
      "epoch": 7.413793103448276,
      "grad_norm": 0.22240984439849854,
      "learning_rate": 5.110344827586207e-05,
      "loss": 0.0193,
      "step": 430
    },
    {
      "epoch": 7.431034482758621,
      "grad_norm": 0.2326202243566513,
      "learning_rate": 5.108275862068966e-05,
      "loss": 0.0181,
      "step": 431
    },
    {
      "epoch": 7.448275862068965,
      "grad_norm": 0.15931278467178345,
      "learning_rate": 5.1062068965517243e-05,
      "loss": 0.0172,
      "step": 432
    },
    {
      "epoch": 7.4655172413793105,
      "grad_norm": 0.22697092592716217,
      "learning_rate": 5.1041379310344827e-05,
      "loss": 0.0202,
      "step": 433
    },
    {
      "epoch": 7.482758620689655,
      "grad_norm": 0.18561607599258423,
      "learning_rate": 5.1020689655172416e-05,
      "loss": 0.0169,
      "step": 434
    },
    {
      "epoch": 7.5,
      "grad_norm": 0.45129531621932983,
      "learning_rate": 5.1e-05,
      "loss": 0.0339,
      "step": 435
    },
    {
      "epoch": 7.517241379310345,
      "grad_norm": 0.22984899580478668,
      "learning_rate": 5.097931034482758e-05,
      "loss": 0.0146,
      "step": 436
    },
    {
      "epoch": 7.5344827586206895,
      "grad_norm": 0.17749497294425964,
      "learning_rate": 5.095862068965517e-05,
      "loss": 0.0142,
      "step": 437
    },
    {
      "epoch": 7.551724137931035,
      "grad_norm": 0.20217251777648926,
      "learning_rate": 5.093793103448276e-05,
      "loss": 0.0172,
      "step": 438
    },
    {
      "epoch": 7.568965517241379,
      "grad_norm": 0.19251024723052979,
      "learning_rate": 5.0917241379310346e-05,
      "loss": 0.0171,
      "step": 439
    },
    {
      "epoch": 7.586206896551724,
      "grad_norm": 0.1889643669128418,
      "learning_rate": 5.0896551724137936e-05,
      "loss": 0.0177,
      "step": 440
    },
    {
      "epoch": 7.586206896551724,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.017212949693202972,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.1455,
      "eval_samples_per_second": 2.602,
      "eval_steps_per_second": 1.346,
      "step": 440
    },
    {
      "epoch": 7.603448275862069,
      "grad_norm": 0.21185895800590515,
      "learning_rate": 5.087586206896552e-05,
      "loss": 0.0188,
      "step": 441
    },
    {
      "epoch": 7.620689655172414,
      "grad_norm": 0.22073955833911896,
      "learning_rate": 5.08551724137931e-05,
      "loss": 0.0149,
      "step": 442
    },
    {
      "epoch": 7.637931034482759,
      "grad_norm": 0.14359809458255768,
      "learning_rate": 5.083448275862069e-05,
      "loss": 0.0123,
      "step": 443
    },
    {
      "epoch": 7.655172413793103,
      "grad_norm": 0.17200058698654175,
      "learning_rate": 5.0813793103448275e-05,
      "loss": 0.0123,
      "step": 444
    },
    {
      "epoch": 7.672413793103448,
      "grad_norm": 0.2206002175807953,
      "learning_rate": 5.0793103448275865e-05,
      "loss": 0.0191,
      "step": 445
    },
    {
      "epoch": 7.689655172413794,
      "grad_norm": 0.14701026678085327,
      "learning_rate": 5.077241379310345e-05,
      "loss": 0.0134,
      "step": 446
    },
    {
      "epoch": 7.706896551724138,
      "grad_norm": 0.13556043803691864,
      "learning_rate": 5.075172413793103e-05,
      "loss": 0.0137,
      "step": 447
    },
    {
      "epoch": 7.724137931034483,
      "grad_norm": 0.13578130304813385,
      "learning_rate": 5.073103448275863e-05,
      "loss": 0.0127,
      "step": 448
    },
    {
      "epoch": 7.741379310344827,
      "grad_norm": 0.20098184049129486,
      "learning_rate": 5.071034482758621e-05,
      "loss": 0.0176,
      "step": 449
    },
    {
      "epoch": 7.758620689655173,
      "grad_norm": 0.4409424066543579,
      "learning_rate": 5.0689655172413794e-05,
      "loss": 0.0308,
      "step": 450
    },
    {
      "epoch": 7.775862068965517,
      "grad_norm": 0.22093766927719116,
      "learning_rate": 5.0668965517241384e-05,
      "loss": 0.0207,
      "step": 451
    },
    {
      "epoch": 7.793103448275862,
      "grad_norm": 0.47442626953125,
      "learning_rate": 5.064827586206897e-05,
      "loss": 0.0177,
      "step": 452
    },
    {
      "epoch": 7.810344827586206,
      "grad_norm": 0.14489848911762238,
      "learning_rate": 5.062758620689655e-05,
      "loss": 0.0148,
      "step": 453
    },
    {
      "epoch": 7.827586206896552,
      "grad_norm": 0.28335070610046387,
      "learning_rate": 5.060689655172414e-05,
      "loss": 0.0162,
      "step": 454
    },
    {
      "epoch": 7.844827586206897,
      "grad_norm": 0.3026646077632904,
      "learning_rate": 5.058620689655172e-05,
      "loss": 0.0151,
      "step": 455
    },
    {
      "epoch": 7.862068965517241,
      "grad_norm": 0.6402007341384888,
      "learning_rate": 5.0565517241379306e-05,
      "loss": 0.0214,
      "step": 456
    },
    {
      "epoch": 7.879310344827586,
      "grad_norm": 0.1310076266527176,
      "learning_rate": 5.05448275862069e-05,
      "loss": 0.0131,
      "step": 457
    },
    {
      "epoch": 7.896551724137931,
      "grad_norm": 0.18966878950595856,
      "learning_rate": 5.0524137931034486e-05,
      "loss": 0.0172,
      "step": 458
    },
    {
      "epoch": 7.913793103448276,
      "grad_norm": 0.48458775877952576,
      "learning_rate": 5.050344827586207e-05,
      "loss": 0.0245,
      "step": 459
    },
    {
      "epoch": 7.931034482758621,
      "grad_norm": 0.16400963068008423,
      "learning_rate": 5.048275862068966e-05,
      "loss": 0.0161,
      "step": 460
    },
    {
      "epoch": 7.931034482758621,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.013942962512373924,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.8352,
      "eval_samples_per_second": 3.282,
      "eval_steps_per_second": 1.698,
      "step": 460
    },
    {
      "epoch": 7.948275862068965,
      "grad_norm": 0.1333656907081604,
      "learning_rate": 5.046206896551724e-05,
      "loss": 0.0139,
      "step": 461
    },
    {
      "epoch": 7.9655172413793105,
      "grad_norm": 0.20892395079135895,
      "learning_rate": 5.0441379310344826e-05,
      "loss": 0.0148,
      "step": 462
    },
    {
      "epoch": 7.982758620689655,
      "grad_norm": 0.2510095238685608,
      "learning_rate": 5.0420689655172415e-05,
      "loss": 0.0151,
      "step": 463
    },
    {
      "epoch": 8.0,
      "grad_norm": 0.20659402012825012,
      "learning_rate": 5.04e-05,
      "loss": 0.0196,
      "step": 464
    },
    {
      "epoch": 8.017241379310345,
      "grad_norm": 0.1779901534318924,
      "learning_rate": 5.037931034482758e-05,
      "loss": 0.0173,
      "step": 465
    },
    {
      "epoch": 8.03448275862069,
      "grad_norm": 0.20169053971767426,
      "learning_rate": 5.035862068965517e-05,
      "loss": 0.0195,
      "step": 466
    },
    {
      "epoch": 8.051724137931034,
      "grad_norm": 0.34394335746765137,
      "learning_rate": 5.033793103448276e-05,
      "loss": 0.019,
      "step": 467
    },
    {
      "epoch": 8.068965517241379,
      "grad_norm": 0.1648019403219223,
      "learning_rate": 5.031724137931035e-05,
      "loss": 0.0115,
      "step": 468
    },
    {
      "epoch": 8.086206896551724,
      "grad_norm": 0.15097613632678986,
      "learning_rate": 5.0296551724137935e-05,
      "loss": 0.0159,
      "step": 469
    },
    {
      "epoch": 8.10344827586207,
      "grad_norm": 0.15467993915081024,
      "learning_rate": 5.027586206896552e-05,
      "loss": 0.0153,
      "step": 470
    },
    {
      "epoch": 8.120689655172415,
      "grad_norm": 0.14607936143875122,
      "learning_rate": 5.025517241379311e-05,
      "loss": 0.0122,
      "step": 471
    },
    {
      "epoch": 8.137931034482758,
      "grad_norm": 0.17154307663440704,
      "learning_rate": 5.023448275862069e-05,
      "loss": 0.0105,
      "step": 472
    },
    {
      "epoch": 8.155172413793103,
      "grad_norm": 0.1666453778743744,
      "learning_rate": 5.0213793103448274e-05,
      "loss": 0.0137,
      "step": 473
    },
    {
      "epoch": 8.172413793103448,
      "grad_norm": 0.45165756344795227,
      "learning_rate": 5.0193103448275864e-05,
      "loss": 0.0203,
      "step": 474
    },
    {
      "epoch": 8.189655172413794,
      "grad_norm": 0.22099028527736664,
      "learning_rate": 5.017241379310345e-05,
      "loss": 0.021,
      "step": 475
    },
    {
      "epoch": 8.206896551724139,
      "grad_norm": 0.18128174543380737,
      "learning_rate": 5.015172413793104e-05,
      "loss": 0.0162,
      "step": 476
    },
    {
      "epoch": 8.224137931034482,
      "grad_norm": 0.15096566081047058,
      "learning_rate": 5.013103448275863e-05,
      "loss": 0.0169,
      "step": 477
    },
    {
      "epoch": 8.241379310344827,
      "grad_norm": 0.16985498368740082,
      "learning_rate": 5.011034482758621e-05,
      "loss": 0.0183,
      "step": 478
    },
    {
      "epoch": 8.258620689655173,
      "grad_norm": 0.27586719393730164,
      "learning_rate": 5.008965517241379e-05,
      "loss": 0.0172,
      "step": 479
    },
    {
      "epoch": 8.275862068965518,
      "grad_norm": 0.24368423223495483,
      "learning_rate": 5.006896551724138e-05,
      "loss": 0.0163,
      "step": 480
    },
    {
      "epoch": 8.275862068965518,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.014171150512993336,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.3652,
      "eval_samples_per_second": 3.097,
      "eval_steps_per_second": 1.602,
      "step": 480
    },
    {
      "epoch": 8.293103448275861,
      "grad_norm": 0.14928624033927917,
      "learning_rate": 5.0048275862068966e-05,
      "loss": 0.0116,
      "step": 481
    },
    {
      "epoch": 8.310344827586206,
      "grad_norm": 0.24641719460487366,
      "learning_rate": 5.002758620689655e-05,
      "loss": 0.018,
      "step": 482
    },
    {
      "epoch": 8.327586206896552,
      "grad_norm": 9.514791488647461,
      "learning_rate": 5.000689655172414e-05,
      "loss": 0.0302,
      "step": 483
    },
    {
      "epoch": 8.344827586206897,
      "grad_norm": 0.16798914968967438,
      "learning_rate": 4.998620689655172e-05,
      "loss": 0.0181,
      "step": 484
    },
    {
      "epoch": 8.362068965517242,
      "grad_norm": 0.11700811237096786,
      "learning_rate": 4.996551724137931e-05,
      "loss": 0.011,
      "step": 485
    },
    {
      "epoch": 8.379310344827585,
      "grad_norm": 0.22950425744056702,
      "learning_rate": 4.99448275862069e-05,
      "loss": 0.0132,
      "step": 486
    },
    {
      "epoch": 8.39655172413793,
      "grad_norm": 0.19267135858535767,
      "learning_rate": 4.9924137931034485e-05,
      "loss": 0.017,
      "step": 487
    },
    {
      "epoch": 8.413793103448276,
      "grad_norm": 0.1739756017923355,
      "learning_rate": 4.990344827586207e-05,
      "loss": 0.0177,
      "step": 488
    },
    {
      "epoch": 8.431034482758621,
      "grad_norm": 0.13723866641521454,
      "learning_rate": 4.988275862068966e-05,
      "loss": 0.0107,
      "step": 489
    },
    {
      "epoch": 8.448275862068966,
      "grad_norm": 0.09836903214454651,
      "learning_rate": 4.986206896551724e-05,
      "loss": 0.0102,
      "step": 490
    },
    {
      "epoch": 8.46551724137931,
      "grad_norm": 0.5350843667984009,
      "learning_rate": 4.9841379310344824e-05,
      "loss": 0.0304,
      "step": 491
    },
    {
      "epoch": 8.482758620689655,
      "grad_norm": 0.14522357285022736,
      "learning_rate": 4.9820689655172414e-05,
      "loss": 0.0127,
      "step": 492
    },
    {
      "epoch": 8.5,
      "grad_norm": 0.17995499074459076,
      "learning_rate": 4.98e-05,
      "loss": 0.0173,
      "step": 493
    },
    {
      "epoch": 8.517241379310345,
      "grad_norm": 0.3452547490596771,
      "learning_rate": 4.977931034482759e-05,
      "loss": 0.0156,
      "step": 494
    },
    {
      "epoch": 8.53448275862069,
      "grad_norm": 0.1990128755569458,
      "learning_rate": 4.975862068965518e-05,
      "loss": 0.019,
      "step": 495
    },
    {
      "epoch": 8.551724137931034,
      "grad_norm": 0.2596510946750641,
      "learning_rate": 4.973793103448276e-05,
      "loss": 0.0106,
      "step": 496
    },
    {
      "epoch": 8.568965517241379,
      "grad_norm": 0.17221014201641083,
      "learning_rate": 4.971724137931035e-05,
      "loss": 0.0117,
      "step": 497
    },
    {
      "epoch": 8.586206896551724,
      "grad_norm": 0.19464470446109772,
      "learning_rate": 4.9696551724137934e-05,
      "loss": 0.0135,
      "step": 498
    },
    {
      "epoch": 8.60344827586207,
      "grad_norm": 0.1222357302904129,
      "learning_rate": 4.967586206896552e-05,
      "loss": 0.0115,
      "step": 499
    },
    {
      "epoch": 8.620689655172415,
      "grad_norm": 0.15870583057403564,
      "learning_rate": 4.9655172413793107e-05,
      "loss": 0.0113,
      "step": 500
    },
    {
      "epoch": 8.620689655172415,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.011750873178243637,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.9869,
      "eval_samples_per_second": 2.904,
      "eval_steps_per_second": 1.502,
      "step": 500
    },
    {
      "epoch": 8.637931034482758,
      "grad_norm": 0.1809319108724594,
      "learning_rate": 4.963448275862069e-05,
      "loss": 0.0127,
      "step": 501
    },
    {
      "epoch": 8.655172413793103,
      "grad_norm": 0.2731976807117462,
      "learning_rate": 4.961379310344827e-05,
      "loss": 0.0154,
      "step": 502
    },
    {
      "epoch": 8.672413793103448,
      "grad_norm": 0.15337498486042023,
      "learning_rate": 4.959310344827586e-05,
      "loss": 0.0119,
      "step": 503
    },
    {
      "epoch": 8.689655172413794,
      "grad_norm": 0.1408635824918747,
      "learning_rate": 4.957241379310345e-05,
      "loss": 0.0129,
      "step": 504
    },
    {
      "epoch": 8.706896551724139,
      "grad_norm": 0.5165838599205017,
      "learning_rate": 4.9551724137931036e-05,
      "loss": 0.0171,
      "step": 505
    },
    {
      "epoch": 8.724137931034482,
      "grad_norm": 0.14059516787528992,
      "learning_rate": 4.9531034482758626e-05,
      "loss": 0.0136,
      "step": 506
    },
    {
      "epoch": 8.741379310344827,
      "grad_norm": 0.28639334440231323,
      "learning_rate": 4.951034482758621e-05,
      "loss": 0.0221,
      "step": 507
    },
    {
      "epoch": 8.758620689655173,
      "grad_norm": 0.23987770080566406,
      "learning_rate": 4.948965517241379e-05,
      "loss": 0.0158,
      "step": 508
    },
    {
      "epoch": 8.775862068965518,
      "grad_norm": 0.13428737223148346,
      "learning_rate": 4.946896551724138e-05,
      "loss": 0.0105,
      "step": 509
    },
    {
      "epoch": 8.793103448275861,
      "grad_norm": 0.21840514242649078,
      "learning_rate": 4.9448275862068965e-05,
      "loss": 0.0119,
      "step": 510
    },
    {
      "epoch": 8.810344827586206,
      "grad_norm": 0.16675125062465668,
      "learning_rate": 4.942758620689655e-05,
      "loss": 0.0122,
      "step": 511
    },
    {
      "epoch": 8.827586206896552,
      "grad_norm": 0.14584992825984955,
      "learning_rate": 4.940689655172414e-05,
      "loss": 0.0139,
      "step": 512
    },
    {
      "epoch": 8.844827586206897,
      "grad_norm": 0.08828801661729813,
      "learning_rate": 4.938620689655172e-05,
      "loss": 0.0084,
      "step": 513
    },
    {
      "epoch": 8.862068965517242,
      "grad_norm": 0.13793444633483887,
      "learning_rate": 4.936551724137931e-05,
      "loss": 0.0136,
      "step": 514
    },
    {
      "epoch": 8.879310344827585,
      "grad_norm": 0.1343315839767456,
      "learning_rate": 4.93448275862069e-05,
      "loss": 0.0133,
      "step": 515
    },
    {
      "epoch": 8.89655172413793,
      "grad_norm": 0.10386691242456436,
      "learning_rate": 4.9324137931034484e-05,
      "loss": 0.0072,
      "step": 516
    },
    {
      "epoch": 8.913793103448276,
      "grad_norm": 0.11985239386558533,
      "learning_rate": 4.9303448275862074e-05,
      "loss": 0.0119,
      "step": 517
    },
    {
      "epoch": 8.931034482758621,
      "grad_norm": 0.1211954727768898,
      "learning_rate": 4.928275862068966e-05,
      "loss": 0.01,
      "step": 518
    },
    {
      "epoch": 8.948275862068966,
      "grad_norm": 0.17774537205696106,
      "learning_rate": 4.926206896551724e-05,
      "loss": 0.0122,
      "step": 519
    },
    {
      "epoch": 8.96551724137931,
      "grad_norm": 0.16542530059814453,
      "learning_rate": 4.924137931034483e-05,
      "loss": 0.0097,
      "step": 520
    },
    {
      "epoch": 8.96551724137931,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.009569011628627777,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.2764,
      "eval_samples_per_second": 2.572,
      "eval_steps_per_second": 1.33,
      "step": 520
    },
    {
      "epoch": 8.982758620689655,
      "grad_norm": 0.16955053806304932,
      "learning_rate": 4.922068965517241e-05,
      "loss": 0.0175,
      "step": 521
    },
    {
      "epoch": 9.0,
      "grad_norm": 0.12544754147529602,
      "learning_rate": 4.9199999999999997e-05,
      "loss": 0.0097,
      "step": 522
    },
    {
      "epoch": 9.017241379310345,
      "grad_norm": 0.1286616027355194,
      "learning_rate": 4.917931034482759e-05,
      "loss": 0.0126,
      "step": 523
    },
    {
      "epoch": 9.03448275862069,
      "grad_norm": 0.16995839774608612,
      "learning_rate": 4.9158620689655176e-05,
      "loss": 0.013,
      "step": 524
    },
    {
      "epoch": 9.051724137931034,
      "grad_norm": 0.1637357622385025,
      "learning_rate": 4.913793103448276e-05,
      "loss": 0.0156,
      "step": 525
    },
    {
      "epoch": 9.068965517241379,
      "grad_norm": 0.13900581002235413,
      "learning_rate": 4.911724137931035e-05,
      "loss": 0.0143,
      "step": 526
    },
    {
      "epoch": 9.086206896551724,
      "grad_norm": 0.13867583870887756,
      "learning_rate": 4.909655172413793e-05,
      "loss": 0.0149,
      "step": 527
    },
    {
      "epoch": 9.10344827586207,
      "grad_norm": 0.1433430314064026,
      "learning_rate": 4.9075862068965516e-05,
      "loss": 0.0128,
      "step": 528
    },
    {
      "epoch": 9.120689655172415,
      "grad_norm": 0.2533557116985321,
      "learning_rate": 4.9055172413793106e-05,
      "loss": 0.0166,
      "step": 529
    },
    {
      "epoch": 9.137931034482758,
      "grad_norm": 0.1657966673374176,
      "learning_rate": 4.903448275862069e-05,
      "loss": 0.0103,
      "step": 530
    },
    {
      "epoch": 9.155172413793103,
      "grad_norm": 0.5815431475639343,
      "learning_rate": 4.901379310344827e-05,
      "loss": 0.0178,
      "step": 531
    },
    {
      "epoch": 9.172413793103448,
      "grad_norm": 0.2406262904405594,
      "learning_rate": 4.899310344827587e-05,
      "loss": 0.0124,
      "step": 532
    },
    {
      "epoch": 9.189655172413794,
      "grad_norm": 0.37656906247138977,
      "learning_rate": 4.897241379310345e-05,
      "loss": 0.0243,
      "step": 533
    },
    {
      "epoch": 9.206896551724139,
      "grad_norm": 0.10163791477680206,
      "learning_rate": 4.8951724137931035e-05,
      "loss": 0.0086,
      "step": 534
    },
    {
      "epoch": 9.224137931034482,
      "grad_norm": 0.18000580370426178,
      "learning_rate": 4.8931034482758625e-05,
      "loss": 0.014,
      "step": 535
    },
    {
      "epoch": 9.241379310344827,
      "grad_norm": 0.11096787452697754,
      "learning_rate": 4.891034482758621e-05,
      "loss": 0.0116,
      "step": 536
    },
    {
      "epoch": 9.258620689655173,
      "grad_norm": 0.1863456666469574,
      "learning_rate": 4.888965517241379e-05,
      "loss": 0.0145,
      "step": 537
    },
    {
      "epoch": 9.275862068965518,
      "grad_norm": 0.17737632989883423,
      "learning_rate": 4.886896551724138e-05,
      "loss": 0.0157,
      "step": 538
    },
    {
      "epoch": 9.293103448275861,
      "grad_norm": 0.1239151582121849,
      "learning_rate": 4.8848275862068964e-05,
      "loss": 0.0123,
      "step": 539
    },
    {
      "epoch": 9.310344827586206,
      "grad_norm": 0.2341567575931549,
      "learning_rate": 4.8827586206896554e-05,
      "loss": 0.012,
      "step": 540
    },
    {
      "epoch": 9.310344827586206,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.010668071918189526,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.0355,
      "eval_samples_per_second": 2.89,
      "eval_steps_per_second": 1.495,
      "step": 540
    },
    {
      "epoch": 9.327586206896552,
      "grad_norm": 0.16314902901649475,
      "learning_rate": 4.880689655172414e-05,
      "loss": 0.0125,
      "step": 541
    },
    {
      "epoch": 9.344827586206897,
      "grad_norm": 0.11351571977138519,
      "learning_rate": 4.878620689655173e-05,
      "loss": 0.0112,
      "step": 542
    },
    {
      "epoch": 9.362068965517242,
      "grad_norm": 0.10035400837659836,
      "learning_rate": 4.876551724137932e-05,
      "loss": 0.0106,
      "step": 543
    },
    {
      "epoch": 9.379310344827585,
      "grad_norm": 0.17932860553264618,
      "learning_rate": 4.87448275862069e-05,
      "loss": 0.0142,
      "step": 544
    },
    {
      "epoch": 9.39655172413793,
      "grad_norm": 0.13068664073944092,
      "learning_rate": 4.872413793103448e-05,
      "loss": 0.0117,
      "step": 545
    },
    {
      "epoch": 9.413793103448276,
      "grad_norm": 0.11611271649599075,
      "learning_rate": 4.870344827586207e-05,
      "loss": 0.0101,
      "step": 546
    },
    {
      "epoch": 9.431034482758621,
      "grad_norm": 0.06536392122507095,
      "learning_rate": 4.8682758620689656e-05,
      "loss": 0.0058,
      "step": 547
    },
    {
      "epoch": 9.448275862068966,
      "grad_norm": 0.15262657403945923,
      "learning_rate": 4.866206896551724e-05,
      "loss": 0.0135,
      "step": 548
    },
    {
      "epoch": 9.46551724137931,
      "grad_norm": 0.08255289494991302,
      "learning_rate": 4.864137931034483e-05,
      "loss": 0.0074,
      "step": 549
    },
    {
      "epoch": 9.482758620689655,
      "grad_norm": 0.15980780124664307,
      "learning_rate": 4.862068965517241e-05,
      "loss": 0.0148,
      "step": 550
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.21150408685207367,
      "learning_rate": 4.86e-05,
      "loss": 0.0134,
      "step": 551
    },
    {
      "epoch": 9.517241379310345,
      "grad_norm": 0.10626965761184692,
      "learning_rate": 4.857931034482759e-05,
      "loss": 0.0102,
      "step": 552
    },
    {
      "epoch": 9.53448275862069,
      "grad_norm": 0.13133221864700317,
      "learning_rate": 4.8558620689655175e-05,
      "loss": 0.0085,
      "step": 553
    },
    {
      "epoch": 9.551724137931034,
      "grad_norm": 0.12802085280418396,
      "learning_rate": 4.853793103448276e-05,
      "loss": 0.0103,
      "step": 554
    },
    {
      "epoch": 9.568965517241379,
      "grad_norm": 0.12610048055648804,
      "learning_rate": 4.851724137931035e-05,
      "loss": 0.0125,
      "step": 555
    },
    {
      "epoch": 9.586206896551724,
      "grad_norm": 0.15548178553581238,
      "learning_rate": 4.849655172413793e-05,
      "loss": 0.0125,
      "step": 556
    },
    {
      "epoch": 9.60344827586207,
      "grad_norm": 0.13502679765224457,
      "learning_rate": 4.8475862068965515e-05,
      "loss": 0.0114,
      "step": 557
    },
    {
      "epoch": 9.620689655172415,
      "grad_norm": 0.12792912125587463,
      "learning_rate": 4.8455172413793105e-05,
      "loss": 0.0143,
      "step": 558
    },
    {
      "epoch": 9.637931034482758,
      "grad_norm": 0.1237596645951271,
      "learning_rate": 4.843448275862069e-05,
      "loss": 0.0134,
      "step": 559
    },
    {
      "epoch": 9.655172413793103,
      "grad_norm": 0.14699089527130127,
      "learning_rate": 4.841379310344827e-05,
      "loss": 0.0151,
      "step": 560
    },
    {
      "epoch": 9.655172413793103,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.010662919841706753,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.6529,
      "eval_samples_per_second": 2.292,
      "eval_steps_per_second": 1.186,
      "step": 560
    },
    {
      "epoch": 9.672413793103448,
      "grad_norm": 0.1980712115764618,
      "learning_rate": 4.839310344827587e-05,
      "loss": 0.0122,
      "step": 561
    },
    {
      "epoch": 9.689655172413794,
      "grad_norm": 0.14209067821502686,
      "learning_rate": 4.837241379310345e-05,
      "loss": 0.0096,
      "step": 562
    },
    {
      "epoch": 9.706896551724139,
      "grad_norm": 0.19676056504249573,
      "learning_rate": 4.8351724137931034e-05,
      "loss": 0.0126,
      "step": 563
    },
    {
      "epoch": 9.724137931034482,
      "grad_norm": 0.09001390635967255,
      "learning_rate": 4.8331034482758624e-05,
      "loss": 0.0089,
      "step": 564
    },
    {
      "epoch": 9.741379310344827,
      "grad_norm": 0.08802536129951477,
      "learning_rate": 4.831034482758621e-05,
      "loss": 0.0079,
      "step": 565
    },
    {
      "epoch": 9.758620689655173,
      "grad_norm": 0.18201951682567596,
      "learning_rate": 4.82896551724138e-05,
      "loss": 0.0072,
      "step": 566
    },
    {
      "epoch": 9.775862068965518,
      "grad_norm": 0.11825211346149445,
      "learning_rate": 4.826896551724138e-05,
      "loss": 0.0086,
      "step": 567
    },
    {
      "epoch": 9.793103448275861,
      "grad_norm": 0.07463075965642929,
      "learning_rate": 4.824827586206896e-05,
      "loss": 0.0068,
      "step": 568
    },
    {
      "epoch": 9.810344827586206,
      "grad_norm": 0.16045047342777252,
      "learning_rate": 4.822758620689655e-05,
      "loss": 0.0146,
      "step": 569
    },
    {
      "epoch": 9.827586206896552,
      "grad_norm": 0.0764264464378357,
      "learning_rate": 4.820689655172414e-05,
      "loss": 0.0063,
      "step": 570
    },
    {
      "epoch": 9.844827586206897,
      "grad_norm": 0.10228659957647324,
      "learning_rate": 4.8186206896551726e-05,
      "loss": 0.0084,
      "step": 571
    },
    {
      "epoch": 9.862068965517242,
      "grad_norm": 0.13255994021892548,
      "learning_rate": 4.8165517241379316e-05,
      "loss": 0.0127,
      "step": 572
    },
    {
      "epoch": 9.879310344827585,
      "grad_norm": 0.08490229398012161,
      "learning_rate": 4.81448275862069e-05,
      "loss": 0.0077,
      "step": 573
    },
    {
      "epoch": 9.89655172413793,
      "grad_norm": 0.08420681208372116,
      "learning_rate": 4.812413793103448e-05,
      "loss": 0.0086,
      "step": 574
    },
    {
      "epoch": 9.913793103448276,
      "grad_norm": 0.11692793667316437,
      "learning_rate": 4.810344827586207e-05,
      "loss": 0.0077,
      "step": 575
    },
    {
      "epoch": 9.931034482758621,
      "grad_norm": 0.10963626950979233,
      "learning_rate": 4.8082758620689655e-05,
      "loss": 0.0089,
      "step": 576
    },
    {
      "epoch": 9.948275862068966,
      "grad_norm": 0.11366147547960281,
      "learning_rate": 4.806206896551724e-05,
      "loss": 0.0118,
      "step": 577
    },
    {
      "epoch": 9.96551724137931,
      "grad_norm": 0.11375892162322998,
      "learning_rate": 4.804137931034483e-05,
      "loss": 0.0083,
      "step": 578
    },
    {
      "epoch": 9.982758620689655,
      "grad_norm": 0.42135536670684814,
      "learning_rate": 4.802068965517241e-05,
      "loss": 0.0172,
      "step": 579
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.11522118002176285,
      "learning_rate": 4.8e-05,
      "loss": 0.0097,
      "step": 580
    },
    {
      "epoch": 10.0,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.00841373298317194,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.2705,
      "eval_samples_per_second": 2.573,
      "eval_steps_per_second": 1.331,
      "step": 580
    },
    {
      "epoch": 10.017241379310345,
      "grad_norm": 0.09260989725589752,
      "learning_rate": 4.797931034482759e-05,
      "loss": 0.0088,
      "step": 581
    },
    {
      "epoch": 10.03448275862069,
      "grad_norm": 0.1154787614941597,
      "learning_rate": 4.7958620689655174e-05,
      "loss": 0.012,
      "step": 582
    },
    {
      "epoch": 10.051724137931034,
      "grad_norm": 0.09822741150856018,
      "learning_rate": 4.793793103448276e-05,
      "loss": 0.0104,
      "step": 583
    },
    {
      "epoch": 10.068965517241379,
      "grad_norm": 0.17299170792102814,
      "learning_rate": 4.791724137931035e-05,
      "loss": 0.011,
      "step": 584
    },
    {
      "epoch": 10.086206896551724,
      "grad_norm": 0.09910134971141815,
      "learning_rate": 4.789655172413793e-05,
      "loss": 0.0095,
      "step": 585
    },
    {
      "epoch": 10.10344827586207,
      "grad_norm": 0.09906015545129776,
      "learning_rate": 4.7875862068965514e-05,
      "loss": 0.0097,
      "step": 586
    },
    {
      "epoch": 10.120689655172415,
      "grad_norm": 0.17084023356437683,
      "learning_rate": 4.7855172413793103e-05,
      "loss": 0.0104,
      "step": 587
    },
    {
      "epoch": 10.137931034482758,
      "grad_norm": 0.07188001275062561,
      "learning_rate": 4.783448275862069e-05,
      "loss": 0.0056,
      "step": 588
    },
    {
      "epoch": 10.155172413793103,
      "grad_norm": 0.09278585761785507,
      "learning_rate": 4.781379310344828e-05,
      "loss": 0.0093,
      "step": 589
    },
    {
      "epoch": 10.172413793103448,
      "grad_norm": 0.1910705268383026,
      "learning_rate": 4.7793103448275866e-05,
      "loss": 0.0122,
      "step": 590
    },
    {
      "epoch": 10.189655172413794,
      "grad_norm": 0.13299746811389923,
      "learning_rate": 4.777241379310345e-05,
      "loss": 0.0102,
      "step": 591
    },
    {
      "epoch": 10.206896551724139,
      "grad_norm": 0.11270451545715332,
      "learning_rate": 4.775172413793104e-05,
      "loss": 0.0083,
      "step": 592
    },
    {
      "epoch": 10.224137931034482,
      "grad_norm": 0.10694494843482971,
      "learning_rate": 4.773103448275862e-05,
      "loss": 0.0085,
      "step": 593
    },
    {
      "epoch": 10.241379310344827,
      "grad_norm": 0.10976921021938324,
      "learning_rate": 4.7710344827586206e-05,
      "loss": 0.0071,
      "step": 594
    },
    {
      "epoch": 10.258620689655173,
      "grad_norm": 0.11065619438886642,
      "learning_rate": 4.7689655172413796e-05,
      "loss": 0.012,
      "step": 595
    },
    {
      "epoch": 10.275862068965518,
      "grad_norm": 0.14636366069316864,
      "learning_rate": 4.766896551724138e-05,
      "loss": 0.0097,
      "step": 596
    },
    {
      "epoch": 10.293103448275861,
      "grad_norm": 0.30095788836479187,
      "learning_rate": 4.764827586206896e-05,
      "loss": 0.0141,
      "step": 597
    },
    {
      "epoch": 10.310344827586206,
      "grad_norm": 0.22420383989810944,
      "learning_rate": 4.762758620689656e-05,
      "loss": 0.014,
      "step": 598
    },
    {
      "epoch": 10.327586206896552,
      "grad_norm": 0.09992945194244385,
      "learning_rate": 4.760689655172414e-05,
      "loss": 0.0097,
      "step": 599
    },
    {
      "epoch": 10.344827586206897,
      "grad_norm": 0.0995761901140213,
      "learning_rate": 4.7586206896551725e-05,
      "loss": 0.0091,
      "step": 600
    },
    {
      "epoch": 10.344827586206897,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.008015929721295834,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.1503,
      "eval_samples_per_second": 3.169,
      "eval_steps_per_second": 1.639,
      "step": 600
    },
    {
      "epoch": 10.362068965517242,
      "grad_norm": 0.1702967882156372,
      "learning_rate": 4.7565517241379315e-05,
      "loss": 0.0112,
      "step": 601
    },
    {
      "epoch": 10.379310344827585,
      "grad_norm": 0.15555687248706818,
      "learning_rate": 4.75448275862069e-05,
      "loss": 0.0117,
      "step": 602
    },
    {
      "epoch": 10.39655172413793,
      "grad_norm": 0.06862236559391022,
      "learning_rate": 4.752413793103448e-05,
      "loss": 0.0061,
      "step": 603
    },
    {
      "epoch": 10.413793103448276,
      "grad_norm": 0.11051906645298004,
      "learning_rate": 4.750344827586207e-05,
      "loss": 0.0101,
      "step": 604
    },
    {
      "epoch": 10.431034482758621,
      "grad_norm": 0.1628459244966507,
      "learning_rate": 4.7482758620689654e-05,
      "loss": 0.0094,
      "step": 605
    },
    {
      "epoch": 10.448275862068966,
      "grad_norm": 0.12579576671123505,
      "learning_rate": 4.746206896551724e-05,
      "loss": 0.009,
      "step": 606
    },
    {
      "epoch": 10.46551724137931,
      "grad_norm": 0.059154193848371506,
      "learning_rate": 4.744137931034483e-05,
      "loss": 0.0046,
      "step": 607
    },
    {
      "epoch": 10.482758620689655,
      "grad_norm": 0.07356415688991547,
      "learning_rate": 4.742068965517242e-05,
      "loss": 0.0055,
      "step": 608
    },
    {
      "epoch": 10.5,
      "grad_norm": 0.16288277506828308,
      "learning_rate": 4.74e-05,
      "loss": 0.0116,
      "step": 609
    },
    {
      "epoch": 10.517241379310345,
      "grad_norm": 0.14237277209758759,
      "learning_rate": 4.737931034482759e-05,
      "loss": 0.0104,
      "step": 610
    },
    {
      "epoch": 10.53448275862069,
      "grad_norm": 0.14115600287914276,
      "learning_rate": 4.735862068965517e-05,
      "loss": 0.0104,
      "step": 611
    },
    {
      "epoch": 10.551724137931034,
      "grad_norm": 0.0747268870472908,
      "learning_rate": 4.733793103448276e-05,
      "loss": 0.0049,
      "step": 612
    },
    {
      "epoch": 10.568965517241379,
      "grad_norm": 0.11608579009771347,
      "learning_rate": 4.7317241379310346e-05,
      "loss": 0.0093,
      "step": 613
    },
    {
      "epoch": 10.586206896551724,
      "grad_norm": 0.1264481395483017,
      "learning_rate": 4.729655172413793e-05,
      "loss": 0.0138,
      "step": 614
    },
    {
      "epoch": 10.60344827586207,
      "grad_norm": 0.12701278924942017,
      "learning_rate": 4.727586206896552e-05,
      "loss": 0.009,
      "step": 615
    },
    {
      "epoch": 10.620689655172415,
      "grad_norm": 0.1409917026758194,
      "learning_rate": 4.72551724137931e-05,
      "loss": 0.0081,
      "step": 616
    },
    {
      "epoch": 10.637931034482758,
      "grad_norm": 0.09402924031019211,
      "learning_rate": 4.723448275862069e-05,
      "loss": 0.0103,
      "step": 617
    },
    {
      "epoch": 10.655172413793103,
      "grad_norm": 0.11288119852542877,
      "learning_rate": 4.721379310344828e-05,
      "loss": 0.0111,
      "step": 618
    },
    {
      "epoch": 10.672413793103448,
      "grad_norm": 0.20881401002407074,
      "learning_rate": 4.7193103448275865e-05,
      "loss": 0.0096,
      "step": 619
    },
    {
      "epoch": 10.689655172413794,
      "grad_norm": 0.15561771392822266,
      "learning_rate": 4.717241379310345e-05,
      "loss": 0.0077,
      "step": 620
    },
    {
      "epoch": 10.689655172413794,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.007884522899985313,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.2462,
      "eval_samples_per_second": 3.136,
      "eval_steps_per_second": 1.622,
      "step": 620
    },
    {
      "epoch": 10.706896551724139,
      "grad_norm": 0.068343885242939,
      "learning_rate": 4.715172413793104e-05,
      "loss": 0.0065,
      "step": 621
    },
    {
      "epoch": 10.724137931034482,
      "grad_norm": 0.16001124680042267,
      "learning_rate": 4.713103448275862e-05,
      "loss": 0.0073,
      "step": 622
    },
    {
      "epoch": 10.741379310344827,
      "grad_norm": 0.09914689511060715,
      "learning_rate": 4.7110344827586205e-05,
      "loss": 0.0094,
      "step": 623
    },
    {
      "epoch": 10.758620689655173,
      "grad_norm": 0.1609881967306137,
      "learning_rate": 4.7089655172413795e-05,
      "loss": 0.014,
      "step": 624
    },
    {
      "epoch": 10.775862068965518,
      "grad_norm": 0.12030615657567978,
      "learning_rate": 4.706896551724138e-05,
      "loss": 0.0073,
      "step": 625
    },
    {
      "epoch": 10.793103448275861,
      "grad_norm": 0.09900744259357452,
      "learning_rate": 4.704827586206896e-05,
      "loss": 0.0094,
      "step": 626
    },
    {
      "epoch": 10.810344827586206,
      "grad_norm": 0.08437734842300415,
      "learning_rate": 4.702758620689656e-05,
      "loss": 0.0072,
      "step": 627
    },
    {
      "epoch": 10.827586206896552,
      "grad_norm": 0.0832630917429924,
      "learning_rate": 4.700689655172414e-05,
      "loss": 0.008,
      "step": 628
    },
    {
      "epoch": 10.844827586206897,
      "grad_norm": 0.10585252195596695,
      "learning_rate": 4.6986206896551724e-05,
      "loss": 0.009,
      "step": 629
    },
    {
      "epoch": 10.862068965517242,
      "grad_norm": 0.10269950330257416,
      "learning_rate": 4.6965517241379314e-05,
      "loss": 0.0084,
      "step": 630
    },
    {
      "epoch": 10.879310344827585,
      "grad_norm": 0.11758659034967422,
      "learning_rate": 4.69448275862069e-05,
      "loss": 0.0069,
      "step": 631
    },
    {
      "epoch": 10.89655172413793,
      "grad_norm": 0.10985703021287918,
      "learning_rate": 4.692413793103448e-05,
      "loss": 0.0085,
      "step": 632
    },
    {
      "epoch": 10.913793103448276,
      "grad_norm": 0.08258141577243805,
      "learning_rate": 4.690344827586207e-05,
      "loss": 0.007,
      "step": 633
    },
    {
      "epoch": 10.931034482758621,
      "grad_norm": 0.1557447463274002,
      "learning_rate": 4.688275862068965e-05,
      "loss": 0.0113,
      "step": 634
    },
    {
      "epoch": 10.948275862068966,
      "grad_norm": 0.09005384892225266,
      "learning_rate": 4.686206896551724e-05,
      "loss": 0.0089,
      "step": 635
    },
    {
      "epoch": 10.96551724137931,
      "grad_norm": 0.09624326229095459,
      "learning_rate": 4.684137931034483e-05,
      "loss": 0.0092,
      "step": 636
    },
    {
      "epoch": 10.982758620689655,
      "grad_norm": 0.13591451942920685,
      "learning_rate": 4.6820689655172416e-05,
      "loss": 0.0113,
      "step": 637
    },
    {
      "epoch": 11.0,
      "grad_norm": 0.12651802599430084,
      "learning_rate": 4.6800000000000006e-05,
      "loss": 0.0124,
      "step": 638
    },
    {
      "epoch": 11.017241379310345,
      "grad_norm": 0.07165710628032684,
      "learning_rate": 4.677931034482759e-05,
      "loss": 0.0055,
      "step": 639
    },
    {
      "epoch": 11.03448275862069,
      "grad_norm": 0.18469759821891785,
      "learning_rate": 4.675862068965517e-05,
      "loss": 0.0089,
      "step": 640
    },
    {
      "epoch": 11.03448275862069,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.007512377109378576,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.0588,
      "eval_samples_per_second": 2.622,
      "eval_steps_per_second": 1.356,
      "step": 640
    },
    {
      "epoch": 11.051724137931034,
      "grad_norm": 0.09792950004339218,
      "learning_rate": 4.673793103448276e-05,
      "loss": 0.0076,
      "step": 641
    },
    {
      "epoch": 11.068965517241379,
      "grad_norm": 0.11009889096021652,
      "learning_rate": 4.6717241379310345e-05,
      "loss": 0.0095,
      "step": 642
    },
    {
      "epoch": 11.086206896551724,
      "grad_norm": 0.08319481462240219,
      "learning_rate": 4.669655172413793e-05,
      "loss": 0.0089,
      "step": 643
    },
    {
      "epoch": 11.10344827586207,
      "grad_norm": 0.10703002661466599,
      "learning_rate": 4.667586206896552e-05,
      "loss": 0.0081,
      "step": 644
    },
    {
      "epoch": 11.120689655172415,
      "grad_norm": 0.0457693487405777,
      "learning_rate": 4.665517241379311e-05,
      "loss": 0.004,
      "step": 645
    },
    {
      "epoch": 11.137931034482758,
      "grad_norm": 0.0963938757777214,
      "learning_rate": 4.663448275862069e-05,
      "loss": 0.0091,
      "step": 646
    },
    {
      "epoch": 11.155172413793103,
      "grad_norm": 0.20353424549102783,
      "learning_rate": 4.661379310344828e-05,
      "loss": 0.0094,
      "step": 647
    },
    {
      "epoch": 11.172413793103448,
      "grad_norm": 0.09394975751638412,
      "learning_rate": 4.6593103448275864e-05,
      "loss": 0.0087,
      "step": 648
    },
    {
      "epoch": 11.189655172413794,
      "grad_norm": 0.06385689228773117,
      "learning_rate": 4.657241379310345e-05,
      "loss": 0.0065,
      "step": 649
    },
    {
      "epoch": 11.206896551724139,
      "grad_norm": 0.054799970239400864,
      "learning_rate": 4.655172413793104e-05,
      "loss": 0.0052,
      "step": 650
    },
    {
      "epoch": 11.224137931034482,
      "grad_norm": 0.0997997373342514,
      "learning_rate": 4.653103448275862e-05,
      "loss": 0.0051,
      "step": 651
    },
    {
      "epoch": 11.241379310344827,
      "grad_norm": 0.06023141369223595,
      "learning_rate": 4.6510344827586204e-05,
      "loss": 0.0057,
      "step": 652
    },
    {
      "epoch": 11.258620689655173,
      "grad_norm": 0.07551179826259613,
      "learning_rate": 4.6489655172413794e-05,
      "loss": 0.0071,
      "step": 653
    },
    {
      "epoch": 11.275862068965518,
      "grad_norm": 0.11201338469982147,
      "learning_rate": 4.646896551724138e-05,
      "loss": 0.0096,
      "step": 654
    },
    {
      "epoch": 11.293103448275861,
      "grad_norm": 0.06343687325716019,
      "learning_rate": 4.644827586206897e-05,
      "loss": 0.0059,
      "step": 655
    },
    {
      "epoch": 11.310344827586206,
      "grad_norm": 0.08718215674161911,
      "learning_rate": 4.6427586206896557e-05,
      "loss": 0.0094,
      "step": 656
    },
    {
      "epoch": 11.327586206896552,
      "grad_norm": 0.1184462159872055,
      "learning_rate": 4.640689655172414e-05,
      "loss": 0.0111,
      "step": 657
    },
    {
      "epoch": 11.344827586206897,
      "grad_norm": 0.08546029031276703,
      "learning_rate": 4.638620689655172e-05,
      "loss": 0.0067,
      "step": 658
    },
    {
      "epoch": 11.362068965517242,
      "grad_norm": 0.1914810836315155,
      "learning_rate": 4.636551724137931e-05,
      "loss": 0.0103,
      "step": 659
    },
    {
      "epoch": 11.379310344827585,
      "grad_norm": 0.057541754096746445,
      "learning_rate": 4.6344827586206896e-05,
      "loss": 0.0055,
      "step": 660
    },
    {
      "epoch": 11.379310344827585,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.006582408212125301,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.2383,
      "eval_samples_per_second": 3.139,
      "eval_steps_per_second": 1.624,
      "step": 660
    },
    {
      "epoch": 11.39655172413793,
      "grad_norm": 0.11924757063388824,
      "learning_rate": 4.6324137931034486e-05,
      "loss": 0.0099,
      "step": 661
    },
    {
      "epoch": 11.413793103448276,
      "grad_norm": 0.05902424082159996,
      "learning_rate": 4.630344827586207e-05,
      "loss": 0.0047,
      "step": 662
    },
    {
      "epoch": 11.431034482758621,
      "grad_norm": 0.1071542352437973,
      "learning_rate": 4.628275862068965e-05,
      "loss": 0.0104,
      "step": 663
    },
    {
      "epoch": 11.448275862068966,
      "grad_norm": 0.09580445289611816,
      "learning_rate": 4.626206896551725e-05,
      "loss": 0.0079,
      "step": 664
    },
    {
      "epoch": 11.46551724137931,
      "grad_norm": 0.09292378276586533,
      "learning_rate": 4.624137931034483e-05,
      "loss": 0.0078,
      "step": 665
    },
    {
      "epoch": 11.482758620689655,
      "grad_norm": 0.14802296459674835,
      "learning_rate": 4.6220689655172415e-05,
      "loss": 0.01,
      "step": 666
    },
    {
      "epoch": 11.5,
      "grad_norm": 0.11464312672615051,
      "learning_rate": 4.6200000000000005e-05,
      "loss": 0.0085,
      "step": 667
    },
    {
      "epoch": 11.517241379310345,
      "grad_norm": 0.07856929302215576,
      "learning_rate": 4.617931034482759e-05,
      "loss": 0.0081,
      "step": 668
    },
    {
      "epoch": 11.53448275862069,
      "grad_norm": 0.10371097922325134,
      "learning_rate": 4.615862068965517e-05,
      "loss": 0.0085,
      "step": 669
    },
    {
      "epoch": 11.551724137931034,
      "grad_norm": 0.10085698962211609,
      "learning_rate": 4.613793103448276e-05,
      "loss": 0.005,
      "step": 670
    },
    {
      "epoch": 11.568965517241379,
      "grad_norm": 0.06656165421009064,
      "learning_rate": 4.6117241379310344e-05,
      "loss": 0.0059,
      "step": 671
    },
    {
      "epoch": 11.586206896551724,
      "grad_norm": 0.09082654863595963,
      "learning_rate": 4.609655172413793e-05,
      "loss": 0.006,
      "step": 672
    },
    {
      "epoch": 11.60344827586207,
      "grad_norm": 0.07855834811925888,
      "learning_rate": 4.607586206896552e-05,
      "loss": 0.0082,
      "step": 673
    },
    {
      "epoch": 11.620689655172415,
      "grad_norm": 0.0892481878399849,
      "learning_rate": 4.605517241379311e-05,
      "loss": 0.0081,
      "step": 674
    },
    {
      "epoch": 11.637931034482758,
      "grad_norm": 0.11006287485361099,
      "learning_rate": 4.603448275862069e-05,
      "loss": 0.0091,
      "step": 675
    },
    {
      "epoch": 11.655172413793103,
      "grad_norm": 0.12845709919929504,
      "learning_rate": 4.601379310344828e-05,
      "loss": 0.0096,
      "step": 676
    },
    {
      "epoch": 11.672413793103448,
      "grad_norm": 0.07570647448301315,
      "learning_rate": 4.599310344827586e-05,
      "loss": 0.0063,
      "step": 677
    },
    {
      "epoch": 11.689655172413794,
      "grad_norm": 0.10146283358335495,
      "learning_rate": 4.5972413793103446e-05,
      "loss": 0.0074,
      "step": 678
    },
    {
      "epoch": 11.706896551724139,
      "grad_norm": 0.1219671368598938,
      "learning_rate": 4.5951724137931036e-05,
      "loss": 0.0083,
      "step": 679
    },
    {
      "epoch": 11.724137931034482,
      "grad_norm": 0.13891233503818512,
      "learning_rate": 4.593103448275862e-05,
      "loss": 0.0069,
      "step": 680
    },
    {
      "epoch": 11.724137931034482,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.006317109800875187,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.9243,
      "eval_samples_per_second": 3.25,
      "eval_steps_per_second": 1.681,
      "step": 680
    },
    {
      "epoch": 11.741379310344827,
      "grad_norm": 0.09447799623012543,
      "learning_rate": 4.59103448275862e-05,
      "loss": 0.0064,
      "step": 681
    },
    {
      "epoch": 11.758620689655173,
      "grad_norm": 0.1315862387418747,
      "learning_rate": 4.588965517241379e-05,
      "loss": 0.0102,
      "step": 682
    },
    {
      "epoch": 11.775862068965518,
      "grad_norm": 0.09089258313179016,
      "learning_rate": 4.586896551724138e-05,
      "loss": 0.0046,
      "step": 683
    },
    {
      "epoch": 11.793103448275861,
      "grad_norm": 0.08016597479581833,
      "learning_rate": 4.584827586206897e-05,
      "loss": 0.0085,
      "step": 684
    },
    {
      "epoch": 11.810344827586206,
      "grad_norm": 0.10369548201560974,
      "learning_rate": 4.5827586206896556e-05,
      "loss": 0.01,
      "step": 685
    },
    {
      "epoch": 11.827586206896552,
      "grad_norm": 0.23660258948802948,
      "learning_rate": 4.580689655172414e-05,
      "loss": 0.016,
      "step": 686
    },
    {
      "epoch": 11.844827586206897,
      "grad_norm": 0.06449820846319199,
      "learning_rate": 4.578620689655173e-05,
      "loss": 0.0067,
      "step": 687
    },
    {
      "epoch": 11.862068965517242,
      "grad_norm": 0.11141868680715561,
      "learning_rate": 4.576551724137931e-05,
      "loss": 0.0091,
      "step": 688
    },
    {
      "epoch": 11.879310344827585,
      "grad_norm": 0.10478463023900986,
      "learning_rate": 4.5744827586206895e-05,
      "loss": 0.0073,
      "step": 689
    },
    {
      "epoch": 11.89655172413793,
      "grad_norm": 0.09681978821754456,
      "learning_rate": 4.5724137931034485e-05,
      "loss": 0.0089,
      "step": 690
    },
    {
      "epoch": 11.913793103448276,
      "grad_norm": 0.15186846256256104,
      "learning_rate": 4.570344827586207e-05,
      "loss": 0.0102,
      "step": 691
    },
    {
      "epoch": 11.931034482758621,
      "grad_norm": 0.11033379286527634,
      "learning_rate": 4.568275862068965e-05,
      "loss": 0.0103,
      "step": 692
    },
    {
      "epoch": 11.948275862068966,
      "grad_norm": 0.06832997500896454,
      "learning_rate": 4.566206896551725e-05,
      "loss": 0.0056,
      "step": 693
    },
    {
      "epoch": 11.96551724137931,
      "grad_norm": 0.09019526839256287,
      "learning_rate": 4.564137931034483e-05,
      "loss": 0.0094,
      "step": 694
    },
    {
      "epoch": 11.982758620689655,
      "grad_norm": 0.10050316154956818,
      "learning_rate": 4.5620689655172414e-05,
      "loss": 0.0055,
      "step": 695
    },
    {
      "epoch": 12.0,
      "grad_norm": 0.08588302135467529,
      "learning_rate": 4.5600000000000004e-05,
      "loss": 0.0083,
      "step": 696
    },
    {
      "epoch": 12.017241379310345,
      "grad_norm": 0.08835398405790329,
      "learning_rate": 4.557931034482759e-05,
      "loss": 0.0085,
      "step": 697
    },
    {
      "epoch": 12.03448275862069,
      "grad_norm": 0.06363671272993088,
      "learning_rate": 4.555862068965517e-05,
      "loss": 0.0062,
      "step": 698
    },
    {
      "epoch": 12.051724137931034,
      "grad_norm": 0.1623297780752182,
      "learning_rate": 4.553793103448276e-05,
      "loss": 0.0096,
      "step": 699
    },
    {
      "epoch": 12.068965517241379,
      "grad_norm": 0.19899819791316986,
      "learning_rate": 4.551724137931034e-05,
      "loss": 0.0073,
      "step": 700
    },
    {
      "epoch": 12.068965517241379,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0067844935692846775,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.3165,
      "eval_samples_per_second": 3.113,
      "eval_steps_per_second": 1.61,
      "step": 700
    },
    {
      "epoch": 12.086206896551724,
      "grad_norm": 0.0987452045083046,
      "learning_rate": 4.5496551724137926e-05,
      "loss": 0.0081,
      "step": 701
    },
    {
      "epoch": 12.10344827586207,
      "grad_norm": 0.13100847601890564,
      "learning_rate": 4.547586206896552e-05,
      "loss": 0.0091,
      "step": 702
    },
    {
      "epoch": 12.120689655172415,
      "grad_norm": 0.19597932696342468,
      "learning_rate": 4.5455172413793106e-05,
      "loss": 0.0093,
      "step": 703
    },
    {
      "epoch": 12.137931034482758,
      "grad_norm": 0.07748876512050629,
      "learning_rate": 4.543448275862069e-05,
      "loss": 0.0076,
      "step": 704
    },
    {
      "epoch": 12.155172413793103,
      "grad_norm": 0.10301892459392548,
      "learning_rate": 4.541379310344828e-05,
      "loss": 0.0096,
      "step": 705
    },
    {
      "epoch": 12.172413793103448,
      "grad_norm": 0.07028059661388397,
      "learning_rate": 4.539310344827586e-05,
      "loss": 0.0076,
      "step": 706
    },
    {
      "epoch": 12.189655172413794,
      "grad_norm": 0.10664768517017365,
      "learning_rate": 4.537241379310345e-05,
      "loss": 0.0062,
      "step": 707
    },
    {
      "epoch": 12.206896551724139,
      "grad_norm": 0.11847348511219025,
      "learning_rate": 4.5351724137931035e-05,
      "loss": 0.0081,
      "step": 708
    },
    {
      "epoch": 12.224137931034482,
      "grad_norm": 0.05266628414392471,
      "learning_rate": 4.533103448275862e-05,
      "loss": 0.0038,
      "step": 709
    },
    {
      "epoch": 12.241379310344827,
      "grad_norm": 0.07190369814634323,
      "learning_rate": 4.531034482758621e-05,
      "loss": 0.005,
      "step": 710
    },
    {
      "epoch": 12.258620689655173,
      "grad_norm": 0.06908626109361649,
      "learning_rate": 4.52896551724138e-05,
      "loss": 0.0059,
      "step": 711
    },
    {
      "epoch": 12.275862068965518,
      "grad_norm": 0.28358468413352966,
      "learning_rate": 4.526896551724138e-05,
      "loss": 0.0113,
      "step": 712
    },
    {
      "epoch": 12.293103448275861,
      "grad_norm": 0.09022559970617294,
      "learning_rate": 4.524827586206897e-05,
      "loss": 0.0059,
      "step": 713
    },
    {
      "epoch": 12.310344827586206,
      "grad_norm": 0.08391019701957703,
      "learning_rate": 4.5227586206896554e-05,
      "loss": 0.0079,
      "step": 714
    },
    {
      "epoch": 12.327586206896552,
      "grad_norm": 0.0640873834490776,
      "learning_rate": 4.520689655172414e-05,
      "loss": 0.0044,
      "step": 715
    },
    {
      "epoch": 12.344827586206897,
      "grad_norm": 0.11394799500703812,
      "learning_rate": 4.518620689655173e-05,
      "loss": 0.0081,
      "step": 716
    },
    {
      "epoch": 12.362068965517242,
      "grad_norm": 0.0776047557592392,
      "learning_rate": 4.516551724137931e-05,
      "loss": 0.0075,
      "step": 717
    },
    {
      "epoch": 12.379310344827585,
      "grad_norm": 0.06690407544374466,
      "learning_rate": 4.5144827586206894e-05,
      "loss": 0.0038,
      "step": 718
    },
    {
      "epoch": 12.39655172413793,
      "grad_norm": 0.06409915536642075,
      "learning_rate": 4.5124137931034484e-05,
      "loss": 0.0055,
      "step": 719
    },
    {
      "epoch": 12.413793103448276,
      "grad_norm": 0.05103013664484024,
      "learning_rate": 4.510344827586207e-05,
      "loss": 0.0042,
      "step": 720
    },
    {
      "epoch": 12.413793103448276,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.005440338980406523,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.3623,
      "eval_samples_per_second": 3.098,
      "eval_steps_per_second": 1.602,
      "step": 720
    },
    {
      "epoch": 12.431034482758621,
      "grad_norm": 0.1039213165640831,
      "learning_rate": 4.508275862068966e-05,
      "loss": 0.0087,
      "step": 721
    },
    {
      "epoch": 12.448275862068966,
      "grad_norm": 0.2119869589805603,
      "learning_rate": 4.506206896551725e-05,
      "loss": 0.0089,
      "step": 722
    },
    {
      "epoch": 12.46551724137931,
      "grad_norm": 0.09218748658895493,
      "learning_rate": 4.504137931034483e-05,
      "loss": 0.0085,
      "step": 723
    },
    {
      "epoch": 12.482758620689655,
      "grad_norm": 0.05920601263642311,
      "learning_rate": 4.502068965517241e-05,
      "loss": 0.0056,
      "step": 724
    },
    {
      "epoch": 12.5,
      "grad_norm": 0.06784351915121078,
      "learning_rate": 4.5e-05,
      "loss": 0.0072,
      "step": 725
    },
    {
      "epoch": 12.517241379310345,
      "grad_norm": 0.0785430446267128,
      "learning_rate": 4.4979310344827586e-05,
      "loss": 0.0067,
      "step": 726
    },
    {
      "epoch": 12.53448275862069,
      "grad_norm": 0.05069660395383835,
      "learning_rate": 4.495862068965517e-05,
      "loss": 0.0045,
      "step": 727
    },
    {
      "epoch": 12.551724137931034,
      "grad_norm": 0.060665909200906754,
      "learning_rate": 4.493793103448276e-05,
      "loss": 0.006,
      "step": 728
    },
    {
      "epoch": 12.568965517241379,
      "grad_norm": 0.1486670821905136,
      "learning_rate": 4.491724137931034e-05,
      "loss": 0.0089,
      "step": 729
    },
    {
      "epoch": 12.586206896551724,
      "grad_norm": 0.06989652663469315,
      "learning_rate": 4.489655172413793e-05,
      "loss": 0.0057,
      "step": 730
    },
    {
      "epoch": 12.60344827586207,
      "grad_norm": 0.05955374613404274,
      "learning_rate": 4.487586206896552e-05,
      "loss": 0.0055,
      "step": 731
    },
    {
      "epoch": 12.620689655172415,
      "grad_norm": 0.09664894640445709,
      "learning_rate": 4.4855172413793105e-05,
      "loss": 0.0069,
      "step": 732
    },
    {
      "epoch": 12.637931034482758,
      "grad_norm": 0.07474956661462784,
      "learning_rate": 4.4834482758620695e-05,
      "loss": 0.0063,
      "step": 733
    },
    {
      "epoch": 12.655172413793103,
      "grad_norm": 0.0719963014125824,
      "learning_rate": 4.481379310344828e-05,
      "loss": 0.0052,
      "step": 734
    },
    {
      "epoch": 12.672413793103448,
      "grad_norm": 0.16955259442329407,
      "learning_rate": 4.479310344827586e-05,
      "loss": 0.0078,
      "step": 735
    },
    {
      "epoch": 12.689655172413794,
      "grad_norm": 0.08265478909015656,
      "learning_rate": 4.477241379310345e-05,
      "loss": 0.0082,
      "step": 736
    },
    {
      "epoch": 12.706896551724139,
      "grad_norm": 0.040541984140872955,
      "learning_rate": 4.4751724137931034e-05,
      "loss": 0.0032,
      "step": 737
    },
    {
      "epoch": 12.724137931034482,
      "grad_norm": 0.07517793029546738,
      "learning_rate": 4.473103448275862e-05,
      "loss": 0.0075,
      "step": 738
    },
    {
      "epoch": 12.741379310344827,
      "grad_norm": 0.09883060306310654,
      "learning_rate": 4.471034482758621e-05,
      "loss": 0.0061,
      "step": 739
    },
    {
      "epoch": 12.758620689655173,
      "grad_norm": 0.08461328595876694,
      "learning_rate": 4.46896551724138e-05,
      "loss": 0.0064,
      "step": 740
    },
    {
      "epoch": 12.758620689655173,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.00555039569735527,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.4875,
      "eval_samples_per_second": 3.057,
      "eval_steps_per_second": 1.581,
      "step": 740
    },
    {
      "epoch": 12.775862068965518,
      "grad_norm": 0.05095168948173523,
      "learning_rate": 4.466896551724138e-05,
      "loss": 0.0049,
      "step": 741
    },
    {
      "epoch": 12.793103448275861,
      "grad_norm": 0.0917300283908844,
      "learning_rate": 4.464827586206897e-05,
      "loss": 0.0084,
      "step": 742
    },
    {
      "epoch": 12.810344827586206,
      "grad_norm": 0.07968936860561371,
      "learning_rate": 4.4627586206896553e-05,
      "loss": 0.0084,
      "step": 743
    },
    {
      "epoch": 12.827586206896552,
      "grad_norm": 0.057839617133140564,
      "learning_rate": 4.4606896551724137e-05,
      "loss": 0.0058,
      "step": 744
    },
    {
      "epoch": 12.844827586206897,
      "grad_norm": 0.08863579481840134,
      "learning_rate": 4.4586206896551726e-05,
      "loss": 0.0078,
      "step": 745
    },
    {
      "epoch": 12.862068965517242,
      "grad_norm": 0.1659170240163803,
      "learning_rate": 4.456551724137931e-05,
      "loss": 0.008,
      "step": 746
    },
    {
      "epoch": 12.879310344827585,
      "grad_norm": 0.10467243194580078,
      "learning_rate": 4.454482758620689e-05,
      "loss": 0.0068,
      "step": 747
    },
    {
      "epoch": 12.89655172413793,
      "grad_norm": 0.1030353382229805,
      "learning_rate": 4.452413793103448e-05,
      "loss": 0.0098,
      "step": 748
    },
    {
      "epoch": 12.913793103448276,
      "grad_norm": 0.1293821781873703,
      "learning_rate": 4.450344827586207e-05,
      "loss": 0.0081,
      "step": 749
    },
    {
      "epoch": 12.931034482758621,
      "grad_norm": 0.0685923621058464,
      "learning_rate": 4.4482758620689656e-05,
      "loss": 0.0068,
      "step": 750
    },
    {
      "epoch": 12.948275862068966,
      "grad_norm": 0.09118745476007462,
      "learning_rate": 4.4462068965517246e-05,
      "loss": 0.0067,
      "step": 751
    },
    {
      "epoch": 12.96551724137931,
      "grad_norm": 0.0895729511976242,
      "learning_rate": 4.444137931034483e-05,
      "loss": 0.0085,
      "step": 752
    },
    {
      "epoch": 12.982758620689655,
      "grad_norm": 0.06985213607549667,
      "learning_rate": 4.442068965517241e-05,
      "loss": 0.0042,
      "step": 753
    },
    {
      "epoch": 13.0,
      "grad_norm": 0.06758242845535278,
      "learning_rate": 4.44e-05,
      "loss": 0.0066,
      "step": 754
    },
    {
      "epoch": 13.017241379310345,
      "grad_norm": 0.10271574556827545,
      "learning_rate": 4.4379310344827585e-05,
      "loss": 0.0072,
      "step": 755
    },
    {
      "epoch": 13.03448275862069,
      "grad_norm": 0.0728544294834137,
      "learning_rate": 4.4358620689655175e-05,
      "loss": 0.0065,
      "step": 756
    },
    {
      "epoch": 13.051724137931034,
      "grad_norm": 0.05875905230641365,
      "learning_rate": 4.433793103448276e-05,
      "loss": 0.0055,
      "step": 757
    },
    {
      "epoch": 13.068965517241379,
      "grad_norm": 0.06983336806297302,
      "learning_rate": 4.431724137931035e-05,
      "loss": 0.0068,
      "step": 758
    },
    {
      "epoch": 13.086206896551724,
      "grad_norm": 0.06671003997325897,
      "learning_rate": 4.429655172413794e-05,
      "loss": 0.0062,
      "step": 759
    },
    {
      "epoch": 13.10344827586207,
      "grad_norm": 0.08100603520870209,
      "learning_rate": 4.427586206896552e-05,
      "loss": 0.0065,
      "step": 760
    },
    {
      "epoch": 13.10344827586207,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.006308453157544136,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.1006,
      "eval_samples_per_second": 3.187,
      "eval_steps_per_second": 1.648,
      "step": 760
    },
    {
      "epoch": 13.120689655172415,
      "grad_norm": 0.1628274917602539,
      "learning_rate": 4.4255172413793104e-05,
      "loss": 0.008,
      "step": 761
    },
    {
      "epoch": 13.137931034482758,
      "grad_norm": 0.0880594551563263,
      "learning_rate": 4.4234482758620694e-05,
      "loss": 0.0059,
      "step": 762
    },
    {
      "epoch": 13.155172413793103,
      "grad_norm": 0.06421884149312973,
      "learning_rate": 4.421379310344828e-05,
      "loss": 0.006,
      "step": 763
    },
    {
      "epoch": 13.172413793103448,
      "grad_norm": 0.09114255756139755,
      "learning_rate": 4.419310344827586e-05,
      "loss": 0.0088,
      "step": 764
    },
    {
      "epoch": 13.189655172413794,
      "grad_norm": 0.05569066107273102,
      "learning_rate": 4.417241379310345e-05,
      "loss": 0.004,
      "step": 765
    },
    {
      "epoch": 13.206896551724139,
      "grad_norm": 0.07064996659755707,
      "learning_rate": 4.415172413793103e-05,
      "loss": 0.0055,
      "step": 766
    },
    {
      "epoch": 13.224137931034482,
      "grad_norm": 0.08288854360580444,
      "learning_rate": 4.4131034482758616e-05,
      "loss": 0.008,
      "step": 767
    },
    {
      "epoch": 13.241379310344827,
      "grad_norm": 0.04429043084383011,
      "learning_rate": 4.411034482758621e-05,
      "loss": 0.0034,
      "step": 768
    },
    {
      "epoch": 13.258620689655173,
      "grad_norm": 0.032608531415462494,
      "learning_rate": 4.4089655172413796e-05,
      "loss": 0.0026,
      "step": 769
    },
    {
      "epoch": 13.275862068965518,
      "grad_norm": 0.058721549808979034,
      "learning_rate": 4.406896551724138e-05,
      "loss": 0.0048,
      "step": 770
    },
    {
      "epoch": 13.293103448275861,
      "grad_norm": 0.09912486374378204,
      "learning_rate": 4.404827586206897e-05,
      "loss": 0.0049,
      "step": 771
    },
    {
      "epoch": 13.310344827586206,
      "grad_norm": 0.060611702501773834,
      "learning_rate": 4.402758620689655e-05,
      "loss": 0.0055,
      "step": 772
    },
    {
      "epoch": 13.327586206896552,
      "grad_norm": 0.07110363245010376,
      "learning_rate": 4.4006896551724136e-05,
      "loss": 0.0063,
      "step": 773
    },
    {
      "epoch": 13.344827586206897,
      "grad_norm": 0.06360705196857452,
      "learning_rate": 4.3986206896551725e-05,
      "loss": 0.0048,
      "step": 774
    },
    {
      "epoch": 13.362068965517242,
      "grad_norm": 0.08192125707864761,
      "learning_rate": 4.396551724137931e-05,
      "loss": 0.0073,
      "step": 775
    },
    {
      "epoch": 13.379310344827585,
      "grad_norm": 0.10815247148275375,
      "learning_rate": 4.394482758620689e-05,
      "loss": 0.0082,
      "step": 776
    },
    {
      "epoch": 13.39655172413793,
      "grad_norm": 0.047895148396492004,
      "learning_rate": 4.392413793103449e-05,
      "loss": 0.0044,
      "step": 777
    },
    {
      "epoch": 13.413793103448276,
      "grad_norm": 0.06475669890642166,
      "learning_rate": 4.390344827586207e-05,
      "loss": 0.0054,
      "step": 778
    },
    {
      "epoch": 13.431034482758621,
      "grad_norm": 0.06972222030162811,
      "learning_rate": 4.3882758620689655e-05,
      "loss": 0.0067,
      "step": 779
    },
    {
      "epoch": 13.448275862068966,
      "grad_norm": 0.09091126918792725,
      "learning_rate": 4.3862068965517245e-05,
      "loss": 0.0067,
      "step": 780
    },
    {
      "epoch": 13.448275862068966,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.005292669404298067,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.2752,
      "eval_samples_per_second": 3.504,
      "eval_steps_per_second": 1.813,
      "step": 780
    },
    {
      "epoch": 13.46551724137931,
      "grad_norm": 0.11730735003948212,
      "learning_rate": 4.384137931034483e-05,
      "loss": 0.0069,
      "step": 781
    },
    {
      "epoch": 13.482758620689655,
      "grad_norm": 0.0678957849740982,
      "learning_rate": 4.382068965517242e-05,
      "loss": 0.0058,
      "step": 782
    },
    {
      "epoch": 13.5,
      "grad_norm": 0.09875514358282089,
      "learning_rate": 4.38e-05,
      "loss": 0.0078,
      "step": 783
    },
    {
      "epoch": 13.517241379310345,
      "grad_norm": 0.07834255695343018,
      "learning_rate": 4.3779310344827584e-05,
      "loss": 0.0082,
      "step": 784
    },
    {
      "epoch": 13.53448275862069,
      "grad_norm": 0.17040693759918213,
      "learning_rate": 4.3758620689655174e-05,
      "loss": 0.0068,
      "step": 785
    },
    {
      "epoch": 13.551724137931034,
      "grad_norm": 0.04757595807313919,
      "learning_rate": 4.373793103448276e-05,
      "loss": 0.0046,
      "step": 786
    },
    {
      "epoch": 13.568965517241379,
      "grad_norm": 0.07866508513689041,
      "learning_rate": 4.371724137931035e-05,
      "loss": 0.0076,
      "step": 787
    },
    {
      "epoch": 13.586206896551724,
      "grad_norm": 0.05681992694735527,
      "learning_rate": 4.369655172413794e-05,
      "loss": 0.0053,
      "step": 788
    },
    {
      "epoch": 13.60344827586207,
      "grad_norm": 0.18950824439525604,
      "learning_rate": 4.367586206896552e-05,
      "loss": 0.0097,
      "step": 789
    },
    {
      "epoch": 13.620689655172415,
      "grad_norm": 0.08171144127845764,
      "learning_rate": 4.36551724137931e-05,
      "loss": 0.0063,
      "step": 790
    },
    {
      "epoch": 13.637931034482758,
      "grad_norm": 0.0499359555542469,
      "learning_rate": 4.363448275862069e-05,
      "loss": 0.0037,
      "step": 791
    },
    {
      "epoch": 13.655172413793103,
      "grad_norm": 0.0663491040468216,
      "learning_rate": 4.3613793103448276e-05,
      "loss": 0.0053,
      "step": 792
    },
    {
      "epoch": 13.672413793103448,
      "grad_norm": 0.06597506254911423,
      "learning_rate": 4.359310344827586e-05,
      "loss": 0.006,
      "step": 793
    },
    {
      "epoch": 13.689655172413794,
      "grad_norm": 0.07391232997179031,
      "learning_rate": 4.357241379310345e-05,
      "loss": 0.006,
      "step": 794
    },
    {
      "epoch": 13.706896551724139,
      "grad_norm": 0.0741780698299408,
      "learning_rate": 4.355172413793103e-05,
      "loss": 0.0045,
      "step": 795
    },
    {
      "epoch": 13.724137931034482,
      "grad_norm": 0.050532665103673935,
      "learning_rate": 4.353103448275862e-05,
      "loss": 0.0045,
      "step": 796
    },
    {
      "epoch": 13.741379310344827,
      "grad_norm": 0.057596053928136826,
      "learning_rate": 4.351034482758621e-05,
      "loss": 0.0045,
      "step": 797
    },
    {
      "epoch": 13.758620689655173,
      "grad_norm": 0.08260490000247955,
      "learning_rate": 4.3489655172413795e-05,
      "loss": 0.0045,
      "step": 798
    },
    {
      "epoch": 13.775862068965518,
      "grad_norm": 0.08827582001686096,
      "learning_rate": 4.346896551724138e-05,
      "loss": 0.0066,
      "step": 799
    },
    {
      "epoch": 13.793103448275861,
      "grad_norm": 0.0748244896531105,
      "learning_rate": 4.344827586206897e-05,
      "loss": 0.0077,
      "step": 800
    },
    {
      "epoch": 13.793103448275861,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.005122161470353603,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.6925,
      "eval_samples_per_second": 3.336,
      "eval_steps_per_second": 1.726,
      "step": 800
    },
    {
      "epoch": 13.810344827586206,
      "grad_norm": 0.10034382343292236,
      "learning_rate": 4.342758620689655e-05,
      "loss": 0.0052,
      "step": 801
    },
    {
      "epoch": 13.827586206896552,
      "grad_norm": 0.1390276998281479,
      "learning_rate": 4.3406896551724135e-05,
      "loss": 0.0044,
      "step": 802
    },
    {
      "epoch": 13.844827586206897,
      "grad_norm": 0.11536306142807007,
      "learning_rate": 4.3386206896551724e-05,
      "loss": 0.0075,
      "step": 803
    },
    {
      "epoch": 13.862068965517242,
      "grad_norm": 0.035366423428058624,
      "learning_rate": 4.336551724137931e-05,
      "loss": 0.0032,
      "step": 804
    },
    {
      "epoch": 13.879310344827585,
      "grad_norm": 0.10042471438646317,
      "learning_rate": 4.33448275862069e-05,
      "loss": 0.0049,
      "step": 805
    },
    {
      "epoch": 13.89655172413793,
      "grad_norm": 0.09781850874423981,
      "learning_rate": 4.332413793103449e-05,
      "loss": 0.0067,
      "step": 806
    },
    {
      "epoch": 13.913793103448276,
      "grad_norm": 0.07550975680351257,
      "learning_rate": 4.330344827586207e-05,
      "loss": 0.0057,
      "step": 807
    },
    {
      "epoch": 13.931034482758621,
      "grad_norm": 0.3439065217971802,
      "learning_rate": 4.328275862068966e-05,
      "loss": 0.0099,
      "step": 808
    },
    {
      "epoch": 13.948275862068966,
      "grad_norm": 0.06271934509277344,
      "learning_rate": 4.3262068965517244e-05,
      "loss": 0.005,
      "step": 809
    },
    {
      "epoch": 13.96551724137931,
      "grad_norm": 0.07115679234266281,
      "learning_rate": 4.324137931034483e-05,
      "loss": 0.0073,
      "step": 810
    },
    {
      "epoch": 13.982758620689655,
      "grad_norm": 0.3044901490211487,
      "learning_rate": 4.3220689655172417e-05,
      "loss": 0.0113,
      "step": 811
    },
    {
      "epoch": 14.0,
      "grad_norm": 0.17518804967403412,
      "learning_rate": 4.32e-05,
      "loss": 0.0097,
      "step": 812
    },
    {
      "epoch": 14.017241379310345,
      "grad_norm": 0.08519960939884186,
      "learning_rate": 4.317931034482758e-05,
      "loss": 0.0081,
      "step": 813
    },
    {
      "epoch": 14.03448275862069,
      "grad_norm": 0.04681551828980446,
      "learning_rate": 4.315862068965517e-05,
      "loss": 0.0037,
      "step": 814
    },
    {
      "epoch": 14.051724137931034,
      "grad_norm": 0.11493570357561111,
      "learning_rate": 4.313793103448276e-05,
      "loss": 0.0066,
      "step": 815
    },
    {
      "epoch": 14.068965517241379,
      "grad_norm": 0.034339215606451035,
      "learning_rate": 4.3117241379310346e-05,
      "loss": 0.0028,
      "step": 816
    },
    {
      "epoch": 14.086206896551724,
      "grad_norm": 0.043965309858322144,
      "learning_rate": 4.3096551724137936e-05,
      "loss": 0.0044,
      "step": 817
    },
    {
      "epoch": 14.10344827586207,
      "grad_norm": 0.042641378939151764,
      "learning_rate": 4.307586206896552e-05,
      "loss": 0.0039,
      "step": 818
    },
    {
      "epoch": 14.120689655172415,
      "grad_norm": 0.09560345113277435,
      "learning_rate": 4.30551724137931e-05,
      "loss": 0.0052,
      "step": 819
    },
    {
      "epoch": 14.137931034482758,
      "grad_norm": 0.06876802444458008,
      "learning_rate": 4.303448275862069e-05,
      "loss": 0.005,
      "step": 820
    },
    {
      "epoch": 14.137931034482758,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.004585556220263243,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.9457,
      "eval_samples_per_second": 3.242,
      "eval_steps_per_second": 1.677,
      "step": 820
    },
    {
      "epoch": 14.155172413793103,
      "grad_norm": 0.050961073487997055,
      "learning_rate": 4.3013793103448275e-05,
      "loss": 0.0052,
      "step": 821
    },
    {
      "epoch": 14.172413793103448,
      "grad_norm": 0.08177189528942108,
      "learning_rate": 4.299310344827586e-05,
      "loss": 0.008,
      "step": 822
    },
    {
      "epoch": 14.189655172413794,
      "grad_norm": 0.07156089693307877,
      "learning_rate": 4.297241379310345e-05,
      "loss": 0.006,
      "step": 823
    },
    {
      "epoch": 14.206896551724139,
      "grad_norm": 0.07410553842782974,
      "learning_rate": 4.295172413793104e-05,
      "loss": 0.0042,
      "step": 824
    },
    {
      "epoch": 14.224137931034482,
      "grad_norm": 0.04931053891777992,
      "learning_rate": 4.293103448275862e-05,
      "loss": 0.004,
      "step": 825
    },
    {
      "epoch": 14.241379310344827,
      "grad_norm": 0.13434597849845886,
      "learning_rate": 4.291034482758621e-05,
      "loss": 0.0059,
      "step": 826
    },
    {
      "epoch": 14.258620689655173,
      "grad_norm": 0.09209731966257095,
      "learning_rate": 4.2889655172413794e-05,
      "loss": 0.0074,
      "step": 827
    },
    {
      "epoch": 14.275862068965518,
      "grad_norm": 0.061190515756607056,
      "learning_rate": 4.2868965517241384e-05,
      "loss": 0.0061,
      "step": 828
    },
    {
      "epoch": 14.293103448275861,
      "grad_norm": 0.08981835842132568,
      "learning_rate": 4.284827586206897e-05,
      "loss": 0.0058,
      "step": 829
    },
    {
      "epoch": 14.310344827586206,
      "grad_norm": 0.06741391867399216,
      "learning_rate": 4.282758620689655e-05,
      "loss": 0.0052,
      "step": 830
    },
    {
      "epoch": 14.327586206896552,
      "grad_norm": 0.1760634332895279,
      "learning_rate": 4.280689655172414e-05,
      "loss": 0.005,
      "step": 831
    },
    {
      "epoch": 14.344827586206897,
      "grad_norm": 0.03814764320850372,
      "learning_rate": 4.2786206896551723e-05,
      "loss": 0.0036,
      "step": 832
    },
    {
      "epoch": 14.362068965517242,
      "grad_norm": 0.10189128667116165,
      "learning_rate": 4.2765517241379307e-05,
      "loss": 0.0078,
      "step": 833
    },
    {
      "epoch": 14.379310344827585,
      "grad_norm": 0.0535925067961216,
      "learning_rate": 4.27448275862069e-05,
      "loss": 0.0043,
      "step": 834
    },
    {
      "epoch": 14.39655172413793,
      "grad_norm": 0.05763111263513565,
      "learning_rate": 4.2724137931034486e-05,
      "loss": 0.0058,
      "step": 835
    },
    {
      "epoch": 14.413793103448276,
      "grad_norm": 0.05741923674941063,
      "learning_rate": 4.270344827586207e-05,
      "loss": 0.0046,
      "step": 836
    },
    {
      "epoch": 14.431034482758621,
      "grad_norm": 0.06432224810123444,
      "learning_rate": 4.268275862068966e-05,
      "loss": 0.005,
      "step": 837
    },
    {
      "epoch": 14.448275862068966,
      "grad_norm": 0.050446514040231705,
      "learning_rate": 4.266206896551724e-05,
      "loss": 0.0048,
      "step": 838
    },
    {
      "epoch": 14.46551724137931,
      "grad_norm": 0.049184978008270264,
      "learning_rate": 4.2641379310344826e-05,
      "loss": 0.0041,
      "step": 839
    },
    {
      "epoch": 14.482758620689655,
      "grad_norm": 0.041377365589141846,
      "learning_rate": 4.2620689655172416e-05,
      "loss": 0.004,
      "step": 840
    },
    {
      "epoch": 14.482758620689655,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.004620902705937624,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.4269,
      "eval_samples_per_second": 3.441,
      "eval_steps_per_second": 1.78,
      "step": 840
    },
    {
      "epoch": 14.5,
      "grad_norm": 0.07879894971847534,
      "learning_rate": 4.26e-05,
      "loss": 0.0069,
      "step": 841
    },
    {
      "epoch": 14.517241379310345,
      "grad_norm": 0.05149497091770172,
      "learning_rate": 4.257931034482758e-05,
      "loss": 0.0035,
      "step": 842
    },
    {
      "epoch": 14.53448275862069,
      "grad_norm": 0.08251672238111496,
      "learning_rate": 4.255862068965518e-05,
      "loss": 0.0079,
      "step": 843
    },
    {
      "epoch": 14.551724137931034,
      "grad_norm": 0.06568274646997452,
      "learning_rate": 4.253793103448276e-05,
      "loss": 0.0046,
      "step": 844
    },
    {
      "epoch": 14.568965517241379,
      "grad_norm": 0.0752246081829071,
      "learning_rate": 4.2517241379310345e-05,
      "loss": 0.0077,
      "step": 845
    },
    {
      "epoch": 14.586206896551724,
      "grad_norm": 0.07858124375343323,
      "learning_rate": 4.2496551724137935e-05,
      "loss": 0.0054,
      "step": 846
    },
    {
      "epoch": 14.60344827586207,
      "grad_norm": 0.07442787289619446,
      "learning_rate": 4.247586206896552e-05,
      "loss": 0.0074,
      "step": 847
    },
    {
      "epoch": 14.620689655172415,
      "grad_norm": 0.08721695095300674,
      "learning_rate": 4.24551724137931e-05,
      "loss": 0.0048,
      "step": 848
    },
    {
      "epoch": 14.637931034482758,
      "grad_norm": 0.07242432236671448,
      "learning_rate": 4.243448275862069e-05,
      "loss": 0.0061,
      "step": 849
    },
    {
      "epoch": 14.655172413793103,
      "grad_norm": 0.05286097899079323,
      "learning_rate": 4.2413793103448274e-05,
      "loss": 0.0053,
      "step": 850
    },
    {
      "epoch": 14.672413793103448,
      "grad_norm": 0.10090957581996918,
      "learning_rate": 4.2393103448275864e-05,
      "loss": 0.0058,
      "step": 851
    },
    {
      "epoch": 14.689655172413794,
      "grad_norm": 0.07104857265949249,
      "learning_rate": 4.237241379310345e-05,
      "loss": 0.0029,
      "step": 852
    },
    {
      "epoch": 14.706896551724139,
      "grad_norm": 0.060921091586351395,
      "learning_rate": 4.235172413793104e-05,
      "loss": 0.0056,
      "step": 853
    },
    {
      "epoch": 14.724137931034482,
      "grad_norm": 0.060588594526052475,
      "learning_rate": 4.233103448275863e-05,
      "loss": 0.0049,
      "step": 854
    },
    {
      "epoch": 14.741379310344827,
      "grad_norm": 0.11539454013109207,
      "learning_rate": 4.231034482758621e-05,
      "loss": 0.0047,
      "step": 855
    },
    {
      "epoch": 14.758620689655173,
      "grad_norm": 0.048796262592077255,
      "learning_rate": 4.228965517241379e-05,
      "loss": 0.0046,
      "step": 856
    },
    {
      "epoch": 14.775862068965518,
      "grad_norm": 0.10022659599781036,
      "learning_rate": 4.226896551724138e-05,
      "loss": 0.0074,
      "step": 857
    },
    {
      "epoch": 14.793103448275861,
      "grad_norm": 0.05276019871234894,
      "learning_rate": 4.2248275862068966e-05,
      "loss": 0.0054,
      "step": 858
    },
    {
      "epoch": 14.810344827586206,
      "grad_norm": 0.09313315898180008,
      "learning_rate": 4.222758620689655e-05,
      "loss": 0.0052,
      "step": 859
    },
    {
      "epoch": 14.827586206896552,
      "grad_norm": 0.15325042605400085,
      "learning_rate": 4.220689655172414e-05,
      "loss": 0.0072,
      "step": 860
    },
    {
      "epoch": 14.827586206896552,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.004870945122092962,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.0738,
      "eval_samples_per_second": 3.196,
      "eval_steps_per_second": 1.653,
      "step": 860
    },
    {
      "epoch": 14.844827586206897,
      "grad_norm": 0.06361045688390732,
      "learning_rate": 4.218620689655172e-05,
      "loss": 0.0057,
      "step": 861
    },
    {
      "epoch": 14.862068965517242,
      "grad_norm": 0.050462473183870316,
      "learning_rate": 4.216551724137931e-05,
      "loss": 0.0043,
      "step": 862
    },
    {
      "epoch": 14.879310344827585,
      "grad_norm": 0.07308340072631836,
      "learning_rate": 4.21448275862069e-05,
      "loss": 0.0075,
      "step": 863
    },
    {
      "epoch": 14.89655172413793,
      "grad_norm": 0.04954228177666664,
      "learning_rate": 4.2124137931034485e-05,
      "loss": 0.0037,
      "step": 864
    },
    {
      "epoch": 14.913793103448276,
      "grad_norm": 0.09911367297172546,
      "learning_rate": 4.210344827586207e-05,
      "loss": 0.0048,
      "step": 865
    },
    {
      "epoch": 14.931034482758621,
      "grad_norm": 0.14802785217761993,
      "learning_rate": 4.208275862068966e-05,
      "loss": 0.0071,
      "step": 866
    },
    {
      "epoch": 14.948275862068966,
      "grad_norm": 0.1275896430015564,
      "learning_rate": 4.206206896551724e-05,
      "loss": 0.007,
      "step": 867
    },
    {
      "epoch": 14.96551724137931,
      "grad_norm": 0.07656104117631912,
      "learning_rate": 4.2041379310344825e-05,
      "loss": 0.0046,
      "step": 868
    },
    {
      "epoch": 14.982758620689655,
      "grad_norm": 0.11417613923549652,
      "learning_rate": 4.2020689655172415e-05,
      "loss": 0.0068,
      "step": 869
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.08659986406564713,
      "learning_rate": 4.2e-05,
      "loss": 0.0059,
      "step": 870
    },
    {
      "epoch": 15.017241379310345,
      "grad_norm": 0.05519111454486847,
      "learning_rate": 4.197931034482759e-05,
      "loss": 0.0038,
      "step": 871
    },
    {
      "epoch": 15.03448275862069,
      "grad_norm": 0.6090088486671448,
      "learning_rate": 4.195862068965518e-05,
      "loss": 0.0054,
      "step": 872
    },
    {
      "epoch": 15.051724137931034,
      "grad_norm": 0.04146464541554451,
      "learning_rate": 4.193793103448276e-05,
      "loss": 0.0031,
      "step": 873
    },
    {
      "epoch": 15.068965517241379,
      "grad_norm": 0.03708762675523758,
      "learning_rate": 4.1917241379310344e-05,
      "loss": 0.0033,
      "step": 874
    },
    {
      "epoch": 15.086206896551724,
      "grad_norm": 0.07749588787555695,
      "learning_rate": 4.1896551724137934e-05,
      "loss": 0.0052,
      "step": 875
    },
    {
      "epoch": 15.10344827586207,
      "grad_norm": 0.057184286415576935,
      "learning_rate": 4.187586206896552e-05,
      "loss": 0.0056,
      "step": 876
    },
    {
      "epoch": 15.120689655172415,
      "grad_norm": 0.12088718265295029,
      "learning_rate": 4.185517241379311e-05,
      "loss": 0.0068,
      "step": 877
    },
    {
      "epoch": 15.137931034482758,
      "grad_norm": 0.043603066354990005,
      "learning_rate": 4.183448275862069e-05,
      "loss": 0.0039,
      "step": 878
    },
    {
      "epoch": 15.155172413793103,
      "grad_norm": 0.049977488815784454,
      "learning_rate": 4.181379310344827e-05,
      "loss": 0.0043,
      "step": 879
    },
    {
      "epoch": 15.172413793103448,
      "grad_norm": 0.052111007273197174,
      "learning_rate": 4.179310344827586e-05,
      "loss": 0.0051,
      "step": 880
    },
    {
      "epoch": 15.172413793103448,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.004209564067423344,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.9195,
      "eval_samples_per_second": 2.924,
      "eval_steps_per_second": 1.512,
      "step": 880
    },
    {
      "epoch": 15.189655172413794,
      "grad_norm": 0.05833909288048744,
      "learning_rate": 4.177241379310345e-05,
      "loss": 0.0031,
      "step": 881
    },
    {
      "epoch": 15.206896551724139,
      "grad_norm": 0.06829480081796646,
      "learning_rate": 4.1751724137931036e-05,
      "loss": 0.0054,
      "step": 882
    },
    {
      "epoch": 15.224137931034482,
      "grad_norm": 0.05156315863132477,
      "learning_rate": 4.1731034482758626e-05,
      "loss": 0.0039,
      "step": 883
    },
    {
      "epoch": 15.241379310344827,
      "grad_norm": 0.07327450811862946,
      "learning_rate": 4.171034482758621e-05,
      "loss": 0.006,
      "step": 884
    },
    {
      "epoch": 15.258620689655173,
      "grad_norm": 0.048308927565813065,
      "learning_rate": 4.168965517241379e-05,
      "loss": 0.0033,
      "step": 885
    },
    {
      "epoch": 15.275862068965518,
      "grad_norm": 0.05911055952310562,
      "learning_rate": 4.166896551724138e-05,
      "loss": 0.0053,
      "step": 886
    },
    {
      "epoch": 15.293103448275861,
      "grad_norm": 0.055242907255887985,
      "learning_rate": 4.1648275862068965e-05,
      "loss": 0.0048,
      "step": 887
    },
    {
      "epoch": 15.310344827586206,
      "grad_norm": 0.047223806381225586,
      "learning_rate": 4.162758620689655e-05,
      "loss": 0.0047,
      "step": 888
    },
    {
      "epoch": 15.327586206896552,
      "grad_norm": 0.0882505476474762,
      "learning_rate": 4.160689655172414e-05,
      "loss": 0.0074,
      "step": 889
    },
    {
      "epoch": 15.344827586206897,
      "grad_norm": 0.0538211390376091,
      "learning_rate": 4.158620689655173e-05,
      "loss": 0.0036,
      "step": 890
    },
    {
      "epoch": 15.362068965517242,
      "grad_norm": 0.08144800364971161,
      "learning_rate": 4.156551724137931e-05,
      "loss": 0.0045,
      "step": 891
    },
    {
      "epoch": 15.379310344827585,
      "grad_norm": 0.31106850504875183,
      "learning_rate": 4.15448275862069e-05,
      "loss": 0.0068,
      "step": 892
    },
    {
      "epoch": 15.39655172413793,
      "grad_norm": 0.07559525221586227,
      "learning_rate": 4.1524137931034484e-05,
      "loss": 0.0061,
      "step": 893
    },
    {
      "epoch": 15.413793103448276,
      "grad_norm": 0.05533207952976227,
      "learning_rate": 4.150344827586207e-05,
      "loss": 0.0048,
      "step": 894
    },
    {
      "epoch": 15.431034482758621,
      "grad_norm": 0.12624844908714294,
      "learning_rate": 4.148275862068966e-05,
      "loss": 0.0068,
      "step": 895
    },
    {
      "epoch": 15.448275862068966,
      "grad_norm": 0.10096853971481323,
      "learning_rate": 4.146206896551724e-05,
      "loss": 0.0066,
      "step": 896
    },
    {
      "epoch": 15.46551724137931,
      "grad_norm": 0.046796731650829315,
      "learning_rate": 4.1441379310344824e-05,
      "loss": 0.0037,
      "step": 897
    },
    {
      "epoch": 15.482758620689655,
      "grad_norm": 0.0654153898358345,
      "learning_rate": 4.1420689655172414e-05,
      "loss": 0.0043,
      "step": 898
    },
    {
      "epoch": 15.5,
      "grad_norm": 0.09604702889919281,
      "learning_rate": 4.14e-05,
      "loss": 0.0046,
      "step": 899
    },
    {
      "epoch": 15.517241379310345,
      "grad_norm": 0.05298566445708275,
      "learning_rate": 4.137931034482759e-05,
      "loss": 0.0033,
      "step": 900
    },
    {
      "epoch": 15.517241379310345,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.004267864860594273,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.2135,
      "eval_samples_per_second": 2.839,
      "eval_steps_per_second": 1.469,
      "step": 900
    },
    {
      "epoch": 15.53448275862069,
      "grad_norm": 0.061416950076818466,
      "learning_rate": 4.1358620689655176e-05,
      "loss": 0.0051,
      "step": 901
    },
    {
      "epoch": 15.551724137931034,
      "grad_norm": 0.05721345543861389,
      "learning_rate": 4.133793103448276e-05,
      "loss": 0.0049,
      "step": 902
    },
    {
      "epoch": 15.568965517241379,
      "grad_norm": 0.031454604119062424,
      "learning_rate": 4.131724137931035e-05,
      "loss": 0.003,
      "step": 903
    },
    {
      "epoch": 15.586206896551724,
      "grad_norm": 0.06580840796232224,
      "learning_rate": 4.129655172413793e-05,
      "loss": 0.0062,
      "step": 904
    },
    {
      "epoch": 15.60344827586207,
      "grad_norm": 0.06013176217675209,
      "learning_rate": 4.1275862068965516e-05,
      "loss": 0.0059,
      "step": 905
    },
    {
      "epoch": 15.620689655172415,
      "grad_norm": 0.08393384516239166,
      "learning_rate": 4.1255172413793106e-05,
      "loss": 0.0045,
      "step": 906
    },
    {
      "epoch": 15.637931034482758,
      "grad_norm": 0.09592378884553909,
      "learning_rate": 4.123448275862069e-05,
      "loss": 0.0052,
      "step": 907
    },
    {
      "epoch": 15.655172413793103,
      "grad_norm": 0.040977269411087036,
      "learning_rate": 4.121379310344827e-05,
      "loss": 0.0039,
      "step": 908
    },
    {
      "epoch": 15.672413793103448,
      "grad_norm": 0.024187391623854637,
      "learning_rate": 4.119310344827587e-05,
      "loss": 0.0019,
      "step": 909
    },
    {
      "epoch": 15.689655172413794,
      "grad_norm": 0.052552755922079086,
      "learning_rate": 4.117241379310345e-05,
      "loss": 0.0044,
      "step": 910
    },
    {
      "epoch": 15.706896551724139,
      "grad_norm": 0.0647520199418068,
      "learning_rate": 4.1151724137931035e-05,
      "loss": 0.0037,
      "step": 911
    },
    {
      "epoch": 15.724137931034482,
      "grad_norm": 0.10352949053049088,
      "learning_rate": 4.1131034482758625e-05,
      "loss": 0.0043,
      "step": 912
    },
    {
      "epoch": 15.741379310344827,
      "grad_norm": 0.03576328977942467,
      "learning_rate": 4.111034482758621e-05,
      "loss": 0.0033,
      "step": 913
    },
    {
      "epoch": 15.758620689655173,
      "grad_norm": 0.10461591184139252,
      "learning_rate": 4.108965517241379e-05,
      "loss": 0.0054,
      "step": 914
    },
    {
      "epoch": 15.775862068965518,
      "grad_norm": 0.09744016826152802,
      "learning_rate": 4.106896551724138e-05,
      "loss": 0.0053,
      "step": 915
    },
    {
      "epoch": 15.793103448275861,
      "grad_norm": 0.06960341334342957,
      "learning_rate": 4.1048275862068964e-05,
      "loss": 0.0061,
      "step": 916
    },
    {
      "epoch": 15.810344827586206,
      "grad_norm": 0.05662506818771362,
      "learning_rate": 4.102758620689655e-05,
      "loss": 0.0054,
      "step": 917
    },
    {
      "epoch": 15.827586206896552,
      "grad_norm": 0.07828154414892197,
      "learning_rate": 4.100689655172414e-05,
      "loss": 0.0056,
      "step": 918
    },
    {
      "epoch": 15.844827586206897,
      "grad_norm": 0.0771837830543518,
      "learning_rate": 4.098620689655173e-05,
      "loss": 0.0063,
      "step": 919
    },
    {
      "epoch": 15.862068965517242,
      "grad_norm": 0.08726174384355545,
      "learning_rate": 4.096551724137931e-05,
      "loss": 0.0059,
      "step": 920
    },
    {
      "epoch": 15.862068965517242,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0043921093456447124,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.3612,
      "eval_samples_per_second": 3.468,
      "eval_steps_per_second": 1.794,
      "step": 920
    },
    {
      "epoch": 15.879310344827585,
      "grad_norm": 0.05633120611310005,
      "learning_rate": 4.09448275862069e-05,
      "loss": 0.004,
      "step": 921
    },
    {
      "epoch": 15.89655172413793,
      "grad_norm": 0.056090347468853,
      "learning_rate": 4.092413793103448e-05,
      "loss": 0.0052,
      "step": 922
    },
    {
      "epoch": 15.913793103448276,
      "grad_norm": 0.05858136713504791,
      "learning_rate": 4.090344827586207e-05,
      "loss": 0.0053,
      "step": 923
    },
    {
      "epoch": 15.931034482758621,
      "grad_norm": 0.05998356267809868,
      "learning_rate": 4.0882758620689656e-05,
      "loss": 0.0061,
      "step": 924
    },
    {
      "epoch": 15.948275862068966,
      "grad_norm": 0.10148802399635315,
      "learning_rate": 4.086206896551724e-05,
      "loss": 0.0066,
      "step": 925
    },
    {
      "epoch": 15.96551724137931,
      "grad_norm": 0.031389713287353516,
      "learning_rate": 4.084137931034483e-05,
      "loss": 0.0029,
      "step": 926
    },
    {
      "epoch": 15.982758620689655,
      "grad_norm": 0.07443412393331528,
      "learning_rate": 4.082068965517241e-05,
      "loss": 0.0041,
      "step": 927
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.04598313570022583,
      "learning_rate": 4.08e-05,
      "loss": 0.0045,
      "step": 928
    },
    {
      "epoch": 16.017241379310345,
      "grad_norm": 0.08524538576602936,
      "learning_rate": 4.077931034482759e-05,
      "loss": 0.005,
      "step": 929
    },
    {
      "epoch": 16.03448275862069,
      "grad_norm": 0.0437539778649807,
      "learning_rate": 4.0758620689655175e-05,
      "loss": 0.0043,
      "step": 930
    },
    {
      "epoch": 16.051724137931036,
      "grad_norm": 0.05617450922727585,
      "learning_rate": 4.073793103448276e-05,
      "loss": 0.0046,
      "step": 931
    },
    {
      "epoch": 16.06896551724138,
      "grad_norm": 0.05820491164922714,
      "learning_rate": 4.071724137931035e-05,
      "loss": 0.0049,
      "step": 932
    },
    {
      "epoch": 16.086206896551722,
      "grad_norm": 0.05088185891509056,
      "learning_rate": 4.069655172413793e-05,
      "loss": 0.0025,
      "step": 933
    },
    {
      "epoch": 16.103448275862068,
      "grad_norm": 0.05694461613893509,
      "learning_rate": 4.0675862068965515e-05,
      "loss": 0.0053,
      "step": 934
    },
    {
      "epoch": 16.120689655172413,
      "grad_norm": 0.03403357416391373,
      "learning_rate": 4.0655172413793105e-05,
      "loss": 0.0032,
      "step": 935
    },
    {
      "epoch": 16.137931034482758,
      "grad_norm": 0.042849402874708176,
      "learning_rate": 4.063448275862069e-05,
      "loss": 0.0041,
      "step": 936
    },
    {
      "epoch": 16.155172413793103,
      "grad_norm": 0.13871349394321442,
      "learning_rate": 4.061379310344828e-05,
      "loss": 0.0076,
      "step": 937
    },
    {
      "epoch": 16.17241379310345,
      "grad_norm": 0.12506306171417236,
      "learning_rate": 4.059310344827587e-05,
      "loss": 0.0069,
      "step": 938
    },
    {
      "epoch": 16.189655172413794,
      "grad_norm": 0.07817864418029785,
      "learning_rate": 4.057241379310345e-05,
      "loss": 0.0045,
      "step": 939
    },
    {
      "epoch": 16.20689655172414,
      "grad_norm": 0.026231959462165833,
      "learning_rate": 4.0551724137931034e-05,
      "loss": 0.0023,
      "step": 940
    },
    {
      "epoch": 16.20689655172414,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.003943799063563347,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.4429,
      "eval_samples_per_second": 3.435,
      "eval_steps_per_second": 1.777,
      "step": 940
    },
    {
      "epoch": 16.224137931034484,
      "grad_norm": 0.07435853034257889,
      "learning_rate": 4.0531034482758624e-05,
      "loss": 0.007,
      "step": 941
    },
    {
      "epoch": 16.24137931034483,
      "grad_norm": 0.0623687244951725,
      "learning_rate": 4.051034482758621e-05,
      "loss": 0.0058,
      "step": 942
    },
    {
      "epoch": 16.25862068965517,
      "grad_norm": 0.04657283052802086,
      "learning_rate": 4.048965517241379e-05,
      "loss": 0.0049,
      "step": 943
    },
    {
      "epoch": 16.275862068965516,
      "grad_norm": 0.056520428508520126,
      "learning_rate": 4.046896551724138e-05,
      "loss": 0.0052,
      "step": 944
    },
    {
      "epoch": 16.29310344827586,
      "grad_norm": 0.04338293522596359,
      "learning_rate": 4.044827586206896e-05,
      "loss": 0.0038,
      "step": 945
    },
    {
      "epoch": 16.310344827586206,
      "grad_norm": 0.048331938683986664,
      "learning_rate": 4.0427586206896546e-05,
      "loss": 0.004,
      "step": 946
    },
    {
      "epoch": 16.32758620689655,
      "grad_norm": 0.03357885777950287,
      "learning_rate": 4.040689655172414e-05,
      "loss": 0.0029,
      "step": 947
    },
    {
      "epoch": 16.344827586206897,
      "grad_norm": 0.07164300978183746,
      "learning_rate": 4.0386206896551726e-05,
      "loss": 0.0064,
      "step": 948
    },
    {
      "epoch": 16.362068965517242,
      "grad_norm": 0.07193437218666077,
      "learning_rate": 4.0365517241379316e-05,
      "loss": 0.0036,
      "step": 949
    },
    {
      "epoch": 16.379310344827587,
      "grad_norm": 0.030405094847083092,
      "learning_rate": 4.03448275862069e-05,
      "loss": 0.0028,
      "step": 950
    },
    {
      "epoch": 16.396551724137932,
      "grad_norm": 0.06363413482904434,
      "learning_rate": 4.032413793103448e-05,
      "loss": 0.0061,
      "step": 951
    },
    {
      "epoch": 16.413793103448278,
      "grad_norm": 0.04165142402052879,
      "learning_rate": 4.030344827586207e-05,
      "loss": 0.0033,
      "step": 952
    },
    {
      "epoch": 16.43103448275862,
      "grad_norm": 0.052524346858263016,
      "learning_rate": 4.0282758620689655e-05,
      "loss": 0.0051,
      "step": 953
    },
    {
      "epoch": 16.448275862068964,
      "grad_norm": 0.035324398428201675,
      "learning_rate": 4.026206896551724e-05,
      "loss": 0.0033,
      "step": 954
    },
    {
      "epoch": 16.46551724137931,
      "grad_norm": 0.03961443528532982,
      "learning_rate": 4.024137931034483e-05,
      "loss": 0.0038,
      "step": 955
    },
    {
      "epoch": 16.482758620689655,
      "grad_norm": 0.04158766195178032,
      "learning_rate": 4.022068965517242e-05,
      "loss": 0.004,
      "step": 956
    },
    {
      "epoch": 16.5,
      "grad_norm": 0.05320565402507782,
      "learning_rate": 4.02e-05,
      "loss": 0.0044,
      "step": 957
    },
    {
      "epoch": 16.517241379310345,
      "grad_norm": 0.07013868540525436,
      "learning_rate": 4.017931034482759e-05,
      "loss": 0.0041,
      "step": 958
    },
    {
      "epoch": 16.53448275862069,
      "grad_norm": 0.08375832438468933,
      "learning_rate": 4.0158620689655174e-05,
      "loss": 0.005,
      "step": 959
    },
    {
      "epoch": 16.551724137931036,
      "grad_norm": 0.04439813271164894,
      "learning_rate": 4.013793103448276e-05,
      "loss": 0.0047,
      "step": 960
    },
    {
      "epoch": 16.551724137931036,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.004028584808111191,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.5276,
      "eval_samples_per_second": 3.401,
      "eval_steps_per_second": 1.759,
      "step": 960
    },
    {
      "epoch": 16.56896551724138,
      "grad_norm": 0.02495318278670311,
      "learning_rate": 4.011724137931035e-05,
      "loss": 0.0022,
      "step": 961
    },
    {
      "epoch": 16.586206896551722,
      "grad_norm": 0.04298447445034981,
      "learning_rate": 4.009655172413793e-05,
      "loss": 0.0041,
      "step": 962
    },
    {
      "epoch": 16.603448275862068,
      "grad_norm": 0.04848010092973709,
      "learning_rate": 4.0075862068965514e-05,
      "loss": 0.0045,
      "step": 963
    },
    {
      "epoch": 16.620689655172413,
      "grad_norm": 0.07723523676395416,
      "learning_rate": 4.0055172413793104e-05,
      "loss": 0.006,
      "step": 964
    },
    {
      "epoch": 16.637931034482758,
      "grad_norm": 0.06779264658689499,
      "learning_rate": 4.003448275862069e-05,
      "loss": 0.0049,
      "step": 965
    },
    {
      "epoch": 16.655172413793103,
      "grad_norm": 0.06295154243707657,
      "learning_rate": 4.001379310344828e-05,
      "loss": 0.0047,
      "step": 966
    },
    {
      "epoch": 16.67241379310345,
      "grad_norm": 0.040714461356401443,
      "learning_rate": 3.9993103448275867e-05,
      "loss": 0.004,
      "step": 967
    },
    {
      "epoch": 16.689655172413794,
      "grad_norm": 0.0371246412396431,
      "learning_rate": 3.997241379310345e-05,
      "loss": 0.0031,
      "step": 968
    },
    {
      "epoch": 16.70689655172414,
      "grad_norm": 0.03170233219861984,
      "learning_rate": 3.995172413793103e-05,
      "loss": 0.0026,
      "step": 969
    },
    {
      "epoch": 16.724137931034484,
      "grad_norm": 0.06659521162509918,
      "learning_rate": 3.993103448275862e-05,
      "loss": 0.0034,
      "step": 970
    },
    {
      "epoch": 16.74137931034483,
      "grad_norm": 0.052850931882858276,
      "learning_rate": 3.9910344827586206e-05,
      "loss": 0.0047,
      "step": 971
    },
    {
      "epoch": 16.75862068965517,
      "grad_norm": 0.040628235787153244,
      "learning_rate": 3.9889655172413796e-05,
      "loss": 0.004,
      "step": 972
    },
    {
      "epoch": 16.775862068965516,
      "grad_norm": 0.03658395633101463,
      "learning_rate": 3.986896551724138e-05,
      "loss": 0.0037,
      "step": 973
    },
    {
      "epoch": 16.79310344827586,
      "grad_norm": 0.03538547083735466,
      "learning_rate": 3.984827586206896e-05,
      "loss": 0.0031,
      "step": 974
    },
    {
      "epoch": 16.810344827586206,
      "grad_norm": 0.05527175962924957,
      "learning_rate": 3.982758620689656e-05,
      "loss": 0.004,
      "step": 975
    },
    {
      "epoch": 16.82758620689655,
      "grad_norm": 0.04356396198272705,
      "learning_rate": 3.980689655172414e-05,
      "loss": 0.0029,
      "step": 976
    },
    {
      "epoch": 16.844827586206897,
      "grad_norm": 0.04916846752166748,
      "learning_rate": 3.9786206896551725e-05,
      "loss": 0.0052,
      "step": 977
    },
    {
      "epoch": 16.862068965517242,
      "grad_norm": 0.0357215516269207,
      "learning_rate": 3.9765517241379315e-05,
      "loss": 0.0033,
      "step": 978
    },
    {
      "epoch": 16.879310344827587,
      "grad_norm": 0.07285535335540771,
      "learning_rate": 3.97448275862069e-05,
      "loss": 0.0057,
      "step": 979
    },
    {
      "epoch": 16.896551724137932,
      "grad_norm": 0.07558795064687729,
      "learning_rate": 3.972413793103448e-05,
      "loss": 0.0039,
      "step": 980
    },
    {
      "epoch": 16.896551724137932,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.003540806472301483,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.6322,
      "eval_samples_per_second": 3.359,
      "eval_steps_per_second": 1.738,
      "step": 980
    },
    {
      "epoch": 16.913793103448278,
      "grad_norm": 0.05823678523302078,
      "learning_rate": 3.970344827586207e-05,
      "loss": 0.0047,
      "step": 981
    },
    {
      "epoch": 16.93103448275862,
      "grad_norm": 0.051977742463350296,
      "learning_rate": 3.9682758620689654e-05,
      "loss": 0.0041,
      "step": 982
    },
    {
      "epoch": 16.948275862068964,
      "grad_norm": 0.04155542701482773,
      "learning_rate": 3.966206896551724e-05,
      "loss": 0.0041,
      "step": 983
    },
    {
      "epoch": 16.96551724137931,
      "grad_norm": 0.03300682082772255,
      "learning_rate": 3.9641379310344834e-05,
      "loss": 0.0028,
      "step": 984
    },
    {
      "epoch": 16.982758620689655,
      "grad_norm": 0.04227842390537262,
      "learning_rate": 3.962068965517242e-05,
      "loss": 0.0039,
      "step": 985
    },
    {
      "epoch": 17.0,
      "grad_norm": 0.06722413003444672,
      "learning_rate": 3.96e-05,
      "loss": 0.0031,
      "step": 986
    },
    {
      "epoch": 17.017241379310345,
      "grad_norm": 0.033249519765377045,
      "learning_rate": 3.957931034482759e-05,
      "loss": 0.0022,
      "step": 987
    },
    {
      "epoch": 17.03448275862069,
      "grad_norm": 0.03409239277243614,
      "learning_rate": 3.955862068965517e-05,
      "loss": 0.0031,
      "step": 988
    },
    {
      "epoch": 17.051724137931036,
      "grad_norm": 0.07734674960374832,
      "learning_rate": 3.9537931034482757e-05,
      "loss": 0.0042,
      "step": 989
    },
    {
      "epoch": 17.06896551724138,
      "grad_norm": 0.06488324701786041,
      "learning_rate": 3.9517241379310346e-05,
      "loss": 0.0055,
      "step": 990
    },
    {
      "epoch": 17.086206896551722,
      "grad_norm": 0.05269408971071243,
      "learning_rate": 3.949655172413793e-05,
      "loss": 0.003,
      "step": 991
    },
    {
      "epoch": 17.103448275862068,
      "grad_norm": 0.09001171588897705,
      "learning_rate": 3.947586206896551e-05,
      "loss": 0.0079,
      "step": 992
    },
    {
      "epoch": 17.120689655172413,
      "grad_norm": 0.032260749489068985,
      "learning_rate": 3.94551724137931e-05,
      "loss": 0.0029,
      "step": 993
    },
    {
      "epoch": 17.137931034482758,
      "grad_norm": 0.061663903295993805,
      "learning_rate": 3.943448275862069e-05,
      "loss": 0.0048,
      "step": 994
    },
    {
      "epoch": 17.155172413793103,
      "grad_norm": 0.04696168750524521,
      "learning_rate": 3.9413793103448276e-05,
      "loss": 0.0041,
      "step": 995
    },
    {
      "epoch": 17.17241379310345,
      "grad_norm": 0.07780812680721283,
      "learning_rate": 3.9393103448275866e-05,
      "loss": 0.0048,
      "step": 996
    },
    {
      "epoch": 17.189655172413794,
      "grad_norm": 0.135153129696846,
      "learning_rate": 3.937241379310345e-05,
      "loss": 0.0058,
      "step": 997
    },
    {
      "epoch": 17.20689655172414,
      "grad_norm": 0.045066770166158676,
      "learning_rate": 3.935172413793104e-05,
      "loss": 0.004,
      "step": 998
    },
    {
      "epoch": 17.224137931034484,
      "grad_norm": 0.07432086020708084,
      "learning_rate": 3.933103448275862e-05,
      "loss": 0.0047,
      "step": 999
    },
    {
      "epoch": 17.24137931034483,
      "grad_norm": 0.043018922209739685,
      "learning_rate": 3.9310344827586205e-05,
      "loss": 0.0034,
      "step": 1000
    },
    {
      "epoch": 17.24137931034483,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0038009481504559517,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.5503,
      "eval_samples_per_second": 3.037,
      "eval_steps_per_second": 1.571,
      "step": 1000
    },
    {
      "epoch": 17.25862068965517,
      "grad_norm": 0.03598417341709137,
      "learning_rate": 3.9289655172413795e-05,
      "loss": 0.0025,
      "step": 1001
    },
    {
      "epoch": 17.275862068965516,
      "grad_norm": 0.08526626229286194,
      "learning_rate": 3.926896551724138e-05,
      "loss": 0.0061,
      "step": 1002
    },
    {
      "epoch": 17.29310344827586,
      "grad_norm": 0.0881599634885788,
      "learning_rate": 3.924827586206897e-05,
      "loss": 0.0051,
      "step": 1003
    },
    {
      "epoch": 17.310344827586206,
      "grad_norm": 0.034475646913051605,
      "learning_rate": 3.922758620689656e-05,
      "loss": 0.0026,
      "step": 1004
    },
    {
      "epoch": 17.32758620689655,
      "grad_norm": 0.04010079428553581,
      "learning_rate": 3.920689655172414e-05,
      "loss": 0.0024,
      "step": 1005
    },
    {
      "epoch": 17.344827586206897,
      "grad_norm": 0.0483938492834568,
      "learning_rate": 3.9186206896551724e-05,
      "loss": 0.0038,
      "step": 1006
    },
    {
      "epoch": 17.362068965517242,
      "grad_norm": 0.05378606915473938,
      "learning_rate": 3.9165517241379314e-05,
      "loss": 0.0058,
      "step": 1007
    },
    {
      "epoch": 17.379310344827587,
      "grad_norm": 0.03956769034266472,
      "learning_rate": 3.91448275862069e-05,
      "loss": 0.0037,
      "step": 1008
    },
    {
      "epoch": 17.396551724137932,
      "grad_norm": 0.09169023483991623,
      "learning_rate": 3.912413793103448e-05,
      "loss": 0.0057,
      "step": 1009
    },
    {
      "epoch": 17.413793103448278,
      "grad_norm": 0.055994290858507156,
      "learning_rate": 3.910344827586207e-05,
      "loss": 0.0036,
      "step": 1010
    },
    {
      "epoch": 17.43103448275862,
      "grad_norm": 0.04682931676506996,
      "learning_rate": 3.908275862068965e-05,
      "loss": 0.0042,
      "step": 1011
    },
    {
      "epoch": 17.448275862068964,
      "grad_norm": 0.04802046716213226,
      "learning_rate": 3.9062068965517236e-05,
      "loss": 0.0042,
      "step": 1012
    },
    {
      "epoch": 17.46551724137931,
      "grad_norm": 0.03580319881439209,
      "learning_rate": 3.904137931034483e-05,
      "loss": 0.0034,
      "step": 1013
    },
    {
      "epoch": 17.482758620689655,
      "grad_norm": 0.07708680629730225,
      "learning_rate": 3.9020689655172416e-05,
      "loss": 0.0029,
      "step": 1014
    },
    {
      "epoch": 17.5,
      "grad_norm": 0.07488889247179031,
      "learning_rate": 3.9e-05,
      "loss": 0.0044,
      "step": 1015
    },
    {
      "epoch": 17.517241379310345,
      "grad_norm": 0.0670439749956131,
      "learning_rate": 3.897931034482759e-05,
      "loss": 0.0047,
      "step": 1016
    },
    {
      "epoch": 17.53448275862069,
      "grad_norm": 0.0641707181930542,
      "learning_rate": 3.895862068965517e-05,
      "loss": 0.0039,
      "step": 1017
    },
    {
      "epoch": 17.551724137931036,
      "grad_norm": 0.08956345915794373,
      "learning_rate": 3.8937931034482755e-05,
      "loss": 0.0038,
      "step": 1018
    },
    {
      "epoch": 17.56896551724138,
      "grad_norm": 0.11391503363847733,
      "learning_rate": 3.8917241379310345e-05,
      "loss": 0.0058,
      "step": 1019
    },
    {
      "epoch": 17.586206896551722,
      "grad_norm": 0.05282624810934067,
      "learning_rate": 3.889655172413793e-05,
      "loss": 0.0054,
      "step": 1020
    },
    {
      "epoch": 17.586206896551722,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.003678488777950406,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.4305,
      "eval_samples_per_second": 3.075,
      "eval_steps_per_second": 1.591,
      "step": 1020
    },
    {
      "epoch": 17.603448275862068,
      "grad_norm": 0.0457373782992363,
      "learning_rate": 3.887586206896552e-05,
      "loss": 0.0046,
      "step": 1021
    },
    {
      "epoch": 17.620689655172413,
      "grad_norm": 0.049380600452423096,
      "learning_rate": 3.885517241379311e-05,
      "loss": 0.0049,
      "step": 1022
    },
    {
      "epoch": 17.637931034482758,
      "grad_norm": 0.03094581700861454,
      "learning_rate": 3.883448275862069e-05,
      "loss": 0.0027,
      "step": 1023
    },
    {
      "epoch": 17.655172413793103,
      "grad_norm": 0.08143551647663116,
      "learning_rate": 3.881379310344828e-05,
      "loss": 0.0046,
      "step": 1024
    },
    {
      "epoch": 17.67241379310345,
      "grad_norm": 0.033937133848667145,
      "learning_rate": 3.8793103448275865e-05,
      "loss": 0.002,
      "step": 1025
    },
    {
      "epoch": 17.689655172413794,
      "grad_norm": 0.044693849980831146,
      "learning_rate": 3.877241379310345e-05,
      "loss": 0.0042,
      "step": 1026
    },
    {
      "epoch": 17.70689655172414,
      "grad_norm": 0.06886967271566391,
      "learning_rate": 3.875172413793104e-05,
      "loss": 0.0039,
      "step": 1027
    },
    {
      "epoch": 17.724137931034484,
      "grad_norm": 0.041816771030426025,
      "learning_rate": 3.873103448275862e-05,
      "loss": 0.0038,
      "step": 1028
    },
    {
      "epoch": 17.74137931034483,
      "grad_norm": 0.06484247744083405,
      "learning_rate": 3.8710344827586204e-05,
      "loss": 0.0051,
      "step": 1029
    },
    {
      "epoch": 17.75862068965517,
      "grad_norm": 0.06607486307621002,
      "learning_rate": 3.8689655172413794e-05,
      "loss": 0.0056,
      "step": 1030
    },
    {
      "epoch": 17.775862068965516,
      "grad_norm": 0.0347323939204216,
      "learning_rate": 3.866896551724138e-05,
      "loss": 0.0034,
      "step": 1031
    },
    {
      "epoch": 17.79310344827586,
      "grad_norm": 0.07228995114564896,
      "learning_rate": 3.864827586206897e-05,
      "loss": 0.0038,
      "step": 1032
    },
    {
      "epoch": 17.810344827586206,
      "grad_norm": 0.020133553072810173,
      "learning_rate": 3.862758620689656e-05,
      "loss": 0.0018,
      "step": 1033
    },
    {
      "epoch": 17.82758620689655,
      "grad_norm": 0.03353732079267502,
      "learning_rate": 3.860689655172414e-05,
      "loss": 0.0027,
      "step": 1034
    },
    {
      "epoch": 17.844827586206897,
      "grad_norm": 0.03882642090320587,
      "learning_rate": 3.858620689655172e-05,
      "loss": 0.0029,
      "step": 1035
    },
    {
      "epoch": 17.862068965517242,
      "grad_norm": 0.033697567880153656,
      "learning_rate": 3.856551724137931e-05,
      "loss": 0.0034,
      "step": 1036
    },
    {
      "epoch": 17.879310344827587,
      "grad_norm": 0.02982715703547001,
      "learning_rate": 3.8544827586206896e-05,
      "loss": 0.0028,
      "step": 1037
    },
    {
      "epoch": 17.896551724137932,
      "grad_norm": 0.035818297415971756,
      "learning_rate": 3.852413793103448e-05,
      "loss": 0.0035,
      "step": 1038
    },
    {
      "epoch": 17.913793103448278,
      "grad_norm": 0.07274112105369568,
      "learning_rate": 3.850344827586207e-05,
      "loss": 0.0047,
      "step": 1039
    },
    {
      "epoch": 17.93103448275862,
      "grad_norm": 0.041795238852500916,
      "learning_rate": 3.848275862068965e-05,
      "loss": 0.004,
      "step": 1040
    },
    {
      "epoch": 17.93103448275862,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0033237759489566088,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.9211,
      "eval_samples_per_second": 3.251,
      "eval_steps_per_second": 1.681,
      "step": 1040
    },
    {
      "epoch": 17.948275862068964,
      "grad_norm": 0.050167281180620193,
      "learning_rate": 3.846206896551724e-05,
      "loss": 0.0032,
      "step": 1041
    },
    {
      "epoch": 17.96551724137931,
      "grad_norm": 0.0849318653345108,
      "learning_rate": 3.844137931034483e-05,
      "loss": 0.0034,
      "step": 1042
    },
    {
      "epoch": 17.982758620689655,
      "grad_norm": 0.04229824244976044,
      "learning_rate": 3.8420689655172415e-05,
      "loss": 0.0035,
      "step": 1043
    },
    {
      "epoch": 18.0,
      "grad_norm": 0.04593905061483383,
      "learning_rate": 3.8400000000000005e-05,
      "loss": 0.0035,
      "step": 1044
    },
    {
      "epoch": 18.017241379310345,
      "grad_norm": 0.046063847839832306,
      "learning_rate": 3.837931034482759e-05,
      "loss": 0.0038,
      "step": 1045
    },
    {
      "epoch": 18.03448275862069,
      "grad_norm": 0.057907771319150925,
      "learning_rate": 3.835862068965517e-05,
      "loss": 0.0051,
      "step": 1046
    },
    {
      "epoch": 18.051724137931036,
      "grad_norm": 0.05161171033978462,
      "learning_rate": 3.833793103448276e-05,
      "loss": 0.0038,
      "step": 1047
    },
    {
      "epoch": 18.06896551724138,
      "grad_norm": 0.06961016356945038,
      "learning_rate": 3.8317241379310344e-05,
      "loss": 0.0044,
      "step": 1048
    },
    {
      "epoch": 18.086206896551722,
      "grad_norm": 0.039491795003414154,
      "learning_rate": 3.829655172413793e-05,
      "loss": 0.0032,
      "step": 1049
    },
    {
      "epoch": 18.103448275862068,
      "grad_norm": 0.04030352830886841,
      "learning_rate": 3.8275862068965524e-05,
      "loss": 0.0038,
      "step": 1050
    },
    {
      "epoch": 18.120689655172413,
      "grad_norm": 0.03190850839018822,
      "learning_rate": 3.825517241379311e-05,
      "loss": 0.0014,
      "step": 1051
    },
    {
      "epoch": 18.137931034482758,
      "grad_norm": 0.029426300898194313,
      "learning_rate": 3.823448275862069e-05,
      "loss": 0.0028,
      "step": 1052
    },
    {
      "epoch": 18.155172413793103,
      "grad_norm": 0.05230700969696045,
      "learning_rate": 3.821379310344828e-05,
      "loss": 0.0037,
      "step": 1053
    },
    {
      "epoch": 18.17241379310345,
      "grad_norm": 0.08179937303066254,
      "learning_rate": 3.8193103448275863e-05,
      "loss": 0.0038,
      "step": 1054
    },
    {
      "epoch": 18.189655172413794,
      "grad_norm": 0.043800000101327896,
      "learning_rate": 3.817241379310345e-05,
      "loss": 0.0038,
      "step": 1055
    },
    {
      "epoch": 18.20689655172414,
      "grad_norm": 0.03283273056149483,
      "learning_rate": 3.8151724137931037e-05,
      "loss": 0.0025,
      "step": 1056
    },
    {
      "epoch": 18.224137931034484,
      "grad_norm": 0.03971696272492409,
      "learning_rate": 3.813103448275862e-05,
      "loss": 0.004,
      "step": 1057
    },
    {
      "epoch": 18.24137931034483,
      "grad_norm": 0.059418320655822754,
      "learning_rate": 3.81103448275862e-05,
      "loss": 0.0035,
      "step": 1058
    },
    {
      "epoch": 18.25862068965517,
      "grad_norm": 0.06782495975494385,
      "learning_rate": 3.808965517241379e-05,
      "loss": 0.0052,
      "step": 1059
    },
    {
      "epoch": 18.275862068965516,
      "grad_norm": 0.2660295367240906,
      "learning_rate": 3.806896551724138e-05,
      "loss": 0.0032,
      "step": 1060
    },
    {
      "epoch": 18.275862068965516,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.003123376751318574,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.8859,
      "eval_samples_per_second": 3.264,
      "eval_steps_per_second": 1.688,
      "step": 1060
    },
    {
      "epoch": 18.29310344827586,
      "grad_norm": 0.05241610109806061,
      "learning_rate": 3.8048275862068966e-05,
      "loss": 0.0054,
      "step": 1061
    },
    {
      "epoch": 18.310344827586206,
      "grad_norm": 0.04406469315290451,
      "learning_rate": 3.8027586206896556e-05,
      "loss": 0.0027,
      "step": 1062
    },
    {
      "epoch": 18.32758620689655,
      "grad_norm": 0.09798407554626465,
      "learning_rate": 3.800689655172414e-05,
      "loss": 0.0057,
      "step": 1063
    },
    {
      "epoch": 18.344827586206897,
      "grad_norm": 0.1628478467464447,
      "learning_rate": 3.798620689655172e-05,
      "loss": 0.0062,
      "step": 1064
    },
    {
      "epoch": 18.362068965517242,
      "grad_norm": 0.035373374819755554,
      "learning_rate": 3.796551724137931e-05,
      "loss": 0.0034,
      "step": 1065
    },
    {
      "epoch": 18.379310344827587,
      "grad_norm": 0.03433220461010933,
      "learning_rate": 3.7944827586206895e-05,
      "loss": 0.0032,
      "step": 1066
    },
    {
      "epoch": 18.396551724137932,
      "grad_norm": 0.048084504902362823,
      "learning_rate": 3.7924137931034485e-05,
      "loss": 0.0046,
      "step": 1067
    },
    {
      "epoch": 18.413793103448278,
      "grad_norm": 0.1692713350057602,
      "learning_rate": 3.790344827586207e-05,
      "loss": 0.0075,
      "step": 1068
    },
    {
      "epoch": 18.43103448275862,
      "grad_norm": 0.03524433448910713,
      "learning_rate": 3.788275862068966e-05,
      "loss": 0.0029,
      "step": 1069
    },
    {
      "epoch": 18.448275862068964,
      "grad_norm": 0.05972079187631607,
      "learning_rate": 3.786206896551725e-05,
      "loss": 0.0025,
      "step": 1070
    },
    {
      "epoch": 18.46551724137931,
      "grad_norm": 0.03706740960478783,
      "learning_rate": 3.784137931034483e-05,
      "loss": 0.0028,
      "step": 1071
    },
    {
      "epoch": 18.482758620689655,
      "grad_norm": 0.056772783398628235,
      "learning_rate": 3.7820689655172414e-05,
      "loss": 0.0044,
      "step": 1072
    },
    {
      "epoch": 18.5,
      "grad_norm": 0.05747423693537712,
      "learning_rate": 3.7800000000000004e-05,
      "loss": 0.0038,
      "step": 1073
    },
    {
      "epoch": 18.517241379310345,
      "grad_norm": 0.03596069663763046,
      "learning_rate": 3.777931034482759e-05,
      "loss": 0.0034,
      "step": 1074
    },
    {
      "epoch": 18.53448275862069,
      "grad_norm": 0.06616494804620743,
      "learning_rate": 3.775862068965517e-05,
      "loss": 0.0047,
      "step": 1075
    },
    {
      "epoch": 18.551724137931036,
      "grad_norm": 0.057441312819719315,
      "learning_rate": 3.773793103448276e-05,
      "loss": 0.0046,
      "step": 1076
    },
    {
      "epoch": 18.56896551724138,
      "grad_norm": 0.02526349388062954,
      "learning_rate": 3.771724137931034e-05,
      "loss": 0.002,
      "step": 1077
    },
    {
      "epoch": 18.586206896551722,
      "grad_norm": 0.042662642896175385,
      "learning_rate": 3.7696551724137926e-05,
      "loss": 0.0033,
      "step": 1078
    },
    {
      "epoch": 18.603448275862068,
      "grad_norm": 0.03438176214694977,
      "learning_rate": 3.767586206896552e-05,
      "loss": 0.0031,
      "step": 1079
    },
    {
      "epoch": 18.620689655172413,
      "grad_norm": 0.074212945997715,
      "learning_rate": 3.7655172413793106e-05,
      "loss": 0.0042,
      "step": 1080
    },
    {
      "epoch": 18.620689655172413,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.003282766090705991,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.9951,
      "eval_samples_per_second": 3.224,
      "eval_steps_per_second": 1.668,
      "step": 1080
    },
    {
      "epoch": 18.637931034482758,
      "grad_norm": 0.038448311388492584,
      "learning_rate": 3.763448275862069e-05,
      "loss": 0.0041,
      "step": 1081
    },
    {
      "epoch": 18.655172413793103,
      "grad_norm": 0.06407430768013,
      "learning_rate": 3.761379310344828e-05,
      "loss": 0.0042,
      "step": 1082
    },
    {
      "epoch": 18.67241379310345,
      "grad_norm": 0.06150313839316368,
      "learning_rate": 3.759310344827586e-05,
      "loss": 0.0052,
      "step": 1083
    },
    {
      "epoch": 18.689655172413794,
      "grad_norm": 0.026202594861388206,
      "learning_rate": 3.7572413793103446e-05,
      "loss": 0.002,
      "step": 1084
    },
    {
      "epoch": 18.70689655172414,
      "grad_norm": 0.10638564825057983,
      "learning_rate": 3.7551724137931035e-05,
      "loss": 0.0045,
      "step": 1085
    },
    {
      "epoch": 18.724137931034484,
      "grad_norm": 0.050111670047044754,
      "learning_rate": 3.753103448275862e-05,
      "loss": 0.0038,
      "step": 1086
    },
    {
      "epoch": 18.74137931034483,
      "grad_norm": 0.053728438913822174,
      "learning_rate": 3.75103448275862e-05,
      "loss": 0.0038,
      "step": 1087
    },
    {
      "epoch": 18.75862068965517,
      "grad_norm": 0.04104744642972946,
      "learning_rate": 3.74896551724138e-05,
      "loss": 0.004,
      "step": 1088
    },
    {
      "epoch": 18.775862068965516,
      "grad_norm": 0.038311488926410675,
      "learning_rate": 3.746896551724138e-05,
      "loss": 0.0034,
      "step": 1089
    },
    {
      "epoch": 18.79310344827586,
      "grad_norm": 0.03151793032884598,
      "learning_rate": 3.7448275862068965e-05,
      "loss": 0.0031,
      "step": 1090
    },
    {
      "epoch": 18.810344827586206,
      "grad_norm": 0.04044635221362114,
      "learning_rate": 3.7427586206896555e-05,
      "loss": 0.0039,
      "step": 1091
    },
    {
      "epoch": 18.82758620689655,
      "grad_norm": 0.024679917842149734,
      "learning_rate": 3.740689655172414e-05,
      "loss": 0.0024,
      "step": 1092
    },
    {
      "epoch": 18.844827586206897,
      "grad_norm": 0.03961493819952011,
      "learning_rate": 3.738620689655173e-05,
      "loss": 0.0032,
      "step": 1093
    },
    {
      "epoch": 18.862068965517242,
      "grad_norm": 0.04071997106075287,
      "learning_rate": 3.736551724137931e-05,
      "loss": 0.0035,
      "step": 1094
    },
    {
      "epoch": 18.879310344827587,
      "grad_norm": 0.07180175930261612,
      "learning_rate": 3.7344827586206894e-05,
      "loss": 0.0036,
      "step": 1095
    },
    {
      "epoch": 18.896551724137932,
      "grad_norm": 0.036025743931531906,
      "learning_rate": 3.7324137931034484e-05,
      "loss": 0.0028,
      "step": 1096
    },
    {
      "epoch": 18.913793103448278,
      "grad_norm": 0.028860805556178093,
      "learning_rate": 3.7303448275862074e-05,
      "loss": 0.002,
      "step": 1097
    },
    {
      "epoch": 18.93103448275862,
      "grad_norm": 0.06535068154335022,
      "learning_rate": 3.728275862068966e-05,
      "loss": 0.0046,
      "step": 1098
    },
    {
      "epoch": 18.948275862068964,
      "grad_norm": 0.07837524265050888,
      "learning_rate": 3.726206896551725e-05,
      "loss": 0.004,
      "step": 1099
    },
    {
      "epoch": 18.96551724137931,
      "grad_norm": 0.16385217010974884,
      "learning_rate": 3.724137931034483e-05,
      "loss": 0.0037,
      "step": 1100
    },
    {
      "epoch": 18.96551724137931,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0031408711802214384,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.814,
      "eval_samples_per_second": 3.29,
      "eval_steps_per_second": 1.702,
      "step": 1100
    },
    {
      "epoch": 18.982758620689655,
      "grad_norm": 0.0547807440161705,
      "learning_rate": 3.722068965517241e-05,
      "loss": 0.0034,
      "step": 1101
    },
    {
      "epoch": 19.0,
      "grad_norm": 0.02492636814713478,
      "learning_rate": 3.72e-05,
      "loss": 0.0023,
      "step": 1102
    },
    {
      "epoch": 19.017241379310345,
      "grad_norm": 0.01822826825082302,
      "learning_rate": 3.7179310344827586e-05,
      "loss": 0.0014,
      "step": 1103
    },
    {
      "epoch": 19.03448275862069,
      "grad_norm": 0.033274564892053604,
      "learning_rate": 3.715862068965517e-05,
      "loss": 0.0031,
      "step": 1104
    },
    {
      "epoch": 19.051724137931036,
      "grad_norm": 0.04114155098795891,
      "learning_rate": 3.713793103448276e-05,
      "loss": 0.004,
      "step": 1105
    },
    {
      "epoch": 19.06896551724138,
      "grad_norm": 0.10837404429912567,
      "learning_rate": 3.711724137931034e-05,
      "loss": 0.0047,
      "step": 1106
    },
    {
      "epoch": 19.086206896551722,
      "grad_norm": 0.033121347427368164,
      "learning_rate": 3.709655172413793e-05,
      "loss": 0.0028,
      "step": 1107
    },
    {
      "epoch": 19.103448275862068,
      "grad_norm": 0.09778430312871933,
      "learning_rate": 3.707586206896552e-05,
      "loss": 0.0028,
      "step": 1108
    },
    {
      "epoch": 19.120689655172413,
      "grad_norm": 0.0646582692861557,
      "learning_rate": 3.7055172413793105e-05,
      "loss": 0.0046,
      "step": 1109
    },
    {
      "epoch": 19.137931034482758,
      "grad_norm": 0.06523756682872772,
      "learning_rate": 3.703448275862069e-05,
      "loss": 0.003,
      "step": 1110
    },
    {
      "epoch": 19.155172413793103,
      "grad_norm": 0.06882596015930176,
      "learning_rate": 3.701379310344828e-05,
      "loss": 0.0032,
      "step": 1111
    },
    {
      "epoch": 19.17241379310345,
      "grad_norm": 0.04052208364009857,
      "learning_rate": 3.699310344827586e-05,
      "loss": 0.0035,
      "step": 1112
    },
    {
      "epoch": 19.189655172413794,
      "grad_norm": 0.053808242082595825,
      "learning_rate": 3.6972413793103445e-05,
      "loss": 0.0032,
      "step": 1113
    },
    {
      "epoch": 19.20689655172414,
      "grad_norm": 0.06374623626470566,
      "learning_rate": 3.6951724137931034e-05,
      "loss": 0.0039,
      "step": 1114
    },
    {
      "epoch": 19.224137931034484,
      "grad_norm": 0.025420773774385452,
      "learning_rate": 3.693103448275862e-05,
      "loss": 0.0024,
      "step": 1115
    },
    {
      "epoch": 19.24137931034483,
      "grad_norm": 0.03141893446445465,
      "learning_rate": 3.6910344827586214e-05,
      "loss": 0.0024,
      "step": 1116
    },
    {
      "epoch": 19.25862068965517,
      "grad_norm": 0.0698418840765953,
      "learning_rate": 3.68896551724138e-05,
      "loss": 0.0042,
      "step": 1117
    },
    {
      "epoch": 19.275862068965516,
      "grad_norm": 0.04580560326576233,
      "learning_rate": 3.686896551724138e-05,
      "loss": 0.0039,
      "step": 1118
    },
    {
      "epoch": 19.29310344827586,
      "grad_norm": 0.09062223136425018,
      "learning_rate": 3.684827586206897e-05,
      "loss": 0.005,
      "step": 1119
    },
    {
      "epoch": 19.310344827586206,
      "grad_norm": 0.04024307429790497,
      "learning_rate": 3.6827586206896554e-05,
      "loss": 0.0035,
      "step": 1120
    },
    {
      "epoch": 19.310344827586206,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0031817143317312002,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.634,
      "eval_samples_per_second": 3.01,
      "eval_steps_per_second": 1.557,
      "step": 1120
    },
    {
      "epoch": 19.32758620689655,
      "grad_norm": 0.04225817322731018,
      "learning_rate": 3.680689655172414e-05,
      "loss": 0.0028,
      "step": 1121
    },
    {
      "epoch": 19.344827586206897,
      "grad_norm": 0.054305657744407654,
      "learning_rate": 3.678620689655173e-05,
      "loss": 0.0031,
      "step": 1122
    },
    {
      "epoch": 19.362068965517242,
      "grad_norm": 0.029844040051102638,
      "learning_rate": 3.676551724137931e-05,
      "loss": 0.002,
      "step": 1123
    },
    {
      "epoch": 19.379310344827587,
      "grad_norm": 0.05169451981782913,
      "learning_rate": 3.674482758620689e-05,
      "loss": 0.0028,
      "step": 1124
    },
    {
      "epoch": 19.396551724137932,
      "grad_norm": 0.03993372619152069,
      "learning_rate": 3.672413793103448e-05,
      "loss": 0.0032,
      "step": 1125
    },
    {
      "epoch": 19.413793103448278,
      "grad_norm": 0.05205375701189041,
      "learning_rate": 3.670344827586207e-05,
      "loss": 0.0038,
      "step": 1126
    },
    {
      "epoch": 19.43103448275862,
      "grad_norm": 0.04217296093702316,
      "learning_rate": 3.6682758620689656e-05,
      "loss": 0.0034,
      "step": 1127
    },
    {
      "epoch": 19.448275862068964,
      "grad_norm": 0.032585907727479935,
      "learning_rate": 3.6662068965517246e-05,
      "loss": 0.0029,
      "step": 1128
    },
    {
      "epoch": 19.46551724137931,
      "grad_norm": 0.06869295984506607,
      "learning_rate": 3.664137931034483e-05,
      "loss": 0.0037,
      "step": 1129
    },
    {
      "epoch": 19.482758620689655,
      "grad_norm": 0.028518470004200935,
      "learning_rate": 3.662068965517241e-05,
      "loss": 0.0028,
      "step": 1130
    },
    {
      "epoch": 19.5,
      "grad_norm": 0.029549386352300644,
      "learning_rate": 3.66e-05,
      "loss": 0.0027,
      "step": 1131
    },
    {
      "epoch": 19.517241379310345,
      "grad_norm": 0.03437889367341995,
      "learning_rate": 3.6579310344827585e-05,
      "loss": 0.0028,
      "step": 1132
    },
    {
      "epoch": 19.53448275862069,
      "grad_norm": 0.01972912810742855,
      "learning_rate": 3.655862068965517e-05,
      "loss": 0.0018,
      "step": 1133
    },
    {
      "epoch": 19.551724137931036,
      "grad_norm": 0.03163605183362961,
      "learning_rate": 3.653793103448276e-05,
      "loss": 0.0033,
      "step": 1134
    },
    {
      "epoch": 19.56896551724138,
      "grad_norm": 0.0340283028781414,
      "learning_rate": 3.651724137931035e-05,
      "loss": 0.0034,
      "step": 1135
    },
    {
      "epoch": 19.586206896551722,
      "grad_norm": 0.03830433264374733,
      "learning_rate": 3.649655172413793e-05,
      "loss": 0.0027,
      "step": 1136
    },
    {
      "epoch": 19.603448275862068,
      "grad_norm": 0.03999795764684677,
      "learning_rate": 3.647586206896552e-05,
      "loss": 0.0032,
      "step": 1137
    },
    {
      "epoch": 19.620689655172413,
      "grad_norm": 0.02911899797618389,
      "learning_rate": 3.6455172413793104e-05,
      "loss": 0.0027,
      "step": 1138
    },
    {
      "epoch": 19.637931034482758,
      "grad_norm": 0.0664920061826706,
      "learning_rate": 3.6434482758620694e-05,
      "loss": 0.0057,
      "step": 1139
    },
    {
      "epoch": 19.655172413793103,
      "grad_norm": 0.06005873903632164,
      "learning_rate": 3.641379310344828e-05,
      "loss": 0.0046,
      "step": 1140
    },
    {
      "epoch": 19.655172413793103,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0031856391578912735,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.3443,
      "eval_samples_per_second": 2.803,
      "eval_steps_per_second": 1.45,
      "step": 1140
    },
    {
      "epoch": 19.67241379310345,
      "grad_norm": 0.1022074893116951,
      "learning_rate": 3.639310344827586e-05,
      "loss": 0.0057,
      "step": 1141
    },
    {
      "epoch": 19.689655172413794,
      "grad_norm": 0.04552282765507698,
      "learning_rate": 3.637241379310345e-05,
      "loss": 0.0047,
      "step": 1142
    },
    {
      "epoch": 19.70689655172414,
      "grad_norm": 0.030422894284129143,
      "learning_rate": 3.6351724137931033e-05,
      "loss": 0.0028,
      "step": 1143
    },
    {
      "epoch": 19.724137931034484,
      "grad_norm": 0.04207276180386543,
      "learning_rate": 3.633103448275862e-05,
      "loss": 0.004,
      "step": 1144
    },
    {
      "epoch": 19.74137931034483,
      "grad_norm": 0.06707684695720673,
      "learning_rate": 3.631034482758621e-05,
      "loss": 0.0048,
      "step": 1145
    },
    {
      "epoch": 19.75862068965517,
      "grad_norm": 0.0345177948474884,
      "learning_rate": 3.6289655172413796e-05,
      "loss": 0.0025,
      "step": 1146
    },
    {
      "epoch": 19.775862068965516,
      "grad_norm": 0.04184592515230179,
      "learning_rate": 3.626896551724138e-05,
      "loss": 0.0037,
      "step": 1147
    },
    {
      "epoch": 19.79310344827586,
      "grad_norm": 0.036892566829919815,
      "learning_rate": 3.624827586206897e-05,
      "loss": 0.003,
      "step": 1148
    },
    {
      "epoch": 19.810344827586206,
      "grad_norm": 0.0274091437458992,
      "learning_rate": 3.622758620689655e-05,
      "loss": 0.0017,
      "step": 1149
    },
    {
      "epoch": 19.82758620689655,
      "grad_norm": 0.045599278062582016,
      "learning_rate": 3.6206896551724136e-05,
      "loss": 0.0038,
      "step": 1150
    },
    {
      "epoch": 19.844827586206897,
      "grad_norm": 0.07086068391799927,
      "learning_rate": 3.6186206896551726e-05,
      "loss": 0.0042,
      "step": 1151
    },
    {
      "epoch": 19.862068965517242,
      "grad_norm": 0.03350032493472099,
      "learning_rate": 3.616551724137931e-05,
      "loss": 0.0031,
      "step": 1152
    },
    {
      "epoch": 19.879310344827587,
      "grad_norm": 0.027992812916636467,
      "learning_rate": 3.614482758620689e-05,
      "loss": 0.0028,
      "step": 1153
    },
    {
      "epoch": 19.896551724137932,
      "grad_norm": 0.02259378507733345,
      "learning_rate": 3.612413793103449e-05,
      "loss": 0.0016,
      "step": 1154
    },
    {
      "epoch": 19.913793103448278,
      "grad_norm": 0.06711819022893906,
      "learning_rate": 3.610344827586207e-05,
      "loss": 0.0039,
      "step": 1155
    },
    {
      "epoch": 19.93103448275862,
      "grad_norm": 0.04055636748671532,
      "learning_rate": 3.6082758620689655e-05,
      "loss": 0.0039,
      "step": 1156
    },
    {
      "epoch": 19.948275862068964,
      "grad_norm": 0.03833382576704025,
      "learning_rate": 3.6062068965517245e-05,
      "loss": 0.0031,
      "step": 1157
    },
    {
      "epoch": 19.96551724137931,
      "grad_norm": 0.030762068927288055,
      "learning_rate": 3.604137931034483e-05,
      "loss": 0.0026,
      "step": 1158
    },
    {
      "epoch": 19.982758620689655,
      "grad_norm": 0.10516725480556488,
      "learning_rate": 3.602068965517241e-05,
      "loss": 0.0042,
      "step": 1159
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.02854275144636631,
      "learning_rate": 3.6e-05,
      "loss": 0.0028,
      "step": 1160
    },
    {
      "epoch": 20.0,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002894887700676918,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.9226,
      "eval_samples_per_second": 2.655,
      "eval_steps_per_second": 1.373,
      "step": 1160
    },
    {
      "epoch": 20.017241379310345,
      "grad_norm": 0.029463957995176315,
      "learning_rate": 3.5979310344827584e-05,
      "loss": 0.0029,
      "step": 1161
    },
    {
      "epoch": 20.03448275862069,
      "grad_norm": 0.06216898560523987,
      "learning_rate": 3.5958620689655174e-05,
      "loss": 0.0033,
      "step": 1162
    },
    {
      "epoch": 20.051724137931036,
      "grad_norm": 0.03169132396578789,
      "learning_rate": 3.5937931034482764e-05,
      "loss": 0.0026,
      "step": 1163
    },
    {
      "epoch": 20.06896551724138,
      "grad_norm": 0.06031036004424095,
      "learning_rate": 3.591724137931035e-05,
      "loss": 0.0031,
      "step": 1164
    },
    {
      "epoch": 20.086206896551722,
      "grad_norm": 0.027347596362233162,
      "learning_rate": 3.589655172413794e-05,
      "loss": 0.0026,
      "step": 1165
    },
    {
      "epoch": 20.103448275862068,
      "grad_norm": 0.04444215074181557,
      "learning_rate": 3.587586206896552e-05,
      "loss": 0.0043,
      "step": 1166
    },
    {
      "epoch": 20.120689655172413,
      "grad_norm": 0.034289393573999405,
      "learning_rate": 3.58551724137931e-05,
      "loss": 0.0035,
      "step": 1167
    },
    {
      "epoch": 20.137931034482758,
      "grad_norm": 0.02788931131362915,
      "learning_rate": 3.583448275862069e-05,
      "loss": 0.0026,
      "step": 1168
    },
    {
      "epoch": 20.155172413793103,
      "grad_norm": 0.04369653761386871,
      "learning_rate": 3.5813793103448276e-05,
      "loss": 0.0034,
      "step": 1169
    },
    {
      "epoch": 20.17241379310345,
      "grad_norm": 0.025842083618044853,
      "learning_rate": 3.579310344827586e-05,
      "loss": 0.0019,
      "step": 1170
    },
    {
      "epoch": 20.189655172413794,
      "grad_norm": 0.04347103461623192,
      "learning_rate": 3.577241379310345e-05,
      "loss": 0.0032,
      "step": 1171
    },
    {
      "epoch": 20.20689655172414,
      "grad_norm": 0.034005433320999146,
      "learning_rate": 3.575172413793103e-05,
      "loss": 0.0031,
      "step": 1172
    },
    {
      "epoch": 20.224137931034484,
      "grad_norm": 0.03264504671096802,
      "learning_rate": 3.573103448275862e-05,
      "loss": 0.0033,
      "step": 1173
    },
    {
      "epoch": 20.24137931034483,
      "grad_norm": 0.03285742923617363,
      "learning_rate": 3.571034482758621e-05,
      "loss": 0.0025,
      "step": 1174
    },
    {
      "epoch": 20.25862068965517,
      "grad_norm": 0.047942258417606354,
      "learning_rate": 3.5689655172413795e-05,
      "loss": 0.0045,
      "step": 1175
    },
    {
      "epoch": 20.275862068965516,
      "grad_norm": 0.03296087682247162,
      "learning_rate": 3.566896551724138e-05,
      "loss": 0.0027,
      "step": 1176
    },
    {
      "epoch": 20.29310344827586,
      "grad_norm": 0.06335914880037308,
      "learning_rate": 3.564827586206897e-05,
      "loss": 0.0049,
      "step": 1177
    },
    {
      "epoch": 20.310344827586206,
      "grad_norm": 0.03245184198021889,
      "learning_rate": 3.562758620689655e-05,
      "loss": 0.0022,
      "step": 1178
    },
    {
      "epoch": 20.32758620689655,
      "grad_norm": 0.04380641132593155,
      "learning_rate": 3.5606896551724135e-05,
      "loss": 0.0023,
      "step": 1179
    },
    {
      "epoch": 20.344827586206897,
      "grad_norm": 0.02409520372748375,
      "learning_rate": 3.5586206896551725e-05,
      "loss": 0.0023,
      "step": 1180
    },
    {
      "epoch": 20.344827586206897,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0026272935792803764,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.3613,
      "eval_samples_per_second": 3.468,
      "eval_steps_per_second": 1.794,
      "step": 1180
    },
    {
      "epoch": 20.362068965517242,
      "grad_norm": 0.05092903971672058,
      "learning_rate": 3.556551724137931e-05,
      "loss": 0.0042,
      "step": 1181
    },
    {
      "epoch": 20.379310344827587,
      "grad_norm": 0.08109954744577408,
      "learning_rate": 3.55448275862069e-05,
      "loss": 0.0033,
      "step": 1182
    },
    {
      "epoch": 20.396551724137932,
      "grad_norm": 0.03973928093910217,
      "learning_rate": 3.552413793103449e-05,
      "loss": 0.0038,
      "step": 1183
    },
    {
      "epoch": 20.413793103448278,
      "grad_norm": 0.04814128205180168,
      "learning_rate": 3.550344827586207e-05,
      "loss": 0.0036,
      "step": 1184
    },
    {
      "epoch": 20.43103448275862,
      "grad_norm": 0.024241171777248383,
      "learning_rate": 3.5482758620689654e-05,
      "loss": 0.0021,
      "step": 1185
    },
    {
      "epoch": 20.448275862068964,
      "grad_norm": 0.021623261272907257,
      "learning_rate": 3.5462068965517244e-05,
      "loss": 0.002,
      "step": 1186
    },
    {
      "epoch": 20.46551724137931,
      "grad_norm": 0.06971252709627151,
      "learning_rate": 3.544137931034483e-05,
      "loss": 0.0043,
      "step": 1187
    },
    {
      "epoch": 20.482758620689655,
      "grad_norm": 0.05379040166735649,
      "learning_rate": 3.542068965517242e-05,
      "loss": 0.0028,
      "step": 1188
    },
    {
      "epoch": 20.5,
      "grad_norm": 0.03430230915546417,
      "learning_rate": 3.54e-05,
      "loss": 0.0029,
      "step": 1189
    },
    {
      "epoch": 20.517241379310345,
      "grad_norm": 0.060661040246486664,
      "learning_rate": 3.537931034482758e-05,
      "loss": 0.0057,
      "step": 1190
    },
    {
      "epoch": 20.53448275862069,
      "grad_norm": 0.05694545432925224,
      "learning_rate": 3.535862068965517e-05,
      "loss": 0.0033,
      "step": 1191
    },
    {
      "epoch": 20.551724137931036,
      "grad_norm": 0.028723062947392464,
      "learning_rate": 3.533793103448276e-05,
      "loss": 0.0024,
      "step": 1192
    },
    {
      "epoch": 20.56896551724138,
      "grad_norm": 0.03873861953616142,
      "learning_rate": 3.5317241379310346e-05,
      "loss": 0.0035,
      "step": 1193
    },
    {
      "epoch": 20.586206896551722,
      "grad_norm": 0.04016254097223282,
      "learning_rate": 3.5296551724137936e-05,
      "loss": 0.0031,
      "step": 1194
    },
    {
      "epoch": 20.603448275862068,
      "grad_norm": 0.017731575295329094,
      "learning_rate": 3.527586206896552e-05,
      "loss": 0.0016,
      "step": 1195
    },
    {
      "epoch": 20.620689655172413,
      "grad_norm": 0.036170851439237595,
      "learning_rate": 3.52551724137931e-05,
      "loss": 0.0033,
      "step": 1196
    },
    {
      "epoch": 20.637931034482758,
      "grad_norm": 0.02363174967467785,
      "learning_rate": 3.523448275862069e-05,
      "loss": 0.002,
      "step": 1197
    },
    {
      "epoch": 20.655172413793103,
      "grad_norm": 0.03610708564519882,
      "learning_rate": 3.5213793103448275e-05,
      "loss": 0.0037,
      "step": 1198
    },
    {
      "epoch": 20.67241379310345,
      "grad_norm": 0.03661949932575226,
      "learning_rate": 3.519310344827586e-05,
      "loss": 0.0029,
      "step": 1199
    },
    {
      "epoch": 20.689655172413794,
      "grad_norm": 0.03008926659822464,
      "learning_rate": 3.517241379310345e-05,
      "loss": 0.003,
      "step": 1200
    },
    {
      "epoch": 20.689655172413794,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002725569996982813,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.9519,
      "eval_samples_per_second": 3.24,
      "eval_steps_per_second": 1.676,
      "step": 1200
    },
    {
      "epoch": 20.70689655172414,
      "grad_norm": 0.02569541707634926,
      "learning_rate": 3.515172413793104e-05,
      "loss": 0.0021,
      "step": 1201
    },
    {
      "epoch": 20.724137931034484,
      "grad_norm": 0.08841104805469513,
      "learning_rate": 3.513103448275862e-05,
      "loss": 0.0049,
      "step": 1202
    },
    {
      "epoch": 20.74137931034483,
      "grad_norm": 0.051631420850753784,
      "learning_rate": 3.511034482758621e-05,
      "loss": 0.0026,
      "step": 1203
    },
    {
      "epoch": 20.75862068965517,
      "grad_norm": 0.030450616031885147,
      "learning_rate": 3.5089655172413794e-05,
      "loss": 0.0024,
      "step": 1204
    },
    {
      "epoch": 20.775862068965516,
      "grad_norm": 0.08924928307533264,
      "learning_rate": 3.506896551724138e-05,
      "loss": 0.0034,
      "step": 1205
    },
    {
      "epoch": 20.79310344827586,
      "grad_norm": 0.05879785493016243,
      "learning_rate": 3.504827586206897e-05,
      "loss": 0.004,
      "step": 1206
    },
    {
      "epoch": 20.810344827586206,
      "grad_norm": 0.05011618509888649,
      "learning_rate": 3.502758620689655e-05,
      "loss": 0.0025,
      "step": 1207
    },
    {
      "epoch": 20.82758620689655,
      "grad_norm": 0.032079607248306274,
      "learning_rate": 3.5006896551724134e-05,
      "loss": 0.0024,
      "step": 1208
    },
    {
      "epoch": 20.844827586206897,
      "grad_norm": 0.03750726208090782,
      "learning_rate": 3.4986206896551724e-05,
      "loss": 0.0036,
      "step": 1209
    },
    {
      "epoch": 20.862068965517242,
      "grad_norm": 0.04345815256237984,
      "learning_rate": 3.4965517241379313e-05,
      "loss": 0.0041,
      "step": 1210
    },
    {
      "epoch": 20.879310344827587,
      "grad_norm": 0.021464407444000244,
      "learning_rate": 3.49448275862069e-05,
      "loss": 0.0021,
      "step": 1211
    },
    {
      "epoch": 20.896551724137932,
      "grad_norm": 0.04952416568994522,
      "learning_rate": 3.4924137931034486e-05,
      "loss": 0.0033,
      "step": 1212
    },
    {
      "epoch": 20.913793103448278,
      "grad_norm": 0.032718077301979065,
      "learning_rate": 3.490344827586207e-05,
      "loss": 0.0026,
      "step": 1213
    },
    {
      "epoch": 20.93103448275862,
      "grad_norm": 0.0442906953394413,
      "learning_rate": 3.488275862068966e-05,
      "loss": 0.0045,
      "step": 1214
    },
    {
      "epoch": 20.948275862068964,
      "grad_norm": 0.024502063170075417,
      "learning_rate": 3.486206896551724e-05,
      "loss": 0.0023,
      "step": 1215
    },
    {
      "epoch": 20.96551724137931,
      "grad_norm": 0.13666142523288727,
      "learning_rate": 3.4841379310344826e-05,
      "loss": 0.0053,
      "step": 1216
    },
    {
      "epoch": 20.982758620689655,
      "grad_norm": 0.07198813557624817,
      "learning_rate": 3.4820689655172416e-05,
      "loss": 0.0029,
      "step": 1217
    },
    {
      "epoch": 21.0,
      "grad_norm": 0.05396917462348938,
      "learning_rate": 3.48e-05,
      "loss": 0.0027,
      "step": 1218
    },
    {
      "epoch": 21.017241379310345,
      "grad_norm": 0.07054156810045242,
      "learning_rate": 3.477931034482758e-05,
      "loss": 0.0037,
      "step": 1219
    },
    {
      "epoch": 21.03448275862069,
      "grad_norm": 0.05092492327094078,
      "learning_rate": 3.475862068965518e-05,
      "loss": 0.0029,
      "step": 1220
    },
    {
      "epoch": 21.03448275862069,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002761890646070242,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.7943,
      "eval_samples_per_second": 2.687,
      "eval_steps_per_second": 1.39,
      "step": 1220
    },
    {
      "epoch": 21.051724137931036,
      "grad_norm": 0.04047117754817009,
      "learning_rate": 3.473793103448276e-05,
      "loss": 0.0021,
      "step": 1221
    },
    {
      "epoch": 21.06896551724138,
      "grad_norm": 0.0609460212290287,
      "learning_rate": 3.4717241379310345e-05,
      "loss": 0.0039,
      "step": 1222
    },
    {
      "epoch": 21.086206896551722,
      "grad_norm": 0.03673779219388962,
      "learning_rate": 3.4696551724137935e-05,
      "loss": 0.0028,
      "step": 1223
    },
    {
      "epoch": 21.103448275862068,
      "grad_norm": 0.0298792514950037,
      "learning_rate": 3.467586206896552e-05,
      "loss": 0.0026,
      "step": 1224
    },
    {
      "epoch": 21.120689655172413,
      "grad_norm": 0.062456294894218445,
      "learning_rate": 3.46551724137931e-05,
      "loss": 0.0043,
      "step": 1225
    },
    {
      "epoch": 21.137931034482758,
      "grad_norm": 0.047932837158441544,
      "learning_rate": 3.463448275862069e-05,
      "loss": 0.0042,
      "step": 1226
    },
    {
      "epoch": 21.155172413793103,
      "grad_norm": 0.03224080055952072,
      "learning_rate": 3.4613793103448274e-05,
      "loss": 0.003,
      "step": 1227
    },
    {
      "epoch": 21.17241379310345,
      "grad_norm": 0.034983616322278976,
      "learning_rate": 3.459310344827586e-05,
      "loss": 0.0034,
      "step": 1228
    },
    {
      "epoch": 21.189655172413794,
      "grad_norm": 0.05199161544442177,
      "learning_rate": 3.4572413793103454e-05,
      "loss": 0.0036,
      "step": 1229
    },
    {
      "epoch": 21.20689655172414,
      "grad_norm": 0.026372030377388,
      "learning_rate": 3.455172413793104e-05,
      "loss": 0.0023,
      "step": 1230
    },
    {
      "epoch": 21.224137931034484,
      "grad_norm": 0.020827902480959892,
      "learning_rate": 3.453103448275862e-05,
      "loss": 0.002,
      "step": 1231
    },
    {
      "epoch": 21.24137931034483,
      "grad_norm": 0.10628698021173477,
      "learning_rate": 3.451034482758621e-05,
      "loss": 0.0046,
      "step": 1232
    },
    {
      "epoch": 21.25862068965517,
      "grad_norm": 0.013879203237593174,
      "learning_rate": 3.448965517241379e-05,
      "loss": 0.0011,
      "step": 1233
    },
    {
      "epoch": 21.275862068965516,
      "grad_norm": 0.02229217253625393,
      "learning_rate": 3.4468965517241376e-05,
      "loss": 0.0022,
      "step": 1234
    },
    {
      "epoch": 21.29310344827586,
      "grad_norm": 0.052545156329870224,
      "learning_rate": 3.4448275862068966e-05,
      "loss": 0.0034,
      "step": 1235
    },
    {
      "epoch": 21.310344827586206,
      "grad_norm": 0.07748599350452423,
      "learning_rate": 3.442758620689655e-05,
      "loss": 0.0038,
      "step": 1236
    },
    {
      "epoch": 21.32758620689655,
      "grad_norm": 0.0287680272012949,
      "learning_rate": 3.440689655172414e-05,
      "loss": 0.002,
      "step": 1237
    },
    {
      "epoch": 21.344827586206897,
      "grad_norm": 0.016553014516830444,
      "learning_rate": 3.438620689655172e-05,
      "loss": 0.0015,
      "step": 1238
    },
    {
      "epoch": 21.362068965517242,
      "grad_norm": 0.035134509205818176,
      "learning_rate": 3.436551724137931e-05,
      "loss": 0.0033,
      "step": 1239
    },
    {
      "epoch": 21.379310344827587,
      "grad_norm": 0.027981627732515335,
      "learning_rate": 3.43448275862069e-05,
      "loss": 0.0025,
      "step": 1240
    },
    {
      "epoch": 21.379310344827587,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0024341174867004156,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.746,
      "eval_samples_per_second": 2.976,
      "eval_steps_per_second": 1.539,
      "step": 1240
    },
    {
      "epoch": 21.396551724137932,
      "grad_norm": 0.04743395373225212,
      "learning_rate": 3.4324137931034485e-05,
      "loss": 0.0033,
      "step": 1241
    },
    {
      "epoch": 21.413793103448278,
      "grad_norm": 0.03410044685006142,
      "learning_rate": 3.430344827586207e-05,
      "loss": 0.003,
      "step": 1242
    },
    {
      "epoch": 21.43103448275862,
      "grad_norm": 0.0444430336356163,
      "learning_rate": 3.428275862068966e-05,
      "loss": 0.0036,
      "step": 1243
    },
    {
      "epoch": 21.448275862068964,
      "grad_norm": 0.02938111498951912,
      "learning_rate": 3.426206896551724e-05,
      "loss": 0.0028,
      "step": 1244
    },
    {
      "epoch": 21.46551724137931,
      "grad_norm": 0.021401695907115936,
      "learning_rate": 3.4241379310344825e-05,
      "loss": 0.0018,
      "step": 1245
    },
    {
      "epoch": 21.482758620689655,
      "grad_norm": 0.05485589802265167,
      "learning_rate": 3.4220689655172415e-05,
      "loss": 0.0038,
      "step": 1246
    },
    {
      "epoch": 21.5,
      "grad_norm": 0.03305790200829506,
      "learning_rate": 3.42e-05,
      "loss": 0.0026,
      "step": 1247
    },
    {
      "epoch": 21.517241379310345,
      "grad_norm": 0.027120891958475113,
      "learning_rate": 3.417931034482759e-05,
      "loss": 0.0025,
      "step": 1248
    },
    {
      "epoch": 21.53448275862069,
      "grad_norm": 0.038341276347637177,
      "learning_rate": 3.415862068965518e-05,
      "loss": 0.0035,
      "step": 1249
    },
    {
      "epoch": 21.551724137931036,
      "grad_norm": 0.03736751154065132,
      "learning_rate": 3.413793103448276e-05,
      "loss": 0.0032,
      "step": 1250
    },
    {
      "epoch": 21.56896551724138,
      "grad_norm": 0.02173512615263462,
      "learning_rate": 3.4117241379310344e-05,
      "loss": 0.002,
      "step": 1251
    },
    {
      "epoch": 21.586206896551722,
      "grad_norm": 0.05704275891184807,
      "learning_rate": 3.4096551724137934e-05,
      "loss": 0.0033,
      "step": 1252
    },
    {
      "epoch": 21.603448275862068,
      "grad_norm": 0.06920328736305237,
      "learning_rate": 3.407586206896552e-05,
      "loss": 0.0033,
      "step": 1253
    },
    {
      "epoch": 21.620689655172413,
      "grad_norm": 0.058006998151540756,
      "learning_rate": 3.40551724137931e-05,
      "loss": 0.0036,
      "step": 1254
    },
    {
      "epoch": 21.637931034482758,
      "grad_norm": 0.022367319092154503,
      "learning_rate": 3.403448275862069e-05,
      "loss": 0.002,
      "step": 1255
    },
    {
      "epoch": 21.655172413793103,
      "grad_norm": 0.029019977897405624,
      "learning_rate": 3.401379310344827e-05,
      "loss": 0.0024,
      "step": 1256
    },
    {
      "epoch": 21.67241379310345,
      "grad_norm": 0.03089924342930317,
      "learning_rate": 3.399310344827586e-05,
      "loss": 0.0029,
      "step": 1257
    },
    {
      "epoch": 21.689655172413794,
      "grad_norm": 0.027389153838157654,
      "learning_rate": 3.397241379310345e-05,
      "loss": 0.0027,
      "step": 1258
    },
    {
      "epoch": 21.70689655172414,
      "grad_norm": 0.017283005639910698,
      "learning_rate": 3.3951724137931036e-05,
      "loss": 0.0012,
      "step": 1259
    },
    {
      "epoch": 21.724137931034484,
      "grad_norm": 0.039589233696460724,
      "learning_rate": 3.3931034482758626e-05,
      "loss": 0.0037,
      "step": 1260
    },
    {
      "epoch": 21.724137931034484,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002466523787006736,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.448,
      "eval_samples_per_second": 2.533,
      "eval_steps_per_second": 1.31,
      "step": 1260
    },
    {
      "epoch": 21.74137931034483,
      "grad_norm": 0.04264994338154793,
      "learning_rate": 3.391034482758621e-05,
      "loss": 0.0027,
      "step": 1261
    },
    {
      "epoch": 21.75862068965517,
      "grad_norm": 0.031585510820150375,
      "learning_rate": 3.388965517241379e-05,
      "loss": 0.003,
      "step": 1262
    },
    {
      "epoch": 21.775862068965516,
      "grad_norm": 0.05237490311264992,
      "learning_rate": 3.386896551724138e-05,
      "loss": 0.0031,
      "step": 1263
    },
    {
      "epoch": 21.79310344827586,
      "grad_norm": 0.040199629962444305,
      "learning_rate": 3.3848275862068965e-05,
      "loss": 0.0032,
      "step": 1264
    },
    {
      "epoch": 21.810344827586206,
      "grad_norm": 0.05093562602996826,
      "learning_rate": 3.382758620689655e-05,
      "loss": 0.0032,
      "step": 1265
    },
    {
      "epoch": 21.82758620689655,
      "grad_norm": 0.033716753125190735,
      "learning_rate": 3.380689655172414e-05,
      "loss": 0.0028,
      "step": 1266
    },
    {
      "epoch": 21.844827586206897,
      "grad_norm": 0.034443024545907974,
      "learning_rate": 3.378620689655173e-05,
      "loss": 0.002,
      "step": 1267
    },
    {
      "epoch": 21.862068965517242,
      "grad_norm": 0.05581071600317955,
      "learning_rate": 3.376551724137931e-05,
      "loss": 0.0026,
      "step": 1268
    },
    {
      "epoch": 21.879310344827587,
      "grad_norm": 0.02897183783352375,
      "learning_rate": 3.37448275862069e-05,
      "loss": 0.0019,
      "step": 1269
    },
    {
      "epoch": 21.896551724137932,
      "grad_norm": 0.03775603696703911,
      "learning_rate": 3.3724137931034484e-05,
      "loss": 0.0031,
      "step": 1270
    },
    {
      "epoch": 21.913793103448278,
      "grad_norm": 0.04418133199214935,
      "learning_rate": 3.370344827586207e-05,
      "loss": 0.0033,
      "step": 1271
    },
    {
      "epoch": 21.93103448275862,
      "grad_norm": 0.030079834163188934,
      "learning_rate": 3.368275862068966e-05,
      "loss": 0.0024,
      "step": 1272
    },
    {
      "epoch": 21.948275862068964,
      "grad_norm": 0.02196669392287731,
      "learning_rate": 3.366206896551724e-05,
      "loss": 0.002,
      "step": 1273
    },
    {
      "epoch": 21.96551724137931,
      "grad_norm": 0.0362030453979969,
      "learning_rate": 3.3641379310344824e-05,
      "loss": 0.0025,
      "step": 1274
    },
    {
      "epoch": 21.982758620689655,
      "grad_norm": 0.05139223858714104,
      "learning_rate": 3.3620689655172414e-05,
      "loss": 0.0036,
      "step": 1275
    },
    {
      "epoch": 22.0,
      "grad_norm": 0.026236455887556076,
      "learning_rate": 3.3600000000000004e-05,
      "loss": 0.0024,
      "step": 1276
    },
    {
      "epoch": 22.017241379310345,
      "grad_norm": 0.03265891596674919,
      "learning_rate": 3.357931034482759e-05,
      "loss": 0.0033,
      "step": 1277
    },
    {
      "epoch": 22.03448275862069,
      "grad_norm": 0.02141798473894596,
      "learning_rate": 3.3558620689655177e-05,
      "loss": 0.0021,
      "step": 1278
    },
    {
      "epoch": 22.051724137931036,
      "grad_norm": 0.03363277390599251,
      "learning_rate": 3.353793103448276e-05,
      "loss": 0.0018,
      "step": 1279
    },
    {
      "epoch": 22.06896551724138,
      "grad_norm": 0.03637121617794037,
      "learning_rate": 3.351724137931034e-05,
      "loss": 0.0026,
      "step": 1280
    },
    {
      "epoch": 22.06896551724138,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0023973823990672827,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.9209,
      "eval_samples_per_second": 2.923,
      "eval_steps_per_second": 1.512,
      "step": 1280
    },
    {
      "epoch": 22.086206896551722,
      "grad_norm": 0.025380181148648262,
      "learning_rate": 3.349655172413793e-05,
      "loss": 0.0019,
      "step": 1281
    },
    {
      "epoch": 22.103448275862068,
      "grad_norm": 0.02492533251643181,
      "learning_rate": 3.3475862068965516e-05,
      "loss": 0.0023,
      "step": 1282
    },
    {
      "epoch": 22.120689655172413,
      "grad_norm": 0.04540184512734413,
      "learning_rate": 3.3455172413793106e-05,
      "loss": 0.0034,
      "step": 1283
    },
    {
      "epoch": 22.137931034482758,
      "grad_norm": 0.023825107142329216,
      "learning_rate": 3.343448275862069e-05,
      "loss": 0.0022,
      "step": 1284
    },
    {
      "epoch": 22.155172413793103,
      "grad_norm": 0.027646545320749283,
      "learning_rate": 3.341379310344827e-05,
      "loss": 0.0026,
      "step": 1285
    },
    {
      "epoch": 22.17241379310345,
      "grad_norm": 0.018208494409918785,
      "learning_rate": 3.339310344827587e-05,
      "loss": 0.0013,
      "step": 1286
    },
    {
      "epoch": 22.189655172413794,
      "grad_norm": 0.014674934558570385,
      "learning_rate": 3.337241379310345e-05,
      "loss": 0.0013,
      "step": 1287
    },
    {
      "epoch": 22.20689655172414,
      "grad_norm": 0.040282540023326874,
      "learning_rate": 3.3351724137931035e-05,
      "loss": 0.0037,
      "step": 1288
    },
    {
      "epoch": 22.224137931034484,
      "grad_norm": 0.033536750823259354,
      "learning_rate": 3.3331034482758625e-05,
      "loss": 0.0024,
      "step": 1289
    },
    {
      "epoch": 22.24137931034483,
      "grad_norm": 0.02122180350124836,
      "learning_rate": 3.331034482758621e-05,
      "loss": 0.0021,
      "step": 1290
    },
    {
      "epoch": 22.25862068965517,
      "grad_norm": 0.04066640883684158,
      "learning_rate": 3.328965517241379e-05,
      "loss": 0.0034,
      "step": 1291
    },
    {
      "epoch": 22.275862068965516,
      "grad_norm": 0.025648444890975952,
      "learning_rate": 3.326896551724138e-05,
      "loss": 0.0017,
      "step": 1292
    },
    {
      "epoch": 22.29310344827586,
      "grad_norm": 0.03162626922130585,
      "learning_rate": 3.3248275862068964e-05,
      "loss": 0.0028,
      "step": 1293
    },
    {
      "epoch": 22.310344827586206,
      "grad_norm": 0.037328414618968964,
      "learning_rate": 3.322758620689655e-05,
      "loss": 0.0031,
      "step": 1294
    },
    {
      "epoch": 22.32758620689655,
      "grad_norm": 0.05865318700671196,
      "learning_rate": 3.3206896551724144e-05,
      "loss": 0.0027,
      "step": 1295
    },
    {
      "epoch": 22.344827586206897,
      "grad_norm": 0.026600273326039314,
      "learning_rate": 3.318620689655173e-05,
      "loss": 0.0025,
      "step": 1296
    },
    {
      "epoch": 22.362068965517242,
      "grad_norm": 0.051478784531354904,
      "learning_rate": 3.316551724137931e-05,
      "loss": 0.0024,
      "step": 1297
    },
    {
      "epoch": 22.379310344827587,
      "grad_norm": 0.039653584361076355,
      "learning_rate": 3.31448275862069e-05,
      "loss": 0.002,
      "step": 1298
    },
    {
      "epoch": 22.396551724137932,
      "grad_norm": 0.04383748024702072,
      "learning_rate": 3.3124137931034483e-05,
      "loss": 0.0032,
      "step": 1299
    },
    {
      "epoch": 22.413793103448278,
      "grad_norm": 0.04236338660120964,
      "learning_rate": 3.3103448275862067e-05,
      "loss": 0.0035,
      "step": 1300
    },
    {
      "epoch": 22.413793103448278,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0023399395868182182,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.2521,
      "eval_samples_per_second": 2.577,
      "eval_steps_per_second": 1.333,
      "step": 1300
    },
    {
      "epoch": 22.43103448275862,
      "grad_norm": 0.01821177825331688,
      "learning_rate": 3.3082758620689656e-05,
      "loss": 0.0017,
      "step": 1301
    },
    {
      "epoch": 22.448275862068964,
      "grad_norm": 0.06954902410507202,
      "learning_rate": 3.306206896551724e-05,
      "loss": 0.0034,
      "step": 1302
    },
    {
      "epoch": 22.46551724137931,
      "grad_norm": 0.09431572258472443,
      "learning_rate": 3.304137931034482e-05,
      "loss": 0.0037,
      "step": 1303
    },
    {
      "epoch": 22.482758620689655,
      "grad_norm": 0.05196603387594223,
      "learning_rate": 3.302068965517241e-05,
      "loss": 0.0035,
      "step": 1304
    },
    {
      "epoch": 22.5,
      "grad_norm": 0.0329606756567955,
      "learning_rate": 3.3e-05,
      "loss": 0.0024,
      "step": 1305
    },
    {
      "epoch": 22.517241379310345,
      "grad_norm": 0.03847212716937065,
      "learning_rate": 3.2979310344827586e-05,
      "loss": 0.003,
      "step": 1306
    },
    {
      "epoch": 22.53448275862069,
      "grad_norm": 0.0236197616904974,
      "learning_rate": 3.2958620689655176e-05,
      "loss": 0.0016,
      "step": 1307
    },
    {
      "epoch": 22.551724137931036,
      "grad_norm": 0.06267440319061279,
      "learning_rate": 3.293793103448276e-05,
      "loss": 0.0032,
      "step": 1308
    },
    {
      "epoch": 22.56896551724138,
      "grad_norm": 0.04091476649045944,
      "learning_rate": 3.291724137931035e-05,
      "loss": 0.0032,
      "step": 1309
    },
    {
      "epoch": 22.586206896551722,
      "grad_norm": 0.027950214222073555,
      "learning_rate": 3.289655172413793e-05,
      "loss": 0.0026,
      "step": 1310
    },
    {
      "epoch": 22.603448275862068,
      "grad_norm": 0.04319014772772789,
      "learning_rate": 3.2875862068965515e-05,
      "loss": 0.0042,
      "step": 1311
    },
    {
      "epoch": 22.620689655172413,
      "grad_norm": 0.05256686732172966,
      "learning_rate": 3.2855172413793105e-05,
      "loss": 0.0027,
      "step": 1312
    },
    {
      "epoch": 22.637931034482758,
      "grad_norm": 0.024204879999160767,
      "learning_rate": 3.283448275862069e-05,
      "loss": 0.0023,
      "step": 1313
    },
    {
      "epoch": 22.655172413793103,
      "grad_norm": 0.10205905884504318,
      "learning_rate": 3.281379310344828e-05,
      "loss": 0.0043,
      "step": 1314
    },
    {
      "epoch": 22.67241379310345,
      "grad_norm": 0.050654444843530655,
      "learning_rate": 3.279310344827587e-05,
      "loss": 0.002,
      "step": 1315
    },
    {
      "epoch": 22.689655172413794,
      "grad_norm": 0.03602302446961403,
      "learning_rate": 3.277241379310345e-05,
      "loss": 0.0037,
      "step": 1316
    },
    {
      "epoch": 22.70689655172414,
      "grad_norm": 0.03643589839339256,
      "learning_rate": 3.2751724137931034e-05,
      "loss": 0.0035,
      "step": 1317
    },
    {
      "epoch": 22.724137931034484,
      "grad_norm": 0.024940581992268562,
      "learning_rate": 3.2731034482758624e-05,
      "loss": 0.0024,
      "step": 1318
    },
    {
      "epoch": 22.74137931034483,
      "grad_norm": 0.02358260005712509,
      "learning_rate": 3.271034482758621e-05,
      "loss": 0.0023,
      "step": 1319
    },
    {
      "epoch": 22.75862068965517,
      "grad_norm": 0.044067006558179855,
      "learning_rate": 3.268965517241379e-05,
      "loss": 0.0027,
      "step": 1320
    },
    {
      "epoch": 22.75862068965517,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002670153509825468,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.0394,
      "eval_samples_per_second": 2.889,
      "eval_steps_per_second": 1.494,
      "step": 1320
    },
    {
      "epoch": 22.775862068965516,
      "grad_norm": 0.022704774513840675,
      "learning_rate": 3.266896551724138e-05,
      "loss": 0.002,
      "step": 1321
    },
    {
      "epoch": 22.79310344827586,
      "grad_norm": 0.052926141768693924,
      "learning_rate": 3.264827586206896e-05,
      "loss": 0.003,
      "step": 1322
    },
    {
      "epoch": 22.810344827586206,
      "grad_norm": 0.028659293428063393,
      "learning_rate": 3.262758620689655e-05,
      "loss": 0.0024,
      "step": 1323
    },
    {
      "epoch": 22.82758620689655,
      "grad_norm": 0.032357357442379,
      "learning_rate": 3.260689655172414e-05,
      "loss": 0.0033,
      "step": 1324
    },
    {
      "epoch": 22.844827586206897,
      "grad_norm": 0.05284597724676132,
      "learning_rate": 3.2586206896551726e-05,
      "loss": 0.0033,
      "step": 1325
    },
    {
      "epoch": 22.862068965517242,
      "grad_norm": 0.03602117672562599,
      "learning_rate": 3.256551724137931e-05,
      "loss": 0.0035,
      "step": 1326
    },
    {
      "epoch": 22.879310344827587,
      "grad_norm": 0.039168938994407654,
      "learning_rate": 3.25448275862069e-05,
      "loss": 0.0029,
      "step": 1327
    },
    {
      "epoch": 22.896551724137932,
      "grad_norm": 0.03220568969845772,
      "learning_rate": 3.252413793103448e-05,
      "loss": 0.0033,
      "step": 1328
    },
    {
      "epoch": 22.913793103448278,
      "grad_norm": 0.03121347352862358,
      "learning_rate": 3.2503448275862066e-05,
      "loss": 0.0027,
      "step": 1329
    },
    {
      "epoch": 22.93103448275862,
      "grad_norm": 0.0646362379193306,
      "learning_rate": 3.2482758620689655e-05,
      "loss": 0.0024,
      "step": 1330
    },
    {
      "epoch": 22.948275862068964,
      "grad_norm": 0.03173157200217247,
      "learning_rate": 3.246206896551724e-05,
      "loss": 0.0028,
      "step": 1331
    },
    {
      "epoch": 22.96551724137931,
      "grad_norm": 0.09605079889297485,
      "learning_rate": 3.244137931034483e-05,
      "loss": 0.0036,
      "step": 1332
    },
    {
      "epoch": 22.982758620689655,
      "grad_norm": 0.01794213056564331,
      "learning_rate": 3.242068965517242e-05,
      "loss": 0.0014,
      "step": 1333
    },
    {
      "epoch": 23.0,
      "grad_norm": 0.017639130353927612,
      "learning_rate": 3.24e-05,
      "loss": 0.0013,
      "step": 1334
    },
    {
      "epoch": 23.017241379310345,
      "grad_norm": 0.029830556362867355,
      "learning_rate": 3.237931034482759e-05,
      "loss": 0.0019,
      "step": 1335
    },
    {
      "epoch": 23.03448275862069,
      "grad_norm": 0.06627241522073746,
      "learning_rate": 3.2358620689655175e-05,
      "loss": 0.0039,
      "step": 1336
    },
    {
      "epoch": 23.051724137931036,
      "grad_norm": 0.06601377576589584,
      "learning_rate": 3.233793103448276e-05,
      "loss": 0.0028,
      "step": 1337
    },
    {
      "epoch": 23.06896551724138,
      "grad_norm": 0.03858429566025734,
      "learning_rate": 3.231724137931035e-05,
      "loss": 0.0028,
      "step": 1338
    },
    {
      "epoch": 23.086206896551722,
      "grad_norm": 0.03987276181578636,
      "learning_rate": 3.229655172413793e-05,
      "loss": 0.003,
      "step": 1339
    },
    {
      "epoch": 23.103448275862068,
      "grad_norm": 0.018214602023363113,
      "learning_rate": 3.2275862068965514e-05,
      "loss": 0.0015,
      "step": 1340
    },
    {
      "epoch": 23.103448275862068,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0024614331778138876,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.2245,
      "eval_samples_per_second": 2.836,
      "eval_steps_per_second": 1.467,
      "step": 1340
    },
    {
      "epoch": 23.120689655172413,
      "grad_norm": 0.02837972715497017,
      "learning_rate": 3.2255172413793104e-05,
      "loss": 0.0024,
      "step": 1341
    },
    {
      "epoch": 23.137931034482758,
      "grad_norm": 0.04493509978055954,
      "learning_rate": 3.2234482758620694e-05,
      "loss": 0.0032,
      "step": 1342
    },
    {
      "epoch": 23.155172413793103,
      "grad_norm": 0.0629630833864212,
      "learning_rate": 3.221379310344828e-05,
      "loss": 0.0038,
      "step": 1343
    },
    {
      "epoch": 23.17241379310345,
      "grad_norm": 0.06155066937208176,
      "learning_rate": 3.219310344827587e-05,
      "loss": 0.0035,
      "step": 1344
    },
    {
      "epoch": 23.189655172413794,
      "grad_norm": 0.030162343755364418,
      "learning_rate": 3.217241379310345e-05,
      "loss": 0.0029,
      "step": 1345
    },
    {
      "epoch": 23.20689655172414,
      "grad_norm": 0.078888438642025,
      "learning_rate": 3.215172413793103e-05,
      "loss": 0.0038,
      "step": 1346
    },
    {
      "epoch": 23.224137931034484,
      "grad_norm": 0.03274215757846832,
      "learning_rate": 3.213103448275862e-05,
      "loss": 0.002,
      "step": 1347
    },
    {
      "epoch": 23.24137931034483,
      "grad_norm": 0.021301301196217537,
      "learning_rate": 3.2110344827586206e-05,
      "loss": 0.0016,
      "step": 1348
    },
    {
      "epoch": 23.25862068965517,
      "grad_norm": 0.10263390094041824,
      "learning_rate": 3.208965517241379e-05,
      "loss": 0.0036,
      "step": 1349
    },
    {
      "epoch": 23.275862068965516,
      "grad_norm": 0.05073666200041771,
      "learning_rate": 3.206896551724138e-05,
      "loss": 0.0029,
      "step": 1350
    },
    {
      "epoch": 23.29310344827586,
      "grad_norm": 0.04983123019337654,
      "learning_rate": 3.204827586206896e-05,
      "loss": 0.0029,
      "step": 1351
    },
    {
      "epoch": 23.310344827586206,
      "grad_norm": 0.04476351663470268,
      "learning_rate": 3.202758620689655e-05,
      "loss": 0.002,
      "step": 1352
    },
    {
      "epoch": 23.32758620689655,
      "grad_norm": 0.02002400904893875,
      "learning_rate": 3.200689655172414e-05,
      "loss": 0.0019,
      "step": 1353
    },
    {
      "epoch": 23.344827586206897,
      "grad_norm": 0.042381152510643005,
      "learning_rate": 3.1986206896551725e-05,
      "loss": 0.0036,
      "step": 1354
    },
    {
      "epoch": 23.362068965517242,
      "grad_norm": 0.025692278519272804,
      "learning_rate": 3.1965517241379315e-05,
      "loss": 0.0022,
      "step": 1355
    },
    {
      "epoch": 23.379310344827587,
      "grad_norm": 0.03165900707244873,
      "learning_rate": 3.19448275862069e-05,
      "loss": 0.0016,
      "step": 1356
    },
    {
      "epoch": 23.396551724137932,
      "grad_norm": 0.05034324899315834,
      "learning_rate": 3.192413793103448e-05,
      "loss": 0.0037,
      "step": 1357
    },
    {
      "epoch": 23.413793103448278,
      "grad_norm": 0.04662284627556801,
      "learning_rate": 3.190344827586207e-05,
      "loss": 0.0032,
      "step": 1358
    },
    {
      "epoch": 23.43103448275862,
      "grad_norm": 0.07759012281894684,
      "learning_rate": 3.1882758620689654e-05,
      "loss": 0.0033,
      "step": 1359
    },
    {
      "epoch": 23.448275862068964,
      "grad_norm": 0.029093613848090172,
      "learning_rate": 3.186206896551724e-05,
      "loss": 0.0012,
      "step": 1360
    },
    {
      "epoch": 23.448275862068964,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0022798823192715645,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.3464,
      "eval_samples_per_second": 2.556,
      "eval_steps_per_second": 1.322,
      "step": 1360
    },
    {
      "epoch": 23.46551724137931,
      "grad_norm": 0.01901513710618019,
      "learning_rate": 3.1841379310344834e-05,
      "loss": 0.0017,
      "step": 1361
    },
    {
      "epoch": 23.482758620689655,
      "grad_norm": 0.026233777403831482,
      "learning_rate": 3.182068965517242e-05,
      "loss": 0.0026,
      "step": 1362
    },
    {
      "epoch": 23.5,
      "grad_norm": 0.01958167552947998,
      "learning_rate": 3.18e-05,
      "loss": 0.0019,
      "step": 1363
    },
    {
      "epoch": 23.517241379310345,
      "grad_norm": 0.03284445032477379,
      "learning_rate": 3.177931034482759e-05,
      "loss": 0.0022,
      "step": 1364
    },
    {
      "epoch": 23.53448275862069,
      "grad_norm": 0.024124348536133766,
      "learning_rate": 3.1758620689655174e-05,
      "loss": 0.0024,
      "step": 1365
    },
    {
      "epoch": 23.551724137931036,
      "grad_norm": 0.02054884284734726,
      "learning_rate": 3.173793103448276e-05,
      "loss": 0.0019,
      "step": 1366
    },
    {
      "epoch": 23.56896551724138,
      "grad_norm": 0.08157620579004288,
      "learning_rate": 3.1717241379310347e-05,
      "loss": 0.0019,
      "step": 1367
    },
    {
      "epoch": 23.586206896551722,
      "grad_norm": 0.03098135255277157,
      "learning_rate": 3.169655172413793e-05,
      "loss": 0.0024,
      "step": 1368
    },
    {
      "epoch": 23.603448275862068,
      "grad_norm": 0.03306557610630989,
      "learning_rate": 3.167586206896551e-05,
      "loss": 0.0032,
      "step": 1369
    },
    {
      "epoch": 23.620689655172413,
      "grad_norm": 0.028727417811751366,
      "learning_rate": 3.165517241379311e-05,
      "loss": 0.0021,
      "step": 1370
    },
    {
      "epoch": 23.637931034482758,
      "grad_norm": 0.03597436845302582,
      "learning_rate": 3.163448275862069e-05,
      "loss": 0.0033,
      "step": 1371
    },
    {
      "epoch": 23.655172413793103,
      "grad_norm": 0.0497521348297596,
      "learning_rate": 3.1613793103448276e-05,
      "loss": 0.0034,
      "step": 1372
    },
    {
      "epoch": 23.67241379310345,
      "grad_norm": 0.03511291742324829,
      "learning_rate": 3.1593103448275866e-05,
      "loss": 0.0028,
      "step": 1373
    },
    {
      "epoch": 23.689655172413794,
      "grad_norm": 0.034693215042352676,
      "learning_rate": 3.157241379310345e-05,
      "loss": 0.0028,
      "step": 1374
    },
    {
      "epoch": 23.70689655172414,
      "grad_norm": 0.02302343212068081,
      "learning_rate": 3.155172413793103e-05,
      "loss": 0.0022,
      "step": 1375
    },
    {
      "epoch": 23.724137931034484,
      "grad_norm": 0.024868756532669067,
      "learning_rate": 3.153103448275862e-05,
      "loss": 0.0022,
      "step": 1376
    },
    {
      "epoch": 23.74137931034483,
      "grad_norm": 0.03834423050284386,
      "learning_rate": 3.1510344827586205e-05,
      "loss": 0.0028,
      "step": 1377
    },
    {
      "epoch": 23.75862068965517,
      "grad_norm": 0.02040388435125351,
      "learning_rate": 3.1489655172413795e-05,
      "loss": 0.0019,
      "step": 1378
    },
    {
      "epoch": 23.775862068965516,
      "grad_norm": 0.041728612035512924,
      "learning_rate": 3.146896551724138e-05,
      "loss": 0.0026,
      "step": 1379
    },
    {
      "epoch": 23.79310344827586,
      "grad_norm": 0.0344238355755806,
      "learning_rate": 3.144827586206897e-05,
      "loss": 0.0021,
      "step": 1380
    },
    {
      "epoch": 23.79310344827586,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002295535756275058,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.9988,
      "eval_samples_per_second": 2.9,
      "eval_steps_per_second": 1.5,
      "step": 1380
    },
    {
      "epoch": 23.810344827586206,
      "grad_norm": 0.03416449576616287,
      "learning_rate": 3.142758620689656e-05,
      "loss": 0.002,
      "step": 1381
    },
    {
      "epoch": 23.82758620689655,
      "grad_norm": 0.025648411363363266,
      "learning_rate": 3.140689655172414e-05,
      "loss": 0.0021,
      "step": 1382
    },
    {
      "epoch": 23.844827586206897,
      "grad_norm": 0.01863884925842285,
      "learning_rate": 3.1386206896551724e-05,
      "loss": 0.0015,
      "step": 1383
    },
    {
      "epoch": 23.862068965517242,
      "grad_norm": 0.03806454688310623,
      "learning_rate": 3.1365517241379314e-05,
      "loss": 0.0026,
      "step": 1384
    },
    {
      "epoch": 23.879310344827587,
      "grad_norm": 0.029651643708348274,
      "learning_rate": 3.13448275862069e-05,
      "loss": 0.0018,
      "step": 1385
    },
    {
      "epoch": 23.896551724137932,
      "grad_norm": 0.04020664840936661,
      "learning_rate": 3.132413793103448e-05,
      "loss": 0.0016,
      "step": 1386
    },
    {
      "epoch": 23.913793103448278,
      "grad_norm": 0.030679719522595406,
      "learning_rate": 3.130344827586207e-05,
      "loss": 0.0025,
      "step": 1387
    },
    {
      "epoch": 23.93103448275862,
      "grad_norm": 0.032034460455179214,
      "learning_rate": 3.128275862068965e-05,
      "loss": 0.0024,
      "step": 1388
    },
    {
      "epoch": 23.948275862068964,
      "grad_norm": 0.032435450702905655,
      "learning_rate": 3.126206896551724e-05,
      "loss": 0.0024,
      "step": 1389
    },
    {
      "epoch": 23.96551724137931,
      "grad_norm": 0.03198273479938507,
      "learning_rate": 3.124137931034483e-05,
      "loss": 0.0029,
      "step": 1390
    },
    {
      "epoch": 23.982758620689655,
      "grad_norm": 0.03829101473093033,
      "learning_rate": 3.1220689655172416e-05,
      "loss": 0.003,
      "step": 1391
    },
    {
      "epoch": 24.0,
      "grad_norm": 0.030437784269452095,
      "learning_rate": 3.12e-05,
      "loss": 0.0029,
      "step": 1392
    },
    {
      "epoch": 24.017241379310345,
      "grad_norm": 0.023687493056058884,
      "learning_rate": 3.117931034482759e-05,
      "loss": 0.0018,
      "step": 1393
    },
    {
      "epoch": 24.03448275862069,
      "grad_norm": 0.03113185241818428,
      "learning_rate": 3.115862068965517e-05,
      "loss": 0.002,
      "step": 1394
    },
    {
      "epoch": 24.051724137931036,
      "grad_norm": 0.11265064030885696,
      "learning_rate": 3.1137931034482756e-05,
      "loss": 0.0037,
      "step": 1395
    },
    {
      "epoch": 24.06896551724138,
      "grad_norm": 0.02265901491045952,
      "learning_rate": 3.1117241379310346e-05,
      "loss": 0.0022,
      "step": 1396
    },
    {
      "epoch": 24.086206896551722,
      "grad_norm": 0.028762098401784897,
      "learning_rate": 3.109655172413793e-05,
      "loss": 0.003,
      "step": 1397
    },
    {
      "epoch": 24.103448275862068,
      "grad_norm": 0.029748378321528435,
      "learning_rate": 3.107586206896551e-05,
      "loss": 0.0018,
      "step": 1398
    },
    {
      "epoch": 24.120689655172413,
      "grad_norm": 0.041008640080690384,
      "learning_rate": 3.105517241379311e-05,
      "loss": 0.0038,
      "step": 1399
    },
    {
      "epoch": 24.137931034482758,
      "grad_norm": 0.029846111312508583,
      "learning_rate": 3.103448275862069e-05,
      "loss": 0.0019,
      "step": 1400
    },
    {
      "epoch": 24.137931034482758,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002255735220387578,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.5301,
      "eval_samples_per_second": 2.754,
      "eval_steps_per_second": 1.424,
      "step": 1400
    },
    {
      "epoch": 24.155172413793103,
      "grad_norm": 0.024888085201382637,
      "learning_rate": 3.1013793103448275e-05,
      "loss": 0.0025,
      "step": 1401
    },
    {
      "epoch": 24.17241379310345,
      "grad_norm": 0.11301610618829727,
      "learning_rate": 3.0993103448275865e-05,
      "loss": 0.0039,
      "step": 1402
    },
    {
      "epoch": 24.189655172413794,
      "grad_norm": 0.03831205889582634,
      "learning_rate": 3.097241379310345e-05,
      "loss": 0.002,
      "step": 1403
    },
    {
      "epoch": 24.20689655172414,
      "grad_norm": 0.02437189221382141,
      "learning_rate": 3.095172413793104e-05,
      "loss": 0.0022,
      "step": 1404
    },
    {
      "epoch": 24.224137931034484,
      "grad_norm": 0.04893927276134491,
      "learning_rate": 3.093103448275862e-05,
      "loss": 0.002,
      "step": 1405
    },
    {
      "epoch": 24.24137931034483,
      "grad_norm": 0.03384673222899437,
      "learning_rate": 3.0910344827586204e-05,
      "loss": 0.0023,
      "step": 1406
    },
    {
      "epoch": 24.25862068965517,
      "grad_norm": 0.01994498260319233,
      "learning_rate": 3.0889655172413794e-05,
      "loss": 0.0018,
      "step": 1407
    },
    {
      "epoch": 24.275862068965516,
      "grad_norm": 0.03906966745853424,
      "learning_rate": 3.0868965517241384e-05,
      "loss": 0.002,
      "step": 1408
    },
    {
      "epoch": 24.29310344827586,
      "grad_norm": 0.024134110659360886,
      "learning_rate": 3.084827586206897e-05,
      "loss": 0.0021,
      "step": 1409
    },
    {
      "epoch": 24.310344827586206,
      "grad_norm": 0.032490961253643036,
      "learning_rate": 3.082758620689656e-05,
      "loss": 0.0015,
      "step": 1410
    },
    {
      "epoch": 24.32758620689655,
      "grad_norm": 0.04415068030357361,
      "learning_rate": 3.080689655172414e-05,
      "loss": 0.0025,
      "step": 1411
    },
    {
      "epoch": 24.344827586206897,
      "grad_norm": 0.025823844596743584,
      "learning_rate": 3.078620689655172e-05,
      "loss": 0.0019,
      "step": 1412
    },
    {
      "epoch": 24.362068965517242,
      "grad_norm": 0.04362724348902702,
      "learning_rate": 3.076551724137931e-05,
      "loss": 0.0029,
      "step": 1413
    },
    {
      "epoch": 24.379310344827587,
      "grad_norm": 0.03943684324622154,
      "learning_rate": 3.0744827586206896e-05,
      "loss": 0.0024,
      "step": 1414
    },
    {
      "epoch": 24.396551724137932,
      "grad_norm": 0.02628704532980919,
      "learning_rate": 3.072413793103448e-05,
      "loss": 0.0014,
      "step": 1415
    },
    {
      "epoch": 24.413793103448278,
      "grad_norm": 0.023971764370799065,
      "learning_rate": 3.070344827586207e-05,
      "loss": 0.0023,
      "step": 1416
    },
    {
      "epoch": 24.43103448275862,
      "grad_norm": 0.021320393308997154,
      "learning_rate": 3.068275862068965e-05,
      "loss": 0.0017,
      "step": 1417
    },
    {
      "epoch": 24.448275862068964,
      "grad_norm": 0.030756579712033272,
      "learning_rate": 3.066206896551724e-05,
      "loss": 0.0018,
      "step": 1418
    },
    {
      "epoch": 24.46551724137931,
      "grad_norm": 0.0326274037361145,
      "learning_rate": 3.064137931034483e-05,
      "loss": 0.003,
      "step": 1419
    },
    {
      "epoch": 24.482758620689655,
      "grad_norm": 0.04111768305301666,
      "learning_rate": 3.0620689655172415e-05,
      "loss": 0.0017,
      "step": 1420
    },
    {
      "epoch": 24.482758620689655,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0019154029432684183,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.6036,
      "eval_samples_per_second": 2.735,
      "eval_steps_per_second": 1.415,
      "step": 1420
    },
    {
      "epoch": 24.5,
      "grad_norm": 0.02369740977883339,
      "learning_rate": 3.06e-05,
      "loss": 0.0021,
      "step": 1421
    },
    {
      "epoch": 24.517241379310345,
      "grad_norm": 0.032673850655555725,
      "learning_rate": 3.057931034482759e-05,
      "loss": 0.0033,
      "step": 1422
    },
    {
      "epoch": 24.53448275862069,
      "grad_norm": 0.03293363004922867,
      "learning_rate": 3.055862068965517e-05,
      "loss": 0.0033,
      "step": 1423
    },
    {
      "epoch": 24.551724137931036,
      "grad_norm": 0.030844073742628098,
      "learning_rate": 3.0537931034482755e-05,
      "loss": 0.003,
      "step": 1424
    },
    {
      "epoch": 24.56896551724138,
      "grad_norm": 0.03198590874671936,
      "learning_rate": 3.0517241379310344e-05,
      "loss": 0.0023,
      "step": 1425
    },
    {
      "epoch": 24.586206896551722,
      "grad_norm": 0.04395825043320656,
      "learning_rate": 3.0496551724137928e-05,
      "loss": 0.0039,
      "step": 1426
    },
    {
      "epoch": 24.603448275862068,
      "grad_norm": 0.03861704096198082,
      "learning_rate": 3.047586206896552e-05,
      "loss": 0.0033,
      "step": 1427
    },
    {
      "epoch": 24.620689655172413,
      "grad_norm": 0.0603659525513649,
      "learning_rate": 3.0455172413793107e-05,
      "loss": 0.0031,
      "step": 1428
    },
    {
      "epoch": 24.637931034482758,
      "grad_norm": 0.01968236267566681,
      "learning_rate": 3.043448275862069e-05,
      "loss": 0.0013,
      "step": 1429
    },
    {
      "epoch": 24.655172413793103,
      "grad_norm": 0.025282489135861397,
      "learning_rate": 3.0413793103448277e-05,
      "loss": 0.0021,
      "step": 1430
    },
    {
      "epoch": 24.67241379310345,
      "grad_norm": 0.023644398897886276,
      "learning_rate": 3.0393103448275864e-05,
      "loss": 0.0017,
      "step": 1431
    },
    {
      "epoch": 24.689655172413794,
      "grad_norm": 0.03414073958992958,
      "learning_rate": 3.037241379310345e-05,
      "loss": 0.0024,
      "step": 1432
    },
    {
      "epoch": 24.70689655172414,
      "grad_norm": 0.018553106114268303,
      "learning_rate": 3.0351724137931033e-05,
      "loss": 0.0017,
      "step": 1433
    },
    {
      "epoch": 24.724137931034484,
      "grad_norm": 0.034010156989097595,
      "learning_rate": 3.033103448275862e-05,
      "loss": 0.0021,
      "step": 1434
    },
    {
      "epoch": 24.74137931034483,
      "grad_norm": 0.022205647081136703,
      "learning_rate": 3.0310344827586206e-05,
      "loss": 0.0012,
      "step": 1435
    },
    {
      "epoch": 24.75862068965517,
      "grad_norm": 0.02661491557955742,
      "learning_rate": 3.0289655172413796e-05,
      "loss": 0.0022,
      "step": 1436
    },
    {
      "epoch": 24.775862068965516,
      "grad_norm": 0.04463900253176689,
      "learning_rate": 3.0268965517241383e-05,
      "loss": 0.0027,
      "step": 1437
    },
    {
      "epoch": 24.79310344827586,
      "grad_norm": 0.0311133936047554,
      "learning_rate": 3.024827586206897e-05,
      "loss": 0.0019,
      "step": 1438
    },
    {
      "epoch": 24.810344827586206,
      "grad_norm": 0.024408508092164993,
      "learning_rate": 3.0227586206896552e-05,
      "loss": 0.002,
      "step": 1439
    },
    {
      "epoch": 24.82758620689655,
      "grad_norm": 0.020158136263489723,
      "learning_rate": 3.020689655172414e-05,
      "loss": 0.0017,
      "step": 1440
    },
    {
      "epoch": 24.82758620689655,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002003551460802555,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.0936,
      "eval_samples_per_second": 2.614,
      "eval_steps_per_second": 1.352,
      "step": 1440
    },
    {
      "epoch": 24.844827586206897,
      "grad_norm": 0.027255024760961533,
      "learning_rate": 3.0186206896551725e-05,
      "loss": 0.0022,
      "step": 1441
    },
    {
      "epoch": 24.862068965517242,
      "grad_norm": 0.01792888715863228,
      "learning_rate": 3.016551724137931e-05,
      "loss": 0.0015,
      "step": 1442
    },
    {
      "epoch": 24.879310344827587,
      "grad_norm": 0.04586382955312729,
      "learning_rate": 3.0144827586206895e-05,
      "loss": 0.0035,
      "step": 1443
    },
    {
      "epoch": 24.896551724137932,
      "grad_norm": 0.03452792763710022,
      "learning_rate": 3.012413793103448e-05,
      "loss": 0.0024,
      "step": 1444
    },
    {
      "epoch": 24.913793103448278,
      "grad_norm": 0.028435736894607544,
      "learning_rate": 3.0103448275862068e-05,
      "loss": 0.0021,
      "step": 1445
    },
    {
      "epoch": 24.93103448275862,
      "grad_norm": 0.027904335409402847,
      "learning_rate": 3.0082758620689658e-05,
      "loss": 0.0025,
      "step": 1446
    },
    {
      "epoch": 24.948275862068964,
      "grad_norm": 0.036677200347185135,
      "learning_rate": 3.0062068965517245e-05,
      "loss": 0.0023,
      "step": 1447
    },
    {
      "epoch": 24.96551724137931,
      "grad_norm": 0.024516308680176735,
      "learning_rate": 3.004137931034483e-05,
      "loss": 0.0024,
      "step": 1448
    },
    {
      "epoch": 24.982758620689655,
      "grad_norm": 0.027953660115599632,
      "learning_rate": 3.0020689655172414e-05,
      "loss": 0.0021,
      "step": 1449
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.04772813245654106,
      "learning_rate": 3e-05,
      "loss": 0.0025,
      "step": 1450
    },
    {
      "epoch": 25.017241379310345,
      "grad_norm": 0.03491538390517235,
      "learning_rate": 2.9979310344827587e-05,
      "loss": 0.002,
      "step": 1451
    },
    {
      "epoch": 25.03448275862069,
      "grad_norm": 0.034329600632190704,
      "learning_rate": 2.995862068965517e-05,
      "loss": 0.0018,
      "step": 1452
    },
    {
      "epoch": 25.051724137931036,
      "grad_norm": 0.03215090185403824,
      "learning_rate": 2.993793103448276e-05,
      "loss": 0.0025,
      "step": 1453
    },
    {
      "epoch": 25.06896551724138,
      "grad_norm": 0.021973777562379837,
      "learning_rate": 2.9917241379310347e-05,
      "loss": 0.0022,
      "step": 1454
    },
    {
      "epoch": 25.086206896551722,
      "grad_norm": 0.02052280120551586,
      "learning_rate": 2.989655172413793e-05,
      "loss": 0.0015,
      "step": 1455
    },
    {
      "epoch": 25.103448275862068,
      "grad_norm": 0.012811070308089256,
      "learning_rate": 2.9875862068965517e-05,
      "loss": 0.0012,
      "step": 1456
    },
    {
      "epoch": 25.120689655172413,
      "grad_norm": 0.04836361110210419,
      "learning_rate": 2.9855172413793103e-05,
      "loss": 0.0024,
      "step": 1457
    },
    {
      "epoch": 25.137931034482758,
      "grad_norm": 0.023022258654236794,
      "learning_rate": 2.9834482758620693e-05,
      "loss": 0.0022,
      "step": 1458
    },
    {
      "epoch": 25.155172413793103,
      "grad_norm": 0.028646424412727356,
      "learning_rate": 2.9813793103448276e-05,
      "loss": 0.0028,
      "step": 1459
    },
    {
      "epoch": 25.17241379310345,
      "grad_norm": 0.023752054199576378,
      "learning_rate": 2.9793103448275863e-05,
      "loss": 0.0019,
      "step": 1460
    },
    {
      "epoch": 25.17241379310345,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0019279244588688016,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.7525,
      "eval_samples_per_second": 2.697,
      "eval_steps_per_second": 1.395,
      "step": 1460
    },
    {
      "epoch": 25.189655172413794,
      "grad_norm": 0.028407538309693336,
      "learning_rate": 2.977241379310345e-05,
      "loss": 0.0025,
      "step": 1461
    },
    {
      "epoch": 25.20689655172414,
      "grad_norm": 0.02099946327507496,
      "learning_rate": 2.9751724137931036e-05,
      "loss": 0.0019,
      "step": 1462
    },
    {
      "epoch": 25.224137931034484,
      "grad_norm": 0.04874662682414055,
      "learning_rate": 2.9731034482758622e-05,
      "loss": 0.0028,
      "step": 1463
    },
    {
      "epoch": 25.24137931034483,
      "grad_norm": 0.019591687247157097,
      "learning_rate": 2.971034482758621e-05,
      "loss": 0.0017,
      "step": 1464
    },
    {
      "epoch": 25.25862068965517,
      "grad_norm": 0.020238639786839485,
      "learning_rate": 2.9689655172413792e-05,
      "loss": 0.0017,
      "step": 1465
    },
    {
      "epoch": 25.275862068965516,
      "grad_norm": 0.016627805307507515,
      "learning_rate": 2.966896551724138e-05,
      "loss": 0.0016,
      "step": 1466
    },
    {
      "epoch": 25.29310344827586,
      "grad_norm": 0.05374186113476753,
      "learning_rate": 2.9648275862068968e-05,
      "loss": 0.0023,
      "step": 1467
    },
    {
      "epoch": 25.310344827586206,
      "grad_norm": 0.044939298182725906,
      "learning_rate": 2.962758620689655e-05,
      "loss": 0.0025,
      "step": 1468
    },
    {
      "epoch": 25.32758620689655,
      "grad_norm": 0.03737028315663338,
      "learning_rate": 2.9606896551724138e-05,
      "loss": 0.0019,
      "step": 1469
    },
    {
      "epoch": 25.344827586206897,
      "grad_norm": 0.042824819684028625,
      "learning_rate": 2.9586206896551724e-05,
      "loss": 0.0028,
      "step": 1470
    },
    {
      "epoch": 25.362068965517242,
      "grad_norm": 0.030262423679232597,
      "learning_rate": 2.956551724137931e-05,
      "loss": 0.0023,
      "step": 1471
    },
    {
      "epoch": 25.379310344827587,
      "grad_norm": 0.024572249501943588,
      "learning_rate": 2.9544827586206897e-05,
      "loss": 0.0021,
      "step": 1472
    },
    {
      "epoch": 25.396551724137932,
      "grad_norm": 0.02080826461315155,
      "learning_rate": 2.9524137931034484e-05,
      "loss": 0.0012,
      "step": 1473
    },
    {
      "epoch": 25.413793103448278,
      "grad_norm": 0.02723187580704689,
      "learning_rate": 2.950344827586207e-05,
      "loss": 0.0027,
      "step": 1474
    },
    {
      "epoch": 25.43103448275862,
      "grad_norm": 0.11296616494655609,
      "learning_rate": 2.9482758620689654e-05,
      "loss": 0.003,
      "step": 1475
    },
    {
      "epoch": 25.448275862068964,
      "grad_norm": 0.02993124909698963,
      "learning_rate": 2.9462068965517244e-05,
      "loss": 0.0025,
      "step": 1476
    },
    {
      "epoch": 25.46551724137931,
      "grad_norm": 0.017023103311657906,
      "learning_rate": 2.944137931034483e-05,
      "loss": 0.0012,
      "step": 1477
    },
    {
      "epoch": 25.482758620689655,
      "grad_norm": 0.02180904895067215,
      "learning_rate": 2.9420689655172413e-05,
      "loss": 0.0015,
      "step": 1478
    },
    {
      "epoch": 25.5,
      "grad_norm": 0.030237171798944473,
      "learning_rate": 2.94e-05,
      "loss": 0.0014,
      "step": 1479
    },
    {
      "epoch": 25.517241379310345,
      "grad_norm": 0.03755751997232437,
      "learning_rate": 2.9379310344827586e-05,
      "loss": 0.0024,
      "step": 1480
    },
    {
      "epoch": 25.517241379310345,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0017819189233705401,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.7155,
      "eval_samples_per_second": 2.985,
      "eval_steps_per_second": 1.544,
      "step": 1480
    },
    {
      "epoch": 25.53448275862069,
      "grad_norm": 0.026778781786561012,
      "learning_rate": 2.9358620689655176e-05,
      "loss": 0.0021,
      "step": 1481
    },
    {
      "epoch": 25.551724137931036,
      "grad_norm": 0.060135312378406525,
      "learning_rate": 2.933793103448276e-05,
      "loss": 0.0023,
      "step": 1482
    },
    {
      "epoch": 25.56896551724138,
      "grad_norm": 0.016727471724152565,
      "learning_rate": 2.9317241379310346e-05,
      "loss": 0.0015,
      "step": 1483
    },
    {
      "epoch": 25.586206896551722,
      "grad_norm": 0.028304820880293846,
      "learning_rate": 2.9296551724137932e-05,
      "loss": 0.0027,
      "step": 1484
    },
    {
      "epoch": 25.603448275862068,
      "grad_norm": 0.07311604917049408,
      "learning_rate": 2.9275862068965515e-05,
      "loss": 0.0034,
      "step": 1485
    },
    {
      "epoch": 25.620689655172413,
      "grad_norm": 0.022478796541690826,
      "learning_rate": 2.9255172413793105e-05,
      "loss": 0.0021,
      "step": 1486
    },
    {
      "epoch": 25.637931034482758,
      "grad_norm": 0.038684677332639694,
      "learning_rate": 2.9234482758620692e-05,
      "loss": 0.0026,
      "step": 1487
    },
    {
      "epoch": 25.655172413793103,
      "grad_norm": 0.05069371685385704,
      "learning_rate": 2.9213793103448275e-05,
      "loss": 0.0025,
      "step": 1488
    },
    {
      "epoch": 25.67241379310345,
      "grad_norm": 0.027777649462223053,
      "learning_rate": 2.919310344827586e-05,
      "loss": 0.0024,
      "step": 1489
    },
    {
      "epoch": 25.689655172413794,
      "grad_norm": 0.019524848088622093,
      "learning_rate": 2.9172413793103448e-05,
      "loss": 0.0018,
      "step": 1490
    },
    {
      "epoch": 25.70689655172414,
      "grad_norm": 0.041888896375894547,
      "learning_rate": 2.9151724137931035e-05,
      "loss": 0.0029,
      "step": 1491
    },
    {
      "epoch": 25.724137931034484,
      "grad_norm": 0.02663705125451088,
      "learning_rate": 2.913103448275862e-05,
      "loss": 0.0014,
      "step": 1492
    },
    {
      "epoch": 25.74137931034483,
      "grad_norm": 0.04129139333963394,
      "learning_rate": 2.9110344827586208e-05,
      "loss": 0.0022,
      "step": 1493
    },
    {
      "epoch": 25.75862068965517,
      "grad_norm": 0.06940391659736633,
      "learning_rate": 2.9089655172413794e-05,
      "loss": 0.0027,
      "step": 1494
    },
    {
      "epoch": 25.775862068965516,
      "grad_norm": 0.0644587054848671,
      "learning_rate": 2.906896551724138e-05,
      "loss": 0.0031,
      "step": 1495
    },
    {
      "epoch": 25.79310344827586,
      "grad_norm": 0.07180923223495483,
      "learning_rate": 2.9048275862068967e-05,
      "loss": 0.0032,
      "step": 1496
    },
    {
      "epoch": 25.810344827586206,
      "grad_norm": 0.016079459339380264,
      "learning_rate": 2.9027586206896554e-05,
      "loss": 0.0011,
      "step": 1497
    },
    {
      "epoch": 25.82758620689655,
      "grad_norm": 0.05459342896938324,
      "learning_rate": 2.9006896551724137e-05,
      "loss": 0.0028,
      "step": 1498
    },
    {
      "epoch": 25.844827586206897,
      "grad_norm": 0.030848275870084763,
      "learning_rate": 2.8986206896551723e-05,
      "loss": 0.0032,
      "step": 1499
    },
    {
      "epoch": 25.862068965517242,
      "grad_norm": 0.044216033071279526,
      "learning_rate": 2.8965517241379313e-05,
      "loss": 0.0025,
      "step": 1500
    },
    {
      "epoch": 25.862068965517242,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0020840028300881386,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.0675,
      "eval_samples_per_second": 2.403,
      "eval_steps_per_second": 1.243,
      "step": 1500
    },
    {
      "epoch": 25.879310344827587,
      "grad_norm": 0.03583747148513794,
      "learning_rate": 2.8944827586206896e-05,
      "loss": 0.0027,
      "step": 1501
    },
    {
      "epoch": 25.896551724137932,
      "grad_norm": 0.04468635469675064,
      "learning_rate": 2.8924137931034483e-05,
      "loss": 0.0027,
      "step": 1502
    },
    {
      "epoch": 25.913793103448278,
      "grad_norm": 0.026762284338474274,
      "learning_rate": 2.890344827586207e-05,
      "loss": 0.0016,
      "step": 1503
    },
    {
      "epoch": 25.93103448275862,
      "grad_norm": 0.030706318095326424,
      "learning_rate": 2.8882758620689656e-05,
      "loss": 0.0028,
      "step": 1504
    },
    {
      "epoch": 25.948275862068964,
      "grad_norm": 0.0312756784260273,
      "learning_rate": 2.8862068965517243e-05,
      "loss": 0.0021,
      "step": 1505
    },
    {
      "epoch": 25.96551724137931,
      "grad_norm": 0.03376559913158417,
      "learning_rate": 2.884137931034483e-05,
      "loss": 0.0022,
      "step": 1506
    },
    {
      "epoch": 25.982758620689655,
      "grad_norm": 0.03572266176342964,
      "learning_rate": 2.8820689655172416e-05,
      "loss": 0.0016,
      "step": 1507
    },
    {
      "epoch": 26.0,
      "grad_norm": 0.05998191237449646,
      "learning_rate": 2.88e-05,
      "loss": 0.0033,
      "step": 1508
    },
    {
      "epoch": 26.017241379310345,
      "grad_norm": 0.028547139838337898,
      "learning_rate": 2.877931034482759e-05,
      "loss": 0.002,
      "step": 1509
    },
    {
      "epoch": 26.03448275862069,
      "grad_norm": 0.040475208312273026,
      "learning_rate": 2.8758620689655175e-05,
      "loss": 0.0018,
      "step": 1510
    },
    {
      "epoch": 26.051724137931036,
      "grad_norm": 0.06493762135505676,
      "learning_rate": 2.8737931034482758e-05,
      "loss": 0.0033,
      "step": 1511
    },
    {
      "epoch": 26.06896551724138,
      "grad_norm": 0.02359660156071186,
      "learning_rate": 2.8717241379310345e-05,
      "loss": 0.0019,
      "step": 1512
    },
    {
      "epoch": 26.086206896551722,
      "grad_norm": 0.016520509496331215,
      "learning_rate": 2.869655172413793e-05,
      "loss": 0.0014,
      "step": 1513
    },
    {
      "epoch": 26.103448275862068,
      "grad_norm": 0.02958536334335804,
      "learning_rate": 2.8675862068965518e-05,
      "loss": 0.003,
      "step": 1514
    },
    {
      "epoch": 26.120689655172413,
      "grad_norm": 0.025795865803956985,
      "learning_rate": 2.8655172413793104e-05,
      "loss": 0.0018,
      "step": 1515
    },
    {
      "epoch": 26.137931034482758,
      "grad_norm": 0.026801547035574913,
      "learning_rate": 2.863448275862069e-05,
      "loss": 0.0015,
      "step": 1516
    },
    {
      "epoch": 26.155172413793103,
      "grad_norm": 0.05718744918704033,
      "learning_rate": 2.8613793103448277e-05,
      "loss": 0.0025,
      "step": 1517
    },
    {
      "epoch": 26.17241379310345,
      "grad_norm": 0.01646914891898632,
      "learning_rate": 2.859310344827586e-05,
      "loss": 0.0016,
      "step": 1518
    },
    {
      "epoch": 26.189655172413794,
      "grad_norm": 0.020846761763095856,
      "learning_rate": 2.857241379310345e-05,
      "loss": 0.0019,
      "step": 1519
    },
    {
      "epoch": 26.20689655172414,
      "grad_norm": 0.023684462532401085,
      "learning_rate": 2.8551724137931037e-05,
      "loss": 0.0017,
      "step": 1520
    },
    {
      "epoch": 26.20689655172414,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0018437363905832171,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.7206,
      "eval_samples_per_second": 2.983,
      "eval_steps_per_second": 1.543,
      "step": 1520
    },
    {
      "epoch": 26.224137931034484,
      "grad_norm": 0.025172457098960876,
      "learning_rate": 2.853103448275862e-05,
      "loss": 0.0024,
      "step": 1521
    },
    {
      "epoch": 26.24137931034483,
      "grad_norm": 0.013058665208518505,
      "learning_rate": 2.8510344827586207e-05,
      "loss": 0.0011,
      "step": 1522
    },
    {
      "epoch": 26.25862068965517,
      "grad_norm": 0.01897980086505413,
      "learning_rate": 2.8489655172413797e-05,
      "loss": 0.0014,
      "step": 1523
    },
    {
      "epoch": 26.275862068965516,
      "grad_norm": 0.03819194436073303,
      "learning_rate": 2.846896551724138e-05,
      "loss": 0.0021,
      "step": 1524
    },
    {
      "epoch": 26.29310344827586,
      "grad_norm": 0.6997250318527222,
      "learning_rate": 2.8448275862068966e-05,
      "loss": 0.0026,
      "step": 1525
    },
    {
      "epoch": 26.310344827586206,
      "grad_norm": 0.029407303780317307,
      "learning_rate": 2.8427586206896553e-05,
      "loss": 0.0018,
      "step": 1526
    },
    {
      "epoch": 26.32758620689655,
      "grad_norm": 0.03437469154596329,
      "learning_rate": 2.8406896551724136e-05,
      "loss": 0.0023,
      "step": 1527
    },
    {
      "epoch": 26.344827586206897,
      "grad_norm": 0.030978117138147354,
      "learning_rate": 2.8386206896551726e-05,
      "loss": 0.0029,
      "step": 1528
    },
    {
      "epoch": 26.362068965517242,
      "grad_norm": 0.016760148108005524,
      "learning_rate": 2.8365517241379312e-05,
      "loss": 0.0016,
      "step": 1529
    },
    {
      "epoch": 26.379310344827587,
      "grad_norm": 0.027677178382873535,
      "learning_rate": 2.83448275862069e-05,
      "loss": 0.0024,
      "step": 1530
    },
    {
      "epoch": 26.396551724137932,
      "grad_norm": 0.01578208990395069,
      "learning_rate": 2.8324137931034482e-05,
      "loss": 0.0014,
      "step": 1531
    },
    {
      "epoch": 26.413793103448278,
      "grad_norm": 0.032511066645383835,
      "learning_rate": 2.830344827586207e-05,
      "loss": 0.0022,
      "step": 1532
    },
    {
      "epoch": 26.43103448275862,
      "grad_norm": 0.037144701927900314,
      "learning_rate": 2.828275862068966e-05,
      "loss": 0.0025,
      "step": 1533
    },
    {
      "epoch": 26.448275862068964,
      "grad_norm": 0.038809921592473984,
      "learning_rate": 2.826206896551724e-05,
      "loss": 0.0027,
      "step": 1534
    },
    {
      "epoch": 26.46551724137931,
      "grad_norm": 0.0381925031542778,
      "learning_rate": 2.8241379310344828e-05,
      "loss": 0.0029,
      "step": 1535
    },
    {
      "epoch": 26.482758620689655,
      "grad_norm": 0.017000263556838036,
      "learning_rate": 2.8220689655172415e-05,
      "loss": 0.0013,
      "step": 1536
    },
    {
      "epoch": 26.5,
      "grad_norm": 0.03535505011677742,
      "learning_rate": 2.8199999999999998e-05,
      "loss": 0.0017,
      "step": 1537
    },
    {
      "epoch": 26.517241379310345,
      "grad_norm": 0.021889356896281242,
      "learning_rate": 2.8179310344827588e-05,
      "loss": 0.0012,
      "step": 1538
    },
    {
      "epoch": 26.53448275862069,
      "grad_norm": 0.0436260849237442,
      "learning_rate": 2.8158620689655174e-05,
      "loss": 0.0026,
      "step": 1539
    },
    {
      "epoch": 26.551724137931036,
      "grad_norm": 0.03036472573876381,
      "learning_rate": 2.813793103448276e-05,
      "loss": 0.0022,
      "step": 1540
    },
    {
      "epoch": 26.551724137931036,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0017702566692605615,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.5284,
      "eval_samples_per_second": 2.516,
      "eval_steps_per_second": 1.301,
      "step": 1540
    },
    {
      "epoch": 26.56896551724138,
      "grad_norm": 0.038736142218112946,
      "learning_rate": 2.8117241379310344e-05,
      "loss": 0.0032,
      "step": 1541
    },
    {
      "epoch": 26.586206896551722,
      "grad_norm": 0.038887497037649155,
      "learning_rate": 2.8096551724137934e-05,
      "loss": 0.0028,
      "step": 1542
    },
    {
      "epoch": 26.603448275862068,
      "grad_norm": 0.05258440226316452,
      "learning_rate": 2.807586206896552e-05,
      "loss": 0.0021,
      "step": 1543
    },
    {
      "epoch": 26.620689655172413,
      "grad_norm": 0.02942480333149433,
      "learning_rate": 2.8055172413793103e-05,
      "loss": 0.0026,
      "step": 1544
    },
    {
      "epoch": 26.637931034482758,
      "grad_norm": 0.03003224916756153,
      "learning_rate": 2.803448275862069e-05,
      "loss": 0.003,
      "step": 1545
    },
    {
      "epoch": 26.655172413793103,
      "grad_norm": 0.020614108070731163,
      "learning_rate": 2.8013793103448276e-05,
      "loss": 0.0015,
      "step": 1546
    },
    {
      "epoch": 26.67241379310345,
      "grad_norm": 0.015414944849908352,
      "learning_rate": 2.7993103448275863e-05,
      "loss": 0.0014,
      "step": 1547
    },
    {
      "epoch": 26.689655172413794,
      "grad_norm": 0.029036523774266243,
      "learning_rate": 2.797241379310345e-05,
      "loss": 0.0021,
      "step": 1548
    },
    {
      "epoch": 26.70689655172414,
      "grad_norm": 0.05231615528464317,
      "learning_rate": 2.7951724137931036e-05,
      "loss": 0.0028,
      "step": 1549
    },
    {
      "epoch": 26.724137931034484,
      "grad_norm": 0.022118551656603813,
      "learning_rate": 2.793103448275862e-05,
      "loss": 0.0021,
      "step": 1550
    },
    {
      "epoch": 26.74137931034483,
      "grad_norm": 0.040226101875305176,
      "learning_rate": 2.7910344827586206e-05,
      "loss": 0.002,
      "step": 1551
    },
    {
      "epoch": 26.75862068965517,
      "grad_norm": 0.010074708610773087,
      "learning_rate": 2.7889655172413795e-05,
      "loss": 0.0009,
      "step": 1552
    },
    {
      "epoch": 26.775862068965516,
      "grad_norm": 0.03164723142981529,
      "learning_rate": 2.7868965517241382e-05,
      "loss": 0.0022,
      "step": 1553
    },
    {
      "epoch": 26.79310344827586,
      "grad_norm": 0.025676842778921127,
      "learning_rate": 2.7848275862068965e-05,
      "loss": 0.0022,
      "step": 1554
    },
    {
      "epoch": 26.810344827586206,
      "grad_norm": 0.04785867780447006,
      "learning_rate": 2.782758620689655e-05,
      "loss": 0.0033,
      "step": 1555
    },
    {
      "epoch": 26.82758620689655,
      "grad_norm": 0.020249754190444946,
      "learning_rate": 2.780689655172414e-05,
      "loss": 0.0019,
      "step": 1556
    },
    {
      "epoch": 26.844827586206897,
      "grad_norm": 0.05090009421110153,
      "learning_rate": 2.7786206896551725e-05,
      "loss": 0.0029,
      "step": 1557
    },
    {
      "epoch": 26.862068965517242,
      "grad_norm": 0.05433687940239906,
      "learning_rate": 2.776551724137931e-05,
      "loss": 0.003,
      "step": 1558
    },
    {
      "epoch": 26.879310344827587,
      "grad_norm": 0.04761851578950882,
      "learning_rate": 2.7744827586206898e-05,
      "loss": 0.0026,
      "step": 1559
    },
    {
      "epoch": 26.896551724137932,
      "grad_norm": 0.04949326068162918,
      "learning_rate": 2.772413793103448e-05,
      "loss": 0.0029,
      "step": 1560
    },
    {
      "epoch": 26.896551724137932,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0021776750218123198,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.6792,
      "eval_samples_per_second": 2.996,
      "eval_steps_per_second": 1.55,
      "step": 1560
    },
    {
      "epoch": 26.913793103448278,
      "grad_norm": 0.019482677802443504,
      "learning_rate": 2.770344827586207e-05,
      "loss": 0.0011,
      "step": 1561
    },
    {
      "epoch": 26.93103448275862,
      "grad_norm": 0.02415820211172104,
      "learning_rate": 2.7682758620689657e-05,
      "loss": 0.002,
      "step": 1562
    },
    {
      "epoch": 26.948275862068964,
      "grad_norm": 0.030906226485967636,
      "learning_rate": 2.766206896551724e-05,
      "loss": 0.0026,
      "step": 1563
    },
    {
      "epoch": 26.96551724137931,
      "grad_norm": 0.018876884132623672,
      "learning_rate": 2.7641379310344827e-05,
      "loss": 0.0019,
      "step": 1564
    },
    {
      "epoch": 26.982758620689655,
      "grad_norm": 0.030368288978934288,
      "learning_rate": 2.7620689655172413e-05,
      "loss": 0.0019,
      "step": 1565
    },
    {
      "epoch": 27.0,
      "grad_norm": 0.032662201672792435,
      "learning_rate": 2.7600000000000003e-05,
      "loss": 0.0018,
      "step": 1566
    },
    {
      "epoch": 27.017241379310345,
      "grad_norm": 0.022407153621315956,
      "learning_rate": 2.7579310344827587e-05,
      "loss": 0.0014,
      "step": 1567
    },
    {
      "epoch": 27.03448275862069,
      "grad_norm": 0.015249241143465042,
      "learning_rate": 2.7558620689655173e-05,
      "loss": 0.0007,
      "step": 1568
    },
    {
      "epoch": 27.051724137931036,
      "grad_norm": 0.03820417821407318,
      "learning_rate": 2.753793103448276e-05,
      "loss": 0.0016,
      "step": 1569
    },
    {
      "epoch": 27.06896551724138,
      "grad_norm": 0.013442601077258587,
      "learning_rate": 2.7517241379310343e-05,
      "loss": 0.0012,
      "step": 1570
    },
    {
      "epoch": 27.086206896551722,
      "grad_norm": 0.02682463452219963,
      "learning_rate": 2.7496551724137933e-05,
      "loss": 0.0019,
      "step": 1571
    },
    {
      "epoch": 27.103448275862068,
      "grad_norm": 0.04313230141997337,
      "learning_rate": 2.747586206896552e-05,
      "loss": 0.0018,
      "step": 1572
    },
    {
      "epoch": 27.120689655172413,
      "grad_norm": 0.031188804656267166,
      "learning_rate": 2.7455172413793102e-05,
      "loss": 0.0031,
      "step": 1573
    },
    {
      "epoch": 27.137931034482758,
      "grad_norm": 0.023894216865301132,
      "learning_rate": 2.743448275862069e-05,
      "loss": 0.002,
      "step": 1574
    },
    {
      "epoch": 27.155172413793103,
      "grad_norm": 0.018368113785982132,
      "learning_rate": 2.741379310344828e-05,
      "loss": 0.0017,
      "step": 1575
    },
    {
      "epoch": 27.17241379310345,
      "grad_norm": 0.09960729628801346,
      "learning_rate": 2.7393103448275865e-05,
      "loss": 0.0043,
      "step": 1576
    },
    {
      "epoch": 27.189655172413794,
      "grad_norm": 0.025110777467489243,
      "learning_rate": 2.737241379310345e-05,
      "loss": 0.002,
      "step": 1577
    },
    {
      "epoch": 27.20689655172414,
      "grad_norm": 0.028437413275241852,
      "learning_rate": 2.7351724137931035e-05,
      "loss": 0.0013,
      "step": 1578
    },
    {
      "epoch": 27.224137931034484,
      "grad_norm": 0.059987008571624756,
      "learning_rate": 2.733103448275862e-05,
      "loss": 0.0024,
      "step": 1579
    },
    {
      "epoch": 27.24137931034483,
      "grad_norm": 0.020764615386724472,
      "learning_rate": 2.7310344827586208e-05,
      "loss": 0.0016,
      "step": 1580
    },
    {
      "epoch": 27.24137931034483,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001736603444442153,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.3927,
      "eval_samples_per_second": 2.545,
      "eval_steps_per_second": 1.317,
      "step": 1580
    },
    {
      "epoch": 27.25862068965517,
      "grad_norm": 0.029439637437462807,
      "learning_rate": 2.7289655172413794e-05,
      "loss": 0.0024,
      "step": 1581
    },
    {
      "epoch": 27.275862068965516,
      "grad_norm": 0.04531612619757652,
      "learning_rate": 2.726896551724138e-05,
      "loss": 0.0022,
      "step": 1582
    },
    {
      "epoch": 27.29310344827586,
      "grad_norm": 0.04846447333693504,
      "learning_rate": 2.7248275862068964e-05,
      "loss": 0.0031,
      "step": 1583
    },
    {
      "epoch": 27.310344827586206,
      "grad_norm": 0.026616666465997696,
      "learning_rate": 2.722758620689655e-05,
      "loss": 0.002,
      "step": 1584
    },
    {
      "epoch": 27.32758620689655,
      "grad_norm": 0.03057723306119442,
      "learning_rate": 2.720689655172414e-05,
      "loss": 0.0027,
      "step": 1585
    },
    {
      "epoch": 27.344827586206897,
      "grad_norm": 0.01694185473024845,
      "learning_rate": 2.7186206896551724e-05,
      "loss": 0.0011,
      "step": 1586
    },
    {
      "epoch": 27.362068965517242,
      "grad_norm": 0.06250011175870895,
      "learning_rate": 2.716551724137931e-05,
      "loss": 0.0031,
      "step": 1587
    },
    {
      "epoch": 27.379310344827587,
      "grad_norm": 0.022746199741959572,
      "learning_rate": 2.7144827586206897e-05,
      "loss": 0.0018,
      "step": 1588
    },
    {
      "epoch": 27.396551724137932,
      "grad_norm": 0.01888437755405903,
      "learning_rate": 2.7124137931034487e-05,
      "loss": 0.0018,
      "step": 1589
    },
    {
      "epoch": 27.413793103448278,
      "grad_norm": 0.030835673213005066,
      "learning_rate": 2.710344827586207e-05,
      "loss": 0.0016,
      "step": 1590
    },
    {
      "epoch": 27.43103448275862,
      "grad_norm": 0.024420440196990967,
      "learning_rate": 2.7082758620689656e-05,
      "loss": 0.0021,
      "step": 1591
    },
    {
      "epoch": 27.448275862068964,
      "grad_norm": 0.0269159022718668,
      "learning_rate": 2.7062068965517243e-05,
      "loss": 0.0023,
      "step": 1592
    },
    {
      "epoch": 27.46551724137931,
      "grad_norm": 0.05016908794641495,
      "learning_rate": 2.7041379310344826e-05,
      "loss": 0.0026,
      "step": 1593
    },
    {
      "epoch": 27.482758620689655,
      "grad_norm": 0.026406900957226753,
      "learning_rate": 2.7020689655172416e-05,
      "loss": 0.0017,
      "step": 1594
    },
    {
      "epoch": 27.5,
      "grad_norm": 0.02069132588803768,
      "learning_rate": 2.7000000000000002e-05,
      "loss": 0.0015,
      "step": 1595
    },
    {
      "epoch": 27.517241379310345,
      "grad_norm": 0.041580162942409515,
      "learning_rate": 2.6979310344827586e-05,
      "loss": 0.003,
      "step": 1596
    },
    {
      "epoch": 27.53448275862069,
      "grad_norm": 0.03909636661410332,
      "learning_rate": 2.6958620689655172e-05,
      "loss": 0.0022,
      "step": 1597
    },
    {
      "epoch": 27.551724137931036,
      "grad_norm": 0.026555057615041733,
      "learning_rate": 2.693793103448276e-05,
      "loss": 0.002,
      "step": 1598
    },
    {
      "epoch": 27.56896551724138,
      "grad_norm": 0.03780457004904747,
      "learning_rate": 2.6917241379310345e-05,
      "loss": 0.0032,
      "step": 1599
    },
    {
      "epoch": 27.586206896551722,
      "grad_norm": 0.025353945791721344,
      "learning_rate": 2.689655172413793e-05,
      "loss": 0.0024,
      "step": 1600
    },
    {
      "epoch": 27.586206896551722,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.002095051808282733,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.7141,
      "eval_samples_per_second": 2.985,
      "eval_steps_per_second": 1.544,
      "step": 1600
    },
    {
      "epoch": 27.603448275862068,
      "grad_norm": 0.027457797899842262,
      "learning_rate": 2.6875862068965518e-05,
      "loss": 0.0024,
      "step": 1601
    },
    {
      "epoch": 27.620689655172413,
      "grad_norm": 0.04407709464430809,
      "learning_rate": 2.6855172413793105e-05,
      "loss": 0.0025,
      "step": 1602
    },
    {
      "epoch": 27.637931034482758,
      "grad_norm": 0.02622002735733986,
      "learning_rate": 2.6834482758620688e-05,
      "loss": 0.0016,
      "step": 1603
    },
    {
      "epoch": 27.655172413793103,
      "grad_norm": 0.012904665432870388,
      "learning_rate": 2.6813793103448278e-05,
      "loss": 0.0011,
      "step": 1604
    },
    {
      "epoch": 27.67241379310345,
      "grad_norm": 0.037992868572473526,
      "learning_rate": 2.6793103448275864e-05,
      "loss": 0.002,
      "step": 1605
    },
    {
      "epoch": 27.689655172413794,
      "grad_norm": 0.10790001600980759,
      "learning_rate": 2.6772413793103447e-05,
      "loss": 0.003,
      "step": 1606
    },
    {
      "epoch": 27.70689655172414,
      "grad_norm": 0.03004058450460434,
      "learning_rate": 2.6751724137931034e-05,
      "loss": 0.0019,
      "step": 1607
    },
    {
      "epoch": 27.724137931034484,
      "grad_norm": 0.016789261251688004,
      "learning_rate": 2.6731034482758624e-05,
      "loss": 0.0012,
      "step": 1608
    },
    {
      "epoch": 27.74137931034483,
      "grad_norm": 0.04666254296898842,
      "learning_rate": 2.6710344827586207e-05,
      "loss": 0.0017,
      "step": 1609
    },
    {
      "epoch": 27.75862068965517,
      "grad_norm": 0.02893957681953907,
      "learning_rate": 2.6689655172413793e-05,
      "loss": 0.0014,
      "step": 1610
    },
    {
      "epoch": 27.775862068965516,
      "grad_norm": 0.059797562658786774,
      "learning_rate": 2.666896551724138e-05,
      "loss": 0.0025,
      "step": 1611
    },
    {
      "epoch": 27.79310344827586,
      "grad_norm": 0.01842859387397766,
      "learning_rate": 2.6648275862068966e-05,
      "loss": 0.0017,
      "step": 1612
    },
    {
      "epoch": 27.810344827586206,
      "grad_norm": 0.03491363674402237,
      "learning_rate": 2.6627586206896553e-05,
      "loss": 0.0016,
      "step": 1613
    },
    {
      "epoch": 27.82758620689655,
      "grad_norm": 0.03418745473027229,
      "learning_rate": 2.660689655172414e-05,
      "loss": 0.002,
      "step": 1614
    },
    {
      "epoch": 27.844827586206897,
      "grad_norm": 0.01778951659798622,
      "learning_rate": 2.6586206896551726e-05,
      "loss": 0.0017,
      "step": 1615
    },
    {
      "epoch": 27.862068965517242,
      "grad_norm": 0.016430247575044632,
      "learning_rate": 2.656551724137931e-05,
      "loss": 0.0015,
      "step": 1616
    },
    {
      "epoch": 27.879310344827587,
      "grad_norm": 0.02583819255232811,
      "learning_rate": 2.6544827586206896e-05,
      "loss": 0.0026,
      "step": 1617
    },
    {
      "epoch": 27.896551724137932,
      "grad_norm": 0.029916435480117798,
      "learning_rate": 2.6524137931034486e-05,
      "loss": 0.0028,
      "step": 1618
    },
    {
      "epoch": 27.913793103448278,
      "grad_norm": 0.036181215196847916,
      "learning_rate": 2.650344827586207e-05,
      "loss": 0.0022,
      "step": 1619
    },
    {
      "epoch": 27.93103448275862,
      "grad_norm": 0.018194811418652534,
      "learning_rate": 2.6482758620689655e-05,
      "loss": 0.0015,
      "step": 1620
    },
    {
      "epoch": 27.93103448275862,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001842400641180575,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.441,
      "eval_samples_per_second": 2.535,
      "eval_steps_per_second": 1.311,
      "step": 1620
    },
    {
      "epoch": 27.948275862068964,
      "grad_norm": 0.022536955773830414,
      "learning_rate": 2.6462068965517242e-05,
      "loss": 0.002,
      "step": 1621
    },
    {
      "epoch": 27.96551724137931,
      "grad_norm": 0.04154703766107559,
      "learning_rate": 2.6441379310344828e-05,
      "loss": 0.0025,
      "step": 1622
    },
    {
      "epoch": 27.982758620689655,
      "grad_norm": 0.017604196444153786,
      "learning_rate": 2.6420689655172415e-05,
      "loss": 0.0017,
      "step": 1623
    },
    {
      "epoch": 28.0,
      "grad_norm": 0.016176005825400352,
      "learning_rate": 2.64e-05,
      "loss": 0.0014,
      "step": 1624
    },
    {
      "epoch": 28.017241379310345,
      "grad_norm": 0.033325593918561935,
      "learning_rate": 2.6379310344827588e-05,
      "loss": 0.0026,
      "step": 1625
    },
    {
      "epoch": 28.03448275862069,
      "grad_norm": 0.022629816085100174,
      "learning_rate": 2.635862068965517e-05,
      "loss": 0.001,
      "step": 1626
    },
    {
      "epoch": 28.051724137931036,
      "grad_norm": 0.03720949962735176,
      "learning_rate": 2.633793103448276e-05,
      "loss": 0.0023,
      "step": 1627
    },
    {
      "epoch": 28.06896551724138,
      "grad_norm": 0.02125472202897072,
      "learning_rate": 2.6317241379310347e-05,
      "loss": 0.0019,
      "step": 1628
    },
    {
      "epoch": 28.086206896551722,
      "grad_norm": 0.03403152897953987,
      "learning_rate": 2.629655172413793e-05,
      "loss": 0.0027,
      "step": 1629
    },
    {
      "epoch": 28.103448275862068,
      "grad_norm": 0.0464482307434082,
      "learning_rate": 2.6275862068965517e-05,
      "loss": 0.0022,
      "step": 1630
    },
    {
      "epoch": 28.120689655172413,
      "grad_norm": 0.03723359480500221,
      "learning_rate": 2.6255172413793104e-05,
      "loss": 0.0032,
      "step": 1631
    },
    {
      "epoch": 28.137931034482758,
      "grad_norm": 0.027433758601546288,
      "learning_rate": 2.623448275862069e-05,
      "loss": 0.0019,
      "step": 1632
    },
    {
      "epoch": 28.155172413793103,
      "grad_norm": 0.019921422004699707,
      "learning_rate": 2.6213793103448277e-05,
      "loss": 0.0014,
      "step": 1633
    },
    {
      "epoch": 28.17241379310345,
      "grad_norm": 0.018980225548148155,
      "learning_rate": 2.6193103448275863e-05,
      "loss": 0.0016,
      "step": 1634
    },
    {
      "epoch": 28.189655172413794,
      "grad_norm": 0.04146922007203102,
      "learning_rate": 2.6172413793103446e-05,
      "loss": 0.0027,
      "step": 1635
    },
    {
      "epoch": 28.20689655172414,
      "grad_norm": 0.011823146604001522,
      "learning_rate": 2.6151724137931036e-05,
      "loss": 0.001,
      "step": 1636
    },
    {
      "epoch": 28.224137931034484,
      "grad_norm": 0.03531531244516373,
      "learning_rate": 2.6131034482758623e-05,
      "loss": 0.0022,
      "step": 1637
    },
    {
      "epoch": 28.24137931034483,
      "grad_norm": 0.018294241279363632,
      "learning_rate": 2.611034482758621e-05,
      "loss": 0.0015,
      "step": 1638
    },
    {
      "epoch": 28.25862068965517,
      "grad_norm": 0.03034157305955887,
      "learning_rate": 2.6089655172413792e-05,
      "loss": 0.002,
      "step": 1639
    },
    {
      "epoch": 28.275862068965516,
      "grad_norm": 0.029079949483275414,
      "learning_rate": 2.606896551724138e-05,
      "loss": 0.0025,
      "step": 1640
    },
    {
      "epoch": 28.275862068965516,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0018178285099565983,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.662,
      "eval_samples_per_second": 3.001,
      "eval_steps_per_second": 1.552,
      "step": 1640
    },
    {
      "epoch": 28.29310344827586,
      "grad_norm": 0.02538266032934189,
      "learning_rate": 2.604827586206897e-05,
      "loss": 0.0018,
      "step": 1641
    },
    {
      "epoch": 28.310344827586206,
      "grad_norm": 0.03726520389318466,
      "learning_rate": 2.6027586206896552e-05,
      "loss": 0.0018,
      "step": 1642
    },
    {
      "epoch": 28.32758620689655,
      "grad_norm": 0.029299568384885788,
      "learning_rate": 2.600689655172414e-05,
      "loss": 0.0025,
      "step": 1643
    },
    {
      "epoch": 28.344827586206897,
      "grad_norm": 0.01154687162488699,
      "learning_rate": 2.5986206896551725e-05,
      "loss": 0.0011,
      "step": 1644
    },
    {
      "epoch": 28.362068965517242,
      "grad_norm": 0.024574585258960724,
      "learning_rate": 2.5965517241379308e-05,
      "loss": 0.0022,
      "step": 1645
    },
    {
      "epoch": 28.379310344827587,
      "grad_norm": 0.02461046539247036,
      "learning_rate": 2.5944827586206898e-05,
      "loss": 0.0021,
      "step": 1646
    },
    {
      "epoch": 28.396551724137932,
      "grad_norm": 0.041218943893909454,
      "learning_rate": 2.5924137931034485e-05,
      "loss": 0.0026,
      "step": 1647
    },
    {
      "epoch": 28.413793103448278,
      "grad_norm": 0.02778353914618492,
      "learning_rate": 2.590344827586207e-05,
      "loss": 0.001,
      "step": 1648
    },
    {
      "epoch": 28.43103448275862,
      "grad_norm": 0.03353281319141388,
      "learning_rate": 2.5882758620689654e-05,
      "loss": 0.0027,
      "step": 1649
    },
    {
      "epoch": 28.448275862068964,
      "grad_norm": 0.026425562798976898,
      "learning_rate": 2.586206896551724e-05,
      "loss": 0.0011,
      "step": 1650
    },
    {
      "epoch": 28.46551724137931,
      "grad_norm": 0.023776108399033546,
      "learning_rate": 2.584137931034483e-05,
      "loss": 0.0023,
      "step": 1651
    },
    {
      "epoch": 28.482758620689655,
      "grad_norm": 0.02123427391052246,
      "learning_rate": 2.5820689655172414e-05,
      "loss": 0.0015,
      "step": 1652
    },
    {
      "epoch": 28.5,
      "grad_norm": 0.021553248167037964,
      "learning_rate": 2.58e-05,
      "loss": 0.0019,
      "step": 1653
    },
    {
      "epoch": 28.517241379310345,
      "grad_norm": 0.01875639520585537,
      "learning_rate": 2.5779310344827587e-05,
      "loss": 0.0012,
      "step": 1654
    },
    {
      "epoch": 28.53448275862069,
      "grad_norm": 0.059914302080869675,
      "learning_rate": 2.5758620689655173e-05,
      "loss": 0.0027,
      "step": 1655
    },
    {
      "epoch": 28.551724137931036,
      "grad_norm": 0.01859060488641262,
      "learning_rate": 2.573793103448276e-05,
      "loss": 0.0016,
      "step": 1656
    },
    {
      "epoch": 28.56896551724138,
      "grad_norm": 0.07578854262828827,
      "learning_rate": 2.5717241379310346e-05,
      "loss": 0.0022,
      "step": 1657
    },
    {
      "epoch": 28.586206896551722,
      "grad_norm": 0.015988120809197426,
      "learning_rate": 2.569655172413793e-05,
      "loss": 0.001,
      "step": 1658
    },
    {
      "epoch": 28.603448275862068,
      "grad_norm": 0.01966172456741333,
      "learning_rate": 2.5675862068965516e-05,
      "loss": 0.0017,
      "step": 1659
    },
    {
      "epoch": 28.620689655172413,
      "grad_norm": 0.024169793352484703,
      "learning_rate": 2.5655172413793106e-05,
      "loss": 0.0018,
      "step": 1660
    },
    {
      "epoch": 28.620689655172413,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0015830709598958492,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.1044,
      "eval_samples_per_second": 2.612,
      "eval_steps_per_second": 1.351,
      "step": 1660
    },
    {
      "epoch": 28.637931034482758,
      "grad_norm": 0.0305264163762331,
      "learning_rate": 2.5634482758620692e-05,
      "loss": 0.0023,
      "step": 1661
    },
    {
      "epoch": 28.655172413793103,
      "grad_norm": 0.025174643844366074,
      "learning_rate": 2.5613793103448276e-05,
      "loss": 0.0013,
      "step": 1662
    },
    {
      "epoch": 28.67241379310345,
      "grad_norm": 0.015276236459612846,
      "learning_rate": 2.5593103448275862e-05,
      "loss": 0.0011,
      "step": 1663
    },
    {
      "epoch": 28.689655172413794,
      "grad_norm": 0.023054519668221474,
      "learning_rate": 2.557241379310345e-05,
      "loss": 0.0016,
      "step": 1664
    },
    {
      "epoch": 28.70689655172414,
      "grad_norm": 0.037456221878528595,
      "learning_rate": 2.5551724137931035e-05,
      "loss": 0.0025,
      "step": 1665
    },
    {
      "epoch": 28.724137931034484,
      "grad_norm": 0.014560048468410969,
      "learning_rate": 2.5531034482758622e-05,
      "loss": 0.0013,
      "step": 1666
    },
    {
      "epoch": 28.74137931034483,
      "grad_norm": 0.03869180008769035,
      "learning_rate": 2.5510344827586208e-05,
      "loss": 0.0018,
      "step": 1667
    },
    {
      "epoch": 28.75862068965517,
      "grad_norm": 0.02389799989759922,
      "learning_rate": 2.548965517241379e-05,
      "loss": 0.0023,
      "step": 1668
    },
    {
      "epoch": 28.775862068965516,
      "grad_norm": 0.026713497936725616,
      "learning_rate": 2.546896551724138e-05,
      "loss": 0.0021,
      "step": 1669
    },
    {
      "epoch": 28.79310344827586,
      "grad_norm": 0.044879741966724396,
      "learning_rate": 2.5448275862068968e-05,
      "loss": 0.0026,
      "step": 1670
    },
    {
      "epoch": 28.810344827586206,
      "grad_norm": 0.018967438489198685,
      "learning_rate": 2.542758620689655e-05,
      "loss": 0.0019,
      "step": 1671
    },
    {
      "epoch": 28.82758620689655,
      "grad_norm": 0.023713428527116776,
      "learning_rate": 2.5406896551724137e-05,
      "loss": 0.0013,
      "step": 1672
    },
    {
      "epoch": 28.844827586206897,
      "grad_norm": 0.020889634266495705,
      "learning_rate": 2.5386206896551724e-05,
      "loss": 0.0017,
      "step": 1673
    },
    {
      "epoch": 28.862068965517242,
      "grad_norm": 0.04474714770913124,
      "learning_rate": 2.5365517241379314e-05,
      "loss": 0.0018,
      "step": 1674
    },
    {
      "epoch": 28.879310344827587,
      "grad_norm": 0.026984279975295067,
      "learning_rate": 2.5344827586206897e-05,
      "loss": 0.0023,
      "step": 1675
    },
    {
      "epoch": 28.896551724137932,
      "grad_norm": 0.030389314517378807,
      "learning_rate": 2.5324137931034484e-05,
      "loss": 0.002,
      "step": 1676
    },
    {
      "epoch": 28.913793103448278,
      "grad_norm": 0.05961907282471657,
      "learning_rate": 2.530344827586207e-05,
      "loss": 0.0026,
      "step": 1677
    },
    {
      "epoch": 28.93103448275862,
      "grad_norm": 0.04339727759361267,
      "learning_rate": 2.5282758620689653e-05,
      "loss": 0.0028,
      "step": 1678
    },
    {
      "epoch": 28.948275862068964,
      "grad_norm": 0.02611473575234413,
      "learning_rate": 2.5262068965517243e-05,
      "loss": 0.0018,
      "step": 1679
    },
    {
      "epoch": 28.96551724137931,
      "grad_norm": 0.019206799566745758,
      "learning_rate": 2.524137931034483e-05,
      "loss": 0.0017,
      "step": 1680
    },
    {
      "epoch": 28.96551724137931,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0017841329099610448,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 1816.855,
      "eval_samples_per_second": 0.016,
      "eval_steps_per_second": 0.008,
      "step": 1680
    },
    {
      "epoch": 28.982758620689655,
      "grad_norm": 0.01984502002596855,
      "learning_rate": 2.5220689655172413e-05,
      "loss": 0.0014,
      "step": 1681
    },
    {
      "epoch": 29.0,
      "grad_norm": 0.02797473967075348,
      "learning_rate": 2.52e-05,
      "loss": 0.0025,
      "step": 1682
    },
    {
      "epoch": 29.017241379310345,
      "grad_norm": 0.012901343405246735,
      "learning_rate": 2.5179310344827586e-05,
      "loss": 0.0012,
      "step": 1683
    },
    {
      "epoch": 29.03448275862069,
      "grad_norm": 0.024329178035259247,
      "learning_rate": 2.5158620689655176e-05,
      "loss": 0.0021,
      "step": 1684
    },
    {
      "epoch": 29.051724137931036,
      "grad_norm": 0.02804499678313732,
      "learning_rate": 2.513793103448276e-05,
      "loss": 0.0018,
      "step": 1685
    },
    {
      "epoch": 29.06896551724138,
      "grad_norm": 0.027743471786379814,
      "learning_rate": 2.5117241379310345e-05,
      "loss": 0.002,
      "step": 1686
    },
    {
      "epoch": 29.086206896551722,
      "grad_norm": 0.010460486635565758,
      "learning_rate": 2.5096551724137932e-05,
      "loss": 0.0009,
      "step": 1687
    },
    {
      "epoch": 29.103448275862068,
      "grad_norm": 0.014148549176752567,
      "learning_rate": 2.507586206896552e-05,
      "loss": 0.0011,
      "step": 1688
    },
    {
      "epoch": 29.120689655172413,
      "grad_norm": 0.02682342939078808,
      "learning_rate": 2.5055172413793105e-05,
      "loss": 0.0026,
      "step": 1689
    },
    {
      "epoch": 29.137931034482758,
      "grad_norm": 0.023976091295480728,
      "learning_rate": 2.503448275862069e-05,
      "loss": 0.0022,
      "step": 1690
    },
    {
      "epoch": 29.155172413793103,
      "grad_norm": 0.022890765219926834,
      "learning_rate": 2.5013793103448275e-05,
      "loss": 0.0015,
      "step": 1691
    },
    {
      "epoch": 29.17241379310345,
      "grad_norm": 0.02503609098494053,
      "learning_rate": 2.499310344827586e-05,
      "loss": 0.0024,
      "step": 1692
    },
    {
      "epoch": 29.189655172413794,
      "grad_norm": 0.017982307821512222,
      "learning_rate": 2.497241379310345e-05,
      "loss": 0.0018,
      "step": 1693
    },
    {
      "epoch": 29.20689655172414,
      "grad_norm": 0.026741882786154747,
      "learning_rate": 2.4951724137931034e-05,
      "loss": 0.0016,
      "step": 1694
    },
    {
      "epoch": 29.224137931034484,
      "grad_norm": 0.022888032719492912,
      "learning_rate": 2.493103448275862e-05,
      "loss": 0.0015,
      "step": 1695
    },
    {
      "epoch": 29.24137931034483,
      "grad_norm": 0.024571413174271584,
      "learning_rate": 2.4910344827586207e-05,
      "loss": 0.0021,
      "step": 1696
    },
    {
      "epoch": 29.25862068965517,
      "grad_norm": 0.022204259410500526,
      "learning_rate": 2.4889655172413794e-05,
      "loss": 0.002,
      "step": 1697
    },
    {
      "epoch": 29.275862068965516,
      "grad_norm": 0.02538689784705639,
      "learning_rate": 2.486896551724138e-05,
      "loss": 0.0013,
      "step": 1698
    },
    {
      "epoch": 29.29310344827586,
      "grad_norm": 0.015943914651870728,
      "learning_rate": 2.4848275862068967e-05,
      "loss": 0.0014,
      "step": 1699
    },
    {
      "epoch": 29.310344827586206,
      "grad_norm": 0.017744392156600952,
      "learning_rate": 2.4827586206896553e-05,
      "loss": 0.0016,
      "step": 1700
    },
    {
      "epoch": 29.310344827586206,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0016318199923262,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.2718,
      "eval_samples_per_second": 3.128,
      "eval_steps_per_second": 1.618,
      "step": 1700
    },
    {
      "epoch": 29.32758620689655,
      "grad_norm": 0.012242430821061134,
      "learning_rate": 2.4806896551724136e-05,
      "loss": 0.0011,
      "step": 1701
    },
    {
      "epoch": 29.344827586206897,
      "grad_norm": 0.01895911805331707,
      "learning_rate": 2.4786206896551726e-05,
      "loss": 0.0015,
      "step": 1702
    },
    {
      "epoch": 29.362068965517242,
      "grad_norm": 0.0218494925647974,
      "learning_rate": 2.4765517241379313e-05,
      "loss": 0.0015,
      "step": 1703
    },
    {
      "epoch": 29.379310344827587,
      "grad_norm": 0.02011774852871895,
      "learning_rate": 2.4744827586206896e-05,
      "loss": 0.0019,
      "step": 1704
    },
    {
      "epoch": 29.396551724137932,
      "grad_norm": 0.024980219081044197,
      "learning_rate": 2.4724137931034483e-05,
      "loss": 0.0015,
      "step": 1705
    },
    {
      "epoch": 29.413793103448278,
      "grad_norm": 0.03231183812022209,
      "learning_rate": 2.470344827586207e-05,
      "loss": 0.002,
      "step": 1706
    },
    {
      "epoch": 29.43103448275862,
      "grad_norm": 0.028627166524529457,
      "learning_rate": 2.4682758620689656e-05,
      "loss": 0.0018,
      "step": 1707
    },
    {
      "epoch": 29.448275862068964,
      "grad_norm": 0.021413356065750122,
      "learning_rate": 2.4662068965517242e-05,
      "loss": 0.0016,
      "step": 1708
    },
    {
      "epoch": 29.46551724137931,
      "grad_norm": 0.018929649144411087,
      "learning_rate": 2.464137931034483e-05,
      "loss": 0.0017,
      "step": 1709
    },
    {
      "epoch": 29.482758620689655,
      "grad_norm": 0.04232629016041756,
      "learning_rate": 2.4620689655172415e-05,
      "loss": 0.0016,
      "step": 1710
    },
    {
      "epoch": 29.5,
      "grad_norm": 0.0376034714281559,
      "learning_rate": 2.4599999999999998e-05,
      "loss": 0.0017,
      "step": 1711
    },
    {
      "epoch": 29.517241379310345,
      "grad_norm": 0.033514026552438736,
      "learning_rate": 2.4579310344827588e-05,
      "loss": 0.002,
      "step": 1712
    },
    {
      "epoch": 29.53448275862069,
      "grad_norm": 0.031180890277028084,
      "learning_rate": 2.4558620689655175e-05,
      "loss": 0.003,
      "step": 1713
    },
    {
      "epoch": 29.551724137931036,
      "grad_norm": 0.01769990287721157,
      "learning_rate": 2.4537931034482758e-05,
      "loss": 0.0017,
      "step": 1714
    },
    {
      "epoch": 29.56896551724138,
      "grad_norm": 0.02208128198981285,
      "learning_rate": 2.4517241379310344e-05,
      "loss": 0.0022,
      "step": 1715
    },
    {
      "epoch": 29.586206896551722,
      "grad_norm": 0.026512322947382927,
      "learning_rate": 2.4496551724137934e-05,
      "loss": 0.0023,
      "step": 1716
    },
    {
      "epoch": 29.603448275862068,
      "grad_norm": 0.025674020871520042,
      "learning_rate": 2.4475862068965517e-05,
      "loss": 0.0014,
      "step": 1717
    },
    {
      "epoch": 29.620689655172413,
      "grad_norm": 0.033235400915145874,
      "learning_rate": 2.4455172413793104e-05,
      "loss": 0.0025,
      "step": 1718
    },
    {
      "epoch": 29.637931034482758,
      "grad_norm": 0.021964477375149727,
      "learning_rate": 2.443448275862069e-05,
      "loss": 0.0014,
      "step": 1719
    },
    {
      "epoch": 29.655172413793103,
      "grad_norm": 0.027740919962525368,
      "learning_rate": 2.4413793103448277e-05,
      "loss": 0.0021,
      "step": 1720
    },
    {
      "epoch": 29.655172413793103,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001756255398504436,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.1039,
      "eval_samples_per_second": 2.396,
      "eval_steps_per_second": 1.239,
      "step": 1720
    },
    {
      "epoch": 29.67241379310345,
      "grad_norm": 0.02344527281820774,
      "learning_rate": 2.4393103448275863e-05,
      "loss": 0.0015,
      "step": 1721
    },
    {
      "epoch": 29.689655172413794,
      "grad_norm": 0.05822375789284706,
      "learning_rate": 2.437241379310345e-05,
      "loss": 0.0029,
      "step": 1722
    },
    {
      "epoch": 29.70689655172414,
      "grad_norm": 0.03485579043626785,
      "learning_rate": 2.4351724137931037e-05,
      "loss": 0.0018,
      "step": 1723
    },
    {
      "epoch": 29.724137931034484,
      "grad_norm": 0.051784008741378784,
      "learning_rate": 2.433103448275862e-05,
      "loss": 0.0018,
      "step": 1724
    },
    {
      "epoch": 29.74137931034483,
      "grad_norm": 0.01965087093412876,
      "learning_rate": 2.4310344827586206e-05,
      "loss": 0.0014,
      "step": 1725
    },
    {
      "epoch": 29.75862068965517,
      "grad_norm": 0.030969923362135887,
      "learning_rate": 2.4289655172413796e-05,
      "loss": 0.0019,
      "step": 1726
    },
    {
      "epoch": 29.775862068965516,
      "grad_norm": 0.033062782138586044,
      "learning_rate": 2.426896551724138e-05,
      "loss": 0.0021,
      "step": 1727
    },
    {
      "epoch": 29.79310344827586,
      "grad_norm": 0.03148676082491875,
      "learning_rate": 2.4248275862068966e-05,
      "loss": 0.002,
      "step": 1728
    },
    {
      "epoch": 29.810344827586206,
      "grad_norm": 0.02019657753407955,
      "learning_rate": 2.4227586206896552e-05,
      "loss": 0.0018,
      "step": 1729
    },
    {
      "epoch": 29.82758620689655,
      "grad_norm": 0.022182390093803406,
      "learning_rate": 2.4206896551724135e-05,
      "loss": 0.0022,
      "step": 1730
    },
    {
      "epoch": 29.844827586206897,
      "grad_norm": 0.015569501556456089,
      "learning_rate": 2.4186206896551725e-05,
      "loss": 0.0013,
      "step": 1731
    },
    {
      "epoch": 29.862068965517242,
      "grad_norm": 0.022293755784630775,
      "learning_rate": 2.4165517241379312e-05,
      "loss": 0.002,
      "step": 1732
    },
    {
      "epoch": 29.879310344827587,
      "grad_norm": 0.04992040991783142,
      "learning_rate": 2.41448275862069e-05,
      "loss": 0.0021,
      "step": 1733
    },
    {
      "epoch": 29.896551724137932,
      "grad_norm": 0.02012026123702526,
      "learning_rate": 2.412413793103448e-05,
      "loss": 0.0014,
      "step": 1734
    },
    {
      "epoch": 29.913793103448278,
      "grad_norm": 0.020387429744005203,
      "learning_rate": 2.410344827586207e-05,
      "loss": 0.0014,
      "step": 1735
    },
    {
      "epoch": 29.93103448275862,
      "grad_norm": 0.015365234576165676,
      "learning_rate": 2.4082758620689658e-05,
      "loss": 0.0013,
      "step": 1736
    },
    {
      "epoch": 29.948275862068964,
      "grad_norm": 0.023818129673600197,
      "learning_rate": 2.406206896551724e-05,
      "loss": 0.0019,
      "step": 1737
    },
    {
      "epoch": 29.96551724137931,
      "grad_norm": 0.0181109681725502,
      "learning_rate": 2.4041379310344828e-05,
      "loss": 0.0014,
      "step": 1738
    },
    {
      "epoch": 29.982758620689655,
      "grad_norm": 0.03206845000386238,
      "learning_rate": 2.4020689655172414e-05,
      "loss": 0.0017,
      "step": 1739
    },
    {
      "epoch": 30.0,
      "grad_norm": 0.011258560232818127,
      "learning_rate": 2.4e-05,
      "loss": 0.0009,
      "step": 1740
    },
    {
      "epoch": 30.0,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0014911098405718803,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.1299,
      "eval_samples_per_second": 2.209,
      "eval_steps_per_second": 1.142,
      "step": 1740
    },
    {
      "epoch": 30.017241379310345,
      "grad_norm": 0.02413812465965748,
      "learning_rate": 2.3979310344827587e-05,
      "loss": 0.0018,
      "step": 1741
    },
    {
      "epoch": 30.03448275862069,
      "grad_norm": 0.04484637454152107,
      "learning_rate": 2.3958620689655174e-05,
      "loss": 0.0028,
      "step": 1742
    },
    {
      "epoch": 30.051724137931036,
      "grad_norm": 0.02617688663303852,
      "learning_rate": 2.3937931034482757e-05,
      "loss": 0.0014,
      "step": 1743
    },
    {
      "epoch": 30.06896551724138,
      "grad_norm": 0.02276223711669445,
      "learning_rate": 2.3917241379310343e-05,
      "loss": 0.0022,
      "step": 1744
    },
    {
      "epoch": 30.086206896551722,
      "grad_norm": 0.026505105197429657,
      "learning_rate": 2.3896551724137933e-05,
      "loss": 0.0017,
      "step": 1745
    },
    {
      "epoch": 30.103448275862068,
      "grad_norm": 0.02405722625553608,
      "learning_rate": 2.387586206896552e-05,
      "loss": 0.0016,
      "step": 1746
    },
    {
      "epoch": 30.120689655172413,
      "grad_norm": 0.020369330421090126,
      "learning_rate": 2.3855172413793103e-05,
      "loss": 0.0016,
      "step": 1747
    },
    {
      "epoch": 30.137931034482758,
      "grad_norm": 0.034487638622522354,
      "learning_rate": 2.383448275862069e-05,
      "loss": 0.0015,
      "step": 1748
    },
    {
      "epoch": 30.155172413793103,
      "grad_norm": 0.01862994208931923,
      "learning_rate": 2.381379310344828e-05,
      "loss": 0.0018,
      "step": 1749
    },
    {
      "epoch": 30.17241379310345,
      "grad_norm": 0.014374082908034325,
      "learning_rate": 2.3793103448275862e-05,
      "loss": 0.001,
      "step": 1750
    },
    {
      "epoch": 30.189655172413794,
      "grad_norm": 0.013739623129367828,
      "learning_rate": 2.377241379310345e-05,
      "loss": 0.0012,
      "step": 1751
    },
    {
      "epoch": 30.20689655172414,
      "grad_norm": 0.02201109193265438,
      "learning_rate": 2.3751724137931035e-05,
      "loss": 0.0011,
      "step": 1752
    },
    {
      "epoch": 30.224137931034484,
      "grad_norm": 0.019817376509308815,
      "learning_rate": 2.373103448275862e-05,
      "loss": 0.0019,
      "step": 1753
    },
    {
      "epoch": 30.24137931034483,
      "grad_norm": 0.018983939662575722,
      "learning_rate": 2.371034482758621e-05,
      "loss": 0.0016,
      "step": 1754
    },
    {
      "epoch": 30.25862068965517,
      "grad_norm": 0.040343157947063446,
      "learning_rate": 2.3689655172413795e-05,
      "loss": 0.0026,
      "step": 1755
    },
    {
      "epoch": 30.275862068965516,
      "grad_norm": 0.061178676784038544,
      "learning_rate": 2.366896551724138e-05,
      "loss": 0.0029,
      "step": 1756
    },
    {
      "epoch": 30.29310344827586,
      "grad_norm": 0.018004583194851875,
      "learning_rate": 2.3648275862068965e-05,
      "loss": 0.0009,
      "step": 1757
    },
    {
      "epoch": 30.310344827586206,
      "grad_norm": 0.02146065980195999,
      "learning_rate": 2.362758620689655e-05,
      "loss": 0.0013,
      "step": 1758
    },
    {
      "epoch": 30.32758620689655,
      "grad_norm": 0.011827350594103336,
      "learning_rate": 2.360689655172414e-05,
      "loss": 0.0009,
      "step": 1759
    },
    {
      "epoch": 30.344827586206897,
      "grad_norm": 0.03429419547319412,
      "learning_rate": 2.3586206896551724e-05,
      "loss": 0.0025,
      "step": 1760
    },
    {
      "epoch": 30.344827586206897,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0014784951927140355,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.9897,
      "eval_samples_per_second": 2.419,
      "eval_steps_per_second": 1.251,
      "step": 1760
    },
    {
      "epoch": 30.362068965517242,
      "grad_norm": 0.014709072187542915,
      "learning_rate": 2.356551724137931e-05,
      "loss": 0.0011,
      "step": 1761
    },
    {
      "epoch": 30.379310344827587,
      "grad_norm": 0.021431442350149155,
      "learning_rate": 2.3544827586206897e-05,
      "loss": 0.0016,
      "step": 1762
    },
    {
      "epoch": 30.396551724137932,
      "grad_norm": 0.018048487603664398,
      "learning_rate": 2.352413793103448e-05,
      "loss": 0.0015,
      "step": 1763
    },
    {
      "epoch": 30.413793103448278,
      "grad_norm": 0.019723298028111458,
      "learning_rate": 2.350344827586207e-05,
      "loss": 0.0016,
      "step": 1764
    },
    {
      "epoch": 30.43103448275862,
      "grad_norm": 0.04039275273680687,
      "learning_rate": 2.3482758620689657e-05,
      "loss": 0.002,
      "step": 1765
    },
    {
      "epoch": 30.448275862068964,
      "grad_norm": 0.013644859194755554,
      "learning_rate": 2.346206896551724e-05,
      "loss": 0.0012,
      "step": 1766
    },
    {
      "epoch": 30.46551724137931,
      "grad_norm": 0.02974792756140232,
      "learning_rate": 2.3441379310344827e-05,
      "loss": 0.0021,
      "step": 1767
    },
    {
      "epoch": 30.482758620689655,
      "grad_norm": 0.026547521352767944,
      "learning_rate": 2.3420689655172416e-05,
      "loss": 0.0022,
      "step": 1768
    },
    {
      "epoch": 30.5,
      "grad_norm": 0.012060091830790043,
      "learning_rate": 2.3400000000000003e-05,
      "loss": 0.0011,
      "step": 1769
    },
    {
      "epoch": 30.517241379310345,
      "grad_norm": 0.014450550079345703,
      "learning_rate": 2.3379310344827586e-05,
      "loss": 0.0012,
      "step": 1770
    },
    {
      "epoch": 30.53448275862069,
      "grad_norm": 0.02928030677139759,
      "learning_rate": 2.3358620689655173e-05,
      "loss": 0.0023,
      "step": 1771
    },
    {
      "epoch": 30.551724137931036,
      "grad_norm": 0.015723152086138725,
      "learning_rate": 2.333793103448276e-05,
      "loss": 0.0011,
      "step": 1772
    },
    {
      "epoch": 30.56896551724138,
      "grad_norm": 0.07160566747188568,
      "learning_rate": 2.3317241379310346e-05,
      "loss": 0.0023,
      "step": 1773
    },
    {
      "epoch": 30.586206896551722,
      "grad_norm": 0.028040383011102676,
      "learning_rate": 2.3296551724137932e-05,
      "loss": 0.0024,
      "step": 1774
    },
    {
      "epoch": 30.603448275862068,
      "grad_norm": 0.07918527722358704,
      "learning_rate": 2.327586206896552e-05,
      "loss": 0.0026,
      "step": 1775
    },
    {
      "epoch": 30.620689655172413,
      "grad_norm": 0.019485007971525192,
      "learning_rate": 2.3255172413793102e-05,
      "loss": 0.0017,
      "step": 1776
    },
    {
      "epoch": 30.637931034482758,
      "grad_norm": 0.030922334641218185,
      "learning_rate": 2.323448275862069e-05,
      "loss": 0.0014,
      "step": 1777
    },
    {
      "epoch": 30.655172413793103,
      "grad_norm": 0.04375556483864784,
      "learning_rate": 2.3213793103448278e-05,
      "loss": 0.0018,
      "step": 1778
    },
    {
      "epoch": 30.67241379310345,
      "grad_norm": 0.06619487702846527,
      "learning_rate": 2.319310344827586e-05,
      "loss": 0.0028,
      "step": 1779
    },
    {
      "epoch": 30.689655172413794,
      "grad_norm": 0.02746422402560711,
      "learning_rate": 2.3172413793103448e-05,
      "loss": 0.0027,
      "step": 1780
    },
    {
      "epoch": 30.689655172413794,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0016770188231021166,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.254,
      "eval_samples_per_second": 2.367,
      "eval_steps_per_second": 1.224,
      "step": 1780
    },
    {
      "epoch": 30.70689655172414,
      "grad_norm": 0.03540246933698654,
      "learning_rate": 2.3151724137931034e-05,
      "loss": 0.0026,
      "step": 1781
    },
    {
      "epoch": 30.724137931034484,
      "grad_norm": 0.03729204833507538,
      "learning_rate": 2.3131034482758624e-05,
      "loss": 0.0017,
      "step": 1782
    },
    {
      "epoch": 30.74137931034483,
      "grad_norm": 0.02354179136455059,
      "learning_rate": 2.3110344827586207e-05,
      "loss": 0.0016,
      "step": 1783
    },
    {
      "epoch": 30.75862068965517,
      "grad_norm": 0.014643106609582901,
      "learning_rate": 2.3089655172413794e-05,
      "loss": 0.0013,
      "step": 1784
    },
    {
      "epoch": 30.775862068965516,
      "grad_norm": 0.01718939282000065,
      "learning_rate": 2.306896551724138e-05,
      "loss": 0.0016,
      "step": 1785
    },
    {
      "epoch": 30.79310344827586,
      "grad_norm": 0.022055642679333687,
      "learning_rate": 2.3048275862068964e-05,
      "loss": 0.0013,
      "step": 1786
    },
    {
      "epoch": 30.810344827586206,
      "grad_norm": 0.0274329986423254,
      "learning_rate": 2.3027586206896554e-05,
      "loss": 0.0024,
      "step": 1787
    },
    {
      "epoch": 30.82758620689655,
      "grad_norm": 0.02013302408158779,
      "learning_rate": 2.300689655172414e-05,
      "loss": 0.0019,
      "step": 1788
    },
    {
      "epoch": 30.844827586206897,
      "grad_norm": 0.009415228851139545,
      "learning_rate": 2.2986206896551723e-05,
      "loss": 0.0008,
      "step": 1789
    },
    {
      "epoch": 30.862068965517242,
      "grad_norm": 0.02844259887933731,
      "learning_rate": 2.296551724137931e-05,
      "loss": 0.0015,
      "step": 1790
    },
    {
      "epoch": 30.879310344827587,
      "grad_norm": 0.010242629796266556,
      "learning_rate": 2.2944827586206896e-05,
      "loss": 0.0008,
      "step": 1791
    },
    {
      "epoch": 30.896551724137932,
      "grad_norm": 0.032252006232738495,
      "learning_rate": 2.2924137931034486e-05,
      "loss": 0.0022,
      "step": 1792
    },
    {
      "epoch": 30.913793103448278,
      "grad_norm": 0.02969452179968357,
      "learning_rate": 2.290344827586207e-05,
      "loss": 0.0019,
      "step": 1793
    },
    {
      "epoch": 30.93103448275862,
      "grad_norm": 0.048455458134412766,
      "learning_rate": 2.2882758620689656e-05,
      "loss": 0.0031,
      "step": 1794
    },
    {
      "epoch": 30.948275862068964,
      "grad_norm": 0.0226893313229084,
      "learning_rate": 2.2862068965517242e-05,
      "loss": 0.0019,
      "step": 1795
    },
    {
      "epoch": 30.96551724137931,
      "grad_norm": 0.03596444055438042,
      "learning_rate": 2.2841379310344826e-05,
      "loss": 0.002,
      "step": 1796
    },
    {
      "epoch": 30.982758620689655,
      "grad_norm": 0.025972088798880577,
      "learning_rate": 2.2820689655172415e-05,
      "loss": 0.0014,
      "step": 1797
    },
    {
      "epoch": 31.0,
      "grad_norm": 0.013419381342828274,
      "learning_rate": 2.2800000000000002e-05,
      "loss": 0.0011,
      "step": 1798
    },
    {
      "epoch": 31.017241379310345,
      "grad_norm": 0.019427908584475517,
      "learning_rate": 2.2779310344827585e-05,
      "loss": 0.0012,
      "step": 1799
    },
    {
      "epoch": 31.03448275862069,
      "grad_norm": 0.028937041759490967,
      "learning_rate": 2.275862068965517e-05,
      "loss": 0.0022,
      "step": 1800
    },
    {
      "epoch": 31.03448275862069,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0014887243742123246,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.1761,
      "eval_samples_per_second": 2.595,
      "eval_steps_per_second": 1.342,
      "step": 1800
    },
    {
      "epoch": 31.051724137931036,
      "grad_norm": 0.0139929773285985,
      "learning_rate": 2.273793103448276e-05,
      "loss": 0.0011,
      "step": 1801
    },
    {
      "epoch": 31.06896551724138,
      "grad_norm": 0.01815476454794407,
      "learning_rate": 2.2717241379310345e-05,
      "loss": 0.0014,
      "step": 1802
    },
    {
      "epoch": 31.086206896551722,
      "grad_norm": 0.022105103358626366,
      "learning_rate": 2.269655172413793e-05,
      "loss": 0.0018,
      "step": 1803
    },
    {
      "epoch": 31.103448275862068,
      "grad_norm": 0.02582291141152382,
      "learning_rate": 2.2675862068965518e-05,
      "loss": 0.0023,
      "step": 1804
    },
    {
      "epoch": 31.120689655172413,
      "grad_norm": 0.025500837713479996,
      "learning_rate": 2.2655172413793104e-05,
      "loss": 0.002,
      "step": 1805
    },
    {
      "epoch": 31.137931034482758,
      "grad_norm": 0.02829209342598915,
      "learning_rate": 2.263448275862069e-05,
      "loss": 0.0014,
      "step": 1806
    },
    {
      "epoch": 31.155172413793103,
      "grad_norm": 0.0407811664044857,
      "learning_rate": 2.2613793103448277e-05,
      "loss": 0.0024,
      "step": 1807
    },
    {
      "epoch": 31.17241379310345,
      "grad_norm": 0.01916816085577011,
      "learning_rate": 2.2593103448275864e-05,
      "loss": 0.0014,
      "step": 1808
    },
    {
      "epoch": 31.189655172413794,
      "grad_norm": 0.014922583475708961,
      "learning_rate": 2.2572413793103447e-05,
      "loss": 0.0014,
      "step": 1809
    },
    {
      "epoch": 31.20689655172414,
      "grad_norm": 0.010620820336043835,
      "learning_rate": 2.2551724137931033e-05,
      "loss": 0.0008,
      "step": 1810
    },
    {
      "epoch": 31.224137931034484,
      "grad_norm": 0.027104098349809647,
      "learning_rate": 2.2531034482758623e-05,
      "loss": 0.0024,
      "step": 1811
    },
    {
      "epoch": 31.24137931034483,
      "grad_norm": 0.02084924839437008,
      "learning_rate": 2.2510344827586206e-05,
      "loss": 0.0014,
      "step": 1812
    },
    {
      "epoch": 31.25862068965517,
      "grad_norm": 0.017834220081567764,
      "learning_rate": 2.2489655172413793e-05,
      "loss": 0.0016,
      "step": 1813
    },
    {
      "epoch": 31.275862068965516,
      "grad_norm": 0.01654946058988571,
      "learning_rate": 2.246896551724138e-05,
      "loss": 0.0016,
      "step": 1814
    },
    {
      "epoch": 31.29310344827586,
      "grad_norm": 0.03969375789165497,
      "learning_rate": 2.2448275862068966e-05,
      "loss": 0.0016,
      "step": 1815
    },
    {
      "epoch": 31.310344827586206,
      "grad_norm": 0.03249813988804817,
      "learning_rate": 2.2427586206896553e-05,
      "loss": 0.0026,
      "step": 1816
    },
    {
      "epoch": 31.32758620689655,
      "grad_norm": 0.012108387425541878,
      "learning_rate": 2.240689655172414e-05,
      "loss": 0.001,
      "step": 1817
    },
    {
      "epoch": 31.344827586206897,
      "grad_norm": 0.023679036647081375,
      "learning_rate": 2.2386206896551726e-05,
      "loss": 0.0024,
      "step": 1818
    },
    {
      "epoch": 31.362068965517242,
      "grad_norm": 0.046099692583084106,
      "learning_rate": 2.236551724137931e-05,
      "loss": 0.0018,
      "step": 1819
    },
    {
      "epoch": 31.379310344827587,
      "grad_norm": 0.014615962281823158,
      "learning_rate": 2.23448275862069e-05,
      "loss": 0.0013,
      "step": 1820
    },
    {
      "epoch": 31.379310344827587,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001604344928637147,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.3844,
      "eval_samples_per_second": 2.547,
      "eval_steps_per_second": 1.318,
      "step": 1820
    },
    {
      "epoch": 31.396551724137932,
      "grad_norm": 0.008510516956448555,
      "learning_rate": 2.2324137931034485e-05,
      "loss": 0.0007,
      "step": 1821
    },
    {
      "epoch": 31.413793103448278,
      "grad_norm": 0.02251223288476467,
      "learning_rate": 2.2303448275862068e-05,
      "loss": 0.0016,
      "step": 1822
    },
    {
      "epoch": 31.43103448275862,
      "grad_norm": 0.04026488959789276,
      "learning_rate": 2.2282758620689655e-05,
      "loss": 0.0021,
      "step": 1823
    },
    {
      "epoch": 31.448275862068964,
      "grad_norm": 0.020097186788916588,
      "learning_rate": 2.226206896551724e-05,
      "loss": 0.002,
      "step": 1824
    },
    {
      "epoch": 31.46551724137931,
      "grad_norm": 0.03932823985815048,
      "learning_rate": 2.2241379310344828e-05,
      "loss": 0.0021,
      "step": 1825
    },
    {
      "epoch": 31.482758620689655,
      "grad_norm": 0.029535816982388496,
      "learning_rate": 2.2220689655172414e-05,
      "loss": 0.0026,
      "step": 1826
    },
    {
      "epoch": 31.5,
      "grad_norm": 0.020588701590895653,
      "learning_rate": 2.22e-05,
      "loss": 0.0018,
      "step": 1827
    },
    {
      "epoch": 31.517241379310345,
      "grad_norm": 0.014818143099546432,
      "learning_rate": 2.2179310344827587e-05,
      "loss": 0.0011,
      "step": 1828
    },
    {
      "epoch": 31.53448275862069,
      "grad_norm": 0.022847818210721016,
      "learning_rate": 2.2158620689655174e-05,
      "loss": 0.0016,
      "step": 1829
    },
    {
      "epoch": 31.551724137931036,
      "grad_norm": 0.016003701835870743,
      "learning_rate": 2.213793103448276e-05,
      "loss": 0.0013,
      "step": 1830
    },
    {
      "epoch": 31.56896551724138,
      "grad_norm": 0.020383968949317932,
      "learning_rate": 2.2117241379310347e-05,
      "loss": 0.002,
      "step": 1831
    },
    {
      "epoch": 31.586206896551722,
      "grad_norm": 0.03350500017404556,
      "learning_rate": 2.209655172413793e-05,
      "loss": 0.0023,
      "step": 1832
    },
    {
      "epoch": 31.603448275862068,
      "grad_norm": 0.019954752177000046,
      "learning_rate": 2.2075862068965517e-05,
      "loss": 0.0015,
      "step": 1833
    },
    {
      "epoch": 31.620689655172413,
      "grad_norm": 0.013138688169419765,
      "learning_rate": 2.2055172413793107e-05,
      "loss": 0.001,
      "step": 1834
    },
    {
      "epoch": 31.637931034482758,
      "grad_norm": 0.013142918236553669,
      "learning_rate": 2.203448275862069e-05,
      "loss": 0.0007,
      "step": 1835
    },
    {
      "epoch": 31.655172413793103,
      "grad_norm": 0.02303137630224228,
      "learning_rate": 2.2013793103448276e-05,
      "loss": 0.0014,
      "step": 1836
    },
    {
      "epoch": 31.67241379310345,
      "grad_norm": 0.020629888400435448,
      "learning_rate": 2.1993103448275863e-05,
      "loss": 0.0017,
      "step": 1837
    },
    {
      "epoch": 31.689655172413794,
      "grad_norm": 0.027493776753544807,
      "learning_rate": 2.1972413793103446e-05,
      "loss": 0.0013,
      "step": 1838
    },
    {
      "epoch": 31.70689655172414,
      "grad_norm": 0.013085001148283482,
      "learning_rate": 2.1951724137931036e-05,
      "loss": 0.0012,
      "step": 1839
    },
    {
      "epoch": 31.724137931034484,
      "grad_norm": 0.021429233253002167,
      "learning_rate": 2.1931034482758622e-05,
      "loss": 0.0018,
      "step": 1840
    },
    {
      "epoch": 31.724137931034484,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001404815586283803,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.0012,
      "eval_samples_per_second": 2.9,
      "eval_steps_per_second": 1.5,
      "step": 1840
    },
    {
      "epoch": 31.74137931034483,
      "grad_norm": 0.017062490805983543,
      "learning_rate": 2.191034482758621e-05,
      "loss": 0.0011,
      "step": 1841
    },
    {
      "epoch": 31.75862068965517,
      "grad_norm": 0.07001810520887375,
      "learning_rate": 2.1889655172413792e-05,
      "loss": 0.0024,
      "step": 1842
    },
    {
      "epoch": 31.775862068965516,
      "grad_norm": 0.018223440274596214,
      "learning_rate": 2.186896551724138e-05,
      "loss": 0.0017,
      "step": 1843
    },
    {
      "epoch": 31.79310344827586,
      "grad_norm": 0.01907842420041561,
      "learning_rate": 2.184827586206897e-05,
      "loss": 0.0014,
      "step": 1844
    },
    {
      "epoch": 31.810344827586206,
      "grad_norm": 0.03388000279664993,
      "learning_rate": 2.182758620689655e-05,
      "loss": 0.0014,
      "step": 1845
    },
    {
      "epoch": 31.82758620689655,
      "grad_norm": 0.01570812426507473,
      "learning_rate": 2.1806896551724138e-05,
      "loss": 0.0013,
      "step": 1846
    },
    {
      "epoch": 31.844827586206897,
      "grad_norm": 0.02178521826863289,
      "learning_rate": 2.1786206896551725e-05,
      "loss": 0.0022,
      "step": 1847
    },
    {
      "epoch": 31.862068965517242,
      "grad_norm": 0.013179662637412548,
      "learning_rate": 2.176551724137931e-05,
      "loss": 0.0011,
      "step": 1848
    },
    {
      "epoch": 31.879310344827587,
      "grad_norm": 0.023251790553331375,
      "learning_rate": 2.1744827586206898e-05,
      "loss": 0.0015,
      "step": 1849
    },
    {
      "epoch": 31.896551724137932,
      "grad_norm": 0.02815287746489048,
      "learning_rate": 2.1724137931034484e-05,
      "loss": 0.0017,
      "step": 1850
    },
    {
      "epoch": 31.913793103448278,
      "grad_norm": 0.03264649584889412,
      "learning_rate": 2.1703448275862067e-05,
      "loss": 0.0015,
      "step": 1851
    },
    {
      "epoch": 31.93103448275862,
      "grad_norm": 0.016403576359152794,
      "learning_rate": 2.1682758620689654e-05,
      "loss": 0.0016,
      "step": 1852
    },
    {
      "epoch": 31.948275862068964,
      "grad_norm": 0.033879686146974564,
      "learning_rate": 2.1662068965517244e-05,
      "loss": 0.0018,
      "step": 1853
    },
    {
      "epoch": 31.96551724137931,
      "grad_norm": 0.0430147647857666,
      "learning_rate": 2.164137931034483e-05,
      "loss": 0.0019,
      "step": 1854
    },
    {
      "epoch": 31.982758620689655,
      "grad_norm": 0.017748260870575905,
      "learning_rate": 2.1620689655172413e-05,
      "loss": 0.0017,
      "step": 1855
    },
    {
      "epoch": 32.0,
      "grad_norm": 0.026513395830988884,
      "learning_rate": 2.16e-05,
      "loss": 0.0019,
      "step": 1856
    },
    {
      "epoch": 32.01724137931034,
      "grad_norm": 0.01551029458642006,
      "learning_rate": 2.1579310344827586e-05,
      "loss": 0.0007,
      "step": 1857
    },
    {
      "epoch": 32.03448275862069,
      "grad_norm": 0.013998174108564854,
      "learning_rate": 2.1558620689655173e-05,
      "loss": 0.0014,
      "step": 1858
    },
    {
      "epoch": 32.05172413793103,
      "grad_norm": 0.031280189752578735,
      "learning_rate": 2.153793103448276e-05,
      "loss": 0.0013,
      "step": 1859
    },
    {
      "epoch": 32.06896551724138,
      "grad_norm": 0.011179558001458645,
      "learning_rate": 2.1517241379310346e-05,
      "loss": 0.0006,
      "step": 1860
    },
    {
      "epoch": 32.06896551724138,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001262393081560731,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.6258,
      "eval_samples_per_second": 3.013,
      "eval_steps_per_second": 1.558,
      "step": 1860
    },
    {
      "epoch": 32.08620689655172,
      "grad_norm": 0.028513308614492416,
      "learning_rate": 2.149655172413793e-05,
      "loss": 0.002,
      "step": 1861
    },
    {
      "epoch": 32.10344827586207,
      "grad_norm": 0.02089848183095455,
      "learning_rate": 2.147586206896552e-05,
      "loss": 0.002,
      "step": 1862
    },
    {
      "epoch": 32.12068965517241,
      "grad_norm": 0.012238701805472374,
      "learning_rate": 2.1455172413793106e-05,
      "loss": 0.0008,
      "step": 1863
    },
    {
      "epoch": 32.13793103448276,
      "grad_norm": 0.020545581355690956,
      "learning_rate": 2.1434482758620692e-05,
      "loss": 0.0015,
      "step": 1864
    },
    {
      "epoch": 32.1551724137931,
      "grad_norm": 0.03813568130135536,
      "learning_rate": 2.1413793103448275e-05,
      "loss": 0.0022,
      "step": 1865
    },
    {
      "epoch": 32.172413793103445,
      "grad_norm": 0.015339973382651806,
      "learning_rate": 2.1393103448275862e-05,
      "loss": 0.0012,
      "step": 1866
    },
    {
      "epoch": 32.189655172413794,
      "grad_norm": 0.0261989738792181,
      "learning_rate": 2.137241379310345e-05,
      "loss": 0.002,
      "step": 1867
    },
    {
      "epoch": 32.206896551724135,
      "grad_norm": 0.01812794990837574,
      "learning_rate": 2.1351724137931035e-05,
      "loss": 0.0014,
      "step": 1868
    },
    {
      "epoch": 32.224137931034484,
      "grad_norm": 0.01385444775223732,
      "learning_rate": 2.133103448275862e-05,
      "loss": 0.0013,
      "step": 1869
    },
    {
      "epoch": 32.241379310344826,
      "grad_norm": 0.03688402846455574,
      "learning_rate": 2.1310344827586208e-05,
      "loss": 0.0023,
      "step": 1870
    },
    {
      "epoch": 32.258620689655174,
      "grad_norm": 0.01904073916375637,
      "learning_rate": 2.128965517241379e-05,
      "loss": 0.0016,
      "step": 1871
    },
    {
      "epoch": 32.275862068965516,
      "grad_norm": 0.015097626484930515,
      "learning_rate": 2.126896551724138e-05,
      "loss": 0.0015,
      "step": 1872
    },
    {
      "epoch": 32.293103448275865,
      "grad_norm": 0.017836688086390495,
      "learning_rate": 2.1248275862068967e-05,
      "loss": 0.0015,
      "step": 1873
    },
    {
      "epoch": 32.310344827586206,
      "grad_norm": 0.019802633672952652,
      "learning_rate": 2.122758620689655e-05,
      "loss": 0.0014,
      "step": 1874
    },
    {
      "epoch": 32.327586206896555,
      "grad_norm": 0.02565005235373974,
      "learning_rate": 2.1206896551724137e-05,
      "loss": 0.0021,
      "step": 1875
    },
    {
      "epoch": 32.3448275862069,
      "grad_norm": 0.019377967342734337,
      "learning_rate": 2.1186206896551724e-05,
      "loss": 0.0016,
      "step": 1876
    },
    {
      "epoch": 32.36206896551724,
      "grad_norm": 0.01278532575815916,
      "learning_rate": 2.1165517241379313e-05,
      "loss": 0.0011,
      "step": 1877
    },
    {
      "epoch": 32.37931034482759,
      "grad_norm": 0.021186305209994316,
      "learning_rate": 2.1144827586206897e-05,
      "loss": 0.0017,
      "step": 1878
    },
    {
      "epoch": 32.39655172413793,
      "grad_norm": 0.05911711975932121,
      "learning_rate": 2.1124137931034483e-05,
      "loss": 0.0027,
      "step": 1879
    },
    {
      "epoch": 32.41379310344828,
      "grad_norm": 0.01934046298265457,
      "learning_rate": 2.110344827586207e-05,
      "loss": 0.002,
      "step": 1880
    },
    {
      "epoch": 32.41379310344828,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0016076896572485566,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.0091,
      "eval_samples_per_second": 2.229,
      "eval_steps_per_second": 1.153,
      "step": 1880
    },
    {
      "epoch": 32.43103448275862,
      "grad_norm": 0.01704694889485836,
      "learning_rate": 2.1082758620689656e-05,
      "loss": 0.0017,
      "step": 1881
    },
    {
      "epoch": 32.44827586206897,
      "grad_norm": 0.07497704774141312,
      "learning_rate": 2.1062068965517243e-05,
      "loss": 0.003,
      "step": 1882
    },
    {
      "epoch": 32.46551724137931,
      "grad_norm": 0.021729659289121628,
      "learning_rate": 2.104137931034483e-05,
      "loss": 0.0019,
      "step": 1883
    },
    {
      "epoch": 32.48275862068966,
      "grad_norm": 0.0279536210000515,
      "learning_rate": 2.1020689655172412e-05,
      "loss": 0.0017,
      "step": 1884
    },
    {
      "epoch": 32.5,
      "grad_norm": 0.03289734944701195,
      "learning_rate": 2.1e-05,
      "loss": 0.0022,
      "step": 1885
    },
    {
      "epoch": 32.51724137931034,
      "grad_norm": 0.01710793375968933,
      "learning_rate": 2.097931034482759e-05,
      "loss": 0.0014,
      "step": 1886
    },
    {
      "epoch": 32.53448275862069,
      "grad_norm": 0.03841826692223549,
      "learning_rate": 2.0958620689655172e-05,
      "loss": 0.0016,
      "step": 1887
    },
    {
      "epoch": 32.55172413793103,
      "grad_norm": 0.024208487942814827,
      "learning_rate": 2.093793103448276e-05,
      "loss": 0.0019,
      "step": 1888
    },
    {
      "epoch": 32.56896551724138,
      "grad_norm": 0.039420757442712784,
      "learning_rate": 2.0917241379310345e-05,
      "loss": 0.002,
      "step": 1889
    },
    {
      "epoch": 32.58620689655172,
      "grad_norm": 0.018884243443608284,
      "learning_rate": 2.089655172413793e-05,
      "loss": 0.0011,
      "step": 1890
    },
    {
      "epoch": 32.60344827586207,
      "grad_norm": 0.024878324940800667,
      "learning_rate": 2.0875862068965518e-05,
      "loss": 0.0024,
      "step": 1891
    },
    {
      "epoch": 32.62068965517241,
      "grad_norm": 0.02570321410894394,
      "learning_rate": 2.0855172413793104e-05,
      "loss": 0.0023,
      "step": 1892
    },
    {
      "epoch": 32.63793103448276,
      "grad_norm": 0.015661317855119705,
      "learning_rate": 2.083448275862069e-05,
      "loss": 0.0016,
      "step": 1893
    },
    {
      "epoch": 32.6551724137931,
      "grad_norm": 0.036828137934207916,
      "learning_rate": 2.0813793103448274e-05,
      "loss": 0.0021,
      "step": 1894
    },
    {
      "epoch": 32.672413793103445,
      "grad_norm": 0.014990543946623802,
      "learning_rate": 2.0793103448275864e-05,
      "loss": 0.0013,
      "step": 1895
    },
    {
      "epoch": 32.689655172413794,
      "grad_norm": 0.022741885855793953,
      "learning_rate": 2.077241379310345e-05,
      "loss": 0.002,
      "step": 1896
    },
    {
      "epoch": 32.706896551724135,
      "grad_norm": 0.024230312556028366,
      "learning_rate": 2.0751724137931034e-05,
      "loss": 0.0013,
      "step": 1897
    },
    {
      "epoch": 32.724137931034484,
      "grad_norm": 0.04104938730597496,
      "learning_rate": 2.073103448275862e-05,
      "loss": 0.0018,
      "step": 1898
    },
    {
      "epoch": 32.741379310344826,
      "grad_norm": 0.023083291947841644,
      "learning_rate": 2.0710344827586207e-05,
      "loss": 0.0013,
      "step": 1899
    },
    {
      "epoch": 32.758620689655174,
      "grad_norm": 0.009380707517266273,
      "learning_rate": 2.0689655172413797e-05,
      "loss": 0.0008,
      "step": 1900
    },
    {
      "epoch": 32.758620689655174,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0014516188530251384,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.419,
      "eval_samples_per_second": 3.079,
      "eval_steps_per_second": 1.593,
      "step": 1900
    },
    {
      "epoch": 32.775862068965516,
      "grad_norm": 0.017820190638303757,
      "learning_rate": 2.066896551724138e-05,
      "loss": 0.001,
      "step": 1901
    },
    {
      "epoch": 32.793103448275865,
      "grad_norm": 0.01918528415262699,
      "learning_rate": 2.0648275862068966e-05,
      "loss": 0.001,
      "step": 1902
    },
    {
      "epoch": 32.810344827586206,
      "grad_norm": 0.03406602144241333,
      "learning_rate": 2.0627586206896553e-05,
      "loss": 0.0021,
      "step": 1903
    },
    {
      "epoch": 32.827586206896555,
      "grad_norm": 0.012422575615346432,
      "learning_rate": 2.0606896551724136e-05,
      "loss": 0.001,
      "step": 1904
    },
    {
      "epoch": 32.8448275862069,
      "grad_norm": 0.016432320699095726,
      "learning_rate": 2.0586206896551726e-05,
      "loss": 0.0014,
      "step": 1905
    },
    {
      "epoch": 32.86206896551724,
      "grad_norm": 0.045017123222351074,
      "learning_rate": 2.0565517241379312e-05,
      "loss": 0.0011,
      "step": 1906
    },
    {
      "epoch": 32.87931034482759,
      "grad_norm": 0.02678154967725277,
      "learning_rate": 2.0544827586206896e-05,
      "loss": 0.0021,
      "step": 1907
    },
    {
      "epoch": 32.89655172413793,
      "grad_norm": 0.012425417080521584,
      "learning_rate": 2.0524137931034482e-05,
      "loss": 0.0007,
      "step": 1908
    },
    {
      "epoch": 32.91379310344828,
      "grad_norm": 0.02011345513164997,
      "learning_rate": 2.050344827586207e-05,
      "loss": 0.002,
      "step": 1909
    },
    {
      "epoch": 32.93103448275862,
      "grad_norm": 0.0334041528403759,
      "learning_rate": 2.0482758620689655e-05,
      "loss": 0.0017,
      "step": 1910
    },
    {
      "epoch": 32.94827586206897,
      "grad_norm": 0.022094208747148514,
      "learning_rate": 2.046206896551724e-05,
      "loss": 0.0019,
      "step": 1911
    },
    {
      "epoch": 32.96551724137931,
      "grad_norm": 0.01756519265472889,
      "learning_rate": 2.0441379310344828e-05,
      "loss": 0.0016,
      "step": 1912
    },
    {
      "epoch": 32.98275862068966,
      "grad_norm": 0.03224422037601471,
      "learning_rate": 2.0420689655172415e-05,
      "loss": 0.0016,
      "step": 1913
    },
    {
      "epoch": 33.0,
      "grad_norm": 0.01461250614374876,
      "learning_rate": 2.04e-05,
      "loss": 0.0014,
      "step": 1914
    },
    {
      "epoch": 33.01724137931034,
      "grad_norm": 0.031000595539808273,
      "learning_rate": 2.0379310344827588e-05,
      "loss": 0.0018,
      "step": 1915
    },
    {
      "epoch": 33.03448275862069,
      "grad_norm": 0.011255700141191483,
      "learning_rate": 2.0358620689655174e-05,
      "loss": 0.001,
      "step": 1916
    },
    {
      "epoch": 33.05172413793103,
      "grad_norm": 0.020706092938780785,
      "learning_rate": 2.0337931034482757e-05,
      "loss": 0.0013,
      "step": 1917
    },
    {
      "epoch": 33.06896551724138,
      "grad_norm": 0.029614226892590523,
      "learning_rate": 2.0317241379310344e-05,
      "loss": 0.0022,
      "step": 1918
    },
    {
      "epoch": 33.08620689655172,
      "grad_norm": 0.013713320717215538,
      "learning_rate": 2.0296551724137934e-05,
      "loss": 0.001,
      "step": 1919
    },
    {
      "epoch": 33.10344827586207,
      "grad_norm": 0.03013800084590912,
      "learning_rate": 2.0275862068965517e-05,
      "loss": 0.0015,
      "step": 1920
    },
    {
      "epoch": 33.10344827586207,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0013587306020781398,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.8956,
      "eval_samples_per_second": 2.931,
      "eval_steps_per_second": 1.516,
      "step": 1920
    },
    {
      "epoch": 33.12068965517241,
      "grad_norm": 0.02303113043308258,
      "learning_rate": 2.0255172413793103e-05,
      "loss": 0.0016,
      "step": 1921
    },
    {
      "epoch": 33.13793103448276,
      "grad_norm": 0.014706998132169247,
      "learning_rate": 2.023448275862069e-05,
      "loss": 0.0012,
      "step": 1922
    },
    {
      "epoch": 33.1551724137931,
      "grad_norm": 0.013082465156912804,
      "learning_rate": 2.0213793103448273e-05,
      "loss": 0.001,
      "step": 1923
    },
    {
      "epoch": 33.172413793103445,
      "grad_norm": 0.025551285594701767,
      "learning_rate": 2.0193103448275863e-05,
      "loss": 0.0018,
      "step": 1924
    },
    {
      "epoch": 33.189655172413794,
      "grad_norm": 0.013829963281750679,
      "learning_rate": 2.017241379310345e-05,
      "loss": 0.0013,
      "step": 1925
    },
    {
      "epoch": 33.206896551724135,
      "grad_norm": 0.014589366503059864,
      "learning_rate": 2.0151724137931036e-05,
      "loss": 0.0009,
      "step": 1926
    },
    {
      "epoch": 33.224137931034484,
      "grad_norm": 0.02861175499856472,
      "learning_rate": 2.013103448275862e-05,
      "loss": 0.0013,
      "step": 1927
    },
    {
      "epoch": 33.241379310344826,
      "grad_norm": 0.035155847668647766,
      "learning_rate": 2.011034482758621e-05,
      "loss": 0.0014,
      "step": 1928
    },
    {
      "epoch": 33.258620689655174,
      "grad_norm": 0.03277447819709778,
      "learning_rate": 2.0089655172413796e-05,
      "loss": 0.0014,
      "step": 1929
    },
    {
      "epoch": 33.275862068965516,
      "grad_norm": 0.09319643676280975,
      "learning_rate": 2.006896551724138e-05,
      "loss": 0.0019,
      "step": 1930
    },
    {
      "epoch": 33.293103448275865,
      "grad_norm": 0.023418797180056572,
      "learning_rate": 2.0048275862068965e-05,
      "loss": 0.0019,
      "step": 1931
    },
    {
      "epoch": 33.310344827586206,
      "grad_norm": 0.02015409618616104,
      "learning_rate": 2.0027586206896552e-05,
      "loss": 0.0013,
      "step": 1932
    },
    {
      "epoch": 33.327586206896555,
      "grad_norm": 0.014208813197910786,
      "learning_rate": 2.000689655172414e-05,
      "loss": 0.001,
      "step": 1933
    },
    {
      "epoch": 33.3448275862069,
      "grad_norm": 0.03205469995737076,
      "learning_rate": 1.9986206896551725e-05,
      "loss": 0.0018,
      "step": 1934
    },
    {
      "epoch": 33.36206896551724,
      "grad_norm": 0.014369136653840542,
      "learning_rate": 1.996551724137931e-05,
      "loss": 0.0013,
      "step": 1935
    },
    {
      "epoch": 33.37931034482759,
      "grad_norm": 0.021055905148386955,
      "learning_rate": 1.9944827586206898e-05,
      "loss": 0.0016,
      "step": 1936
    },
    {
      "epoch": 33.39655172413793,
      "grad_norm": 0.008051816374063492,
      "learning_rate": 1.992413793103448e-05,
      "loss": 0.0007,
      "step": 1937
    },
    {
      "epoch": 33.41379310344828,
      "grad_norm": 0.03306146338582039,
      "learning_rate": 1.990344827586207e-05,
      "loss": 0.0025,
      "step": 1938
    },
    {
      "epoch": 33.43103448275862,
      "grad_norm": 0.018362952396273613,
      "learning_rate": 1.9882758620689657e-05,
      "loss": 0.0011,
      "step": 1939
    },
    {
      "epoch": 33.44827586206897,
      "grad_norm": 0.05038241297006607,
      "learning_rate": 1.986206896551724e-05,
      "loss": 0.0024,
      "step": 1940
    },
    {
      "epoch": 33.44827586206897,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0013040165649726987,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.0266,
      "eval_samples_per_second": 3.213,
      "eval_steps_per_second": 1.662,
      "step": 1940
    },
    {
      "epoch": 33.46551724137931,
      "grad_norm": 0.0199067872017622,
      "learning_rate": 1.9841379310344827e-05,
      "loss": 0.0012,
      "step": 1941
    },
    {
      "epoch": 33.48275862068966,
      "grad_norm": 0.03557801991701126,
      "learning_rate": 1.9820689655172417e-05,
      "loss": 0.002,
      "step": 1942
    },
    {
      "epoch": 33.5,
      "grad_norm": 0.042342595756053925,
      "learning_rate": 1.98e-05,
      "loss": 0.0018,
      "step": 1943
    },
    {
      "epoch": 33.51724137931034,
      "grad_norm": 0.012808522209525108,
      "learning_rate": 1.9779310344827587e-05,
      "loss": 0.001,
      "step": 1944
    },
    {
      "epoch": 33.53448275862069,
      "grad_norm": 0.018854571506381035,
      "learning_rate": 1.9758620689655173e-05,
      "loss": 0.0019,
      "step": 1945
    },
    {
      "epoch": 33.55172413793103,
      "grad_norm": 0.01929868757724762,
      "learning_rate": 1.9737931034482756e-05,
      "loss": 0.0017,
      "step": 1946
    },
    {
      "epoch": 33.56896551724138,
      "grad_norm": 0.019092313945293427,
      "learning_rate": 1.9717241379310346e-05,
      "loss": 0.0016,
      "step": 1947
    },
    {
      "epoch": 33.58620689655172,
      "grad_norm": 0.036134183406829834,
      "learning_rate": 1.9696551724137933e-05,
      "loss": 0.0018,
      "step": 1948
    },
    {
      "epoch": 33.60344827586207,
      "grad_norm": 0.0276075080037117,
      "learning_rate": 1.967586206896552e-05,
      "loss": 0.0024,
      "step": 1949
    },
    {
      "epoch": 33.62068965517241,
      "grad_norm": 0.02829628996551037,
      "learning_rate": 1.9655172413793102e-05,
      "loss": 0.002,
      "step": 1950
    },
    {
      "epoch": 33.63793103448276,
      "grad_norm": 0.0123548349365592,
      "learning_rate": 1.963448275862069e-05,
      "loss": 0.001,
      "step": 1951
    },
    {
      "epoch": 33.6551724137931,
      "grad_norm": 0.014588669873774052,
      "learning_rate": 1.961379310344828e-05,
      "loss": 0.0011,
      "step": 1952
    },
    {
      "epoch": 33.672413793103445,
      "grad_norm": 0.040948785841464996,
      "learning_rate": 1.9593103448275862e-05,
      "loss": 0.0014,
      "step": 1953
    },
    {
      "epoch": 33.689655172413794,
      "grad_norm": 0.02653009258210659,
      "learning_rate": 1.957241379310345e-05,
      "loss": 0.002,
      "step": 1954
    },
    {
      "epoch": 33.706896551724135,
      "grad_norm": 0.024136096239089966,
      "learning_rate": 1.9551724137931035e-05,
      "loss": 0.0018,
      "step": 1955
    },
    {
      "epoch": 33.724137931034484,
      "grad_norm": 0.016910908743739128,
      "learning_rate": 1.9531034482758618e-05,
      "loss": 0.0016,
      "step": 1956
    },
    {
      "epoch": 33.741379310344826,
      "grad_norm": 0.008762170560657978,
      "learning_rate": 1.9510344827586208e-05,
      "loss": 0.0007,
      "step": 1957
    },
    {
      "epoch": 33.758620689655174,
      "grad_norm": 0.019087165594100952,
      "learning_rate": 1.9489655172413795e-05,
      "loss": 0.0017,
      "step": 1958
    },
    {
      "epoch": 33.775862068965516,
      "grad_norm": 0.018336474895477295,
      "learning_rate": 1.9468965517241378e-05,
      "loss": 0.0013,
      "step": 1959
    },
    {
      "epoch": 33.793103448275865,
      "grad_norm": 0.02550196461379528,
      "learning_rate": 1.9448275862068964e-05,
      "loss": 0.0018,
      "step": 1960
    },
    {
      "epoch": 33.793103448275865,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0014140914427116513,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 19.9625,
      "eval_samples_per_second": 1.453,
      "eval_steps_per_second": 0.751,
      "step": 1960
    },
    {
      "epoch": 33.810344827586206,
      "grad_norm": 0.029391327872872353,
      "learning_rate": 1.9427586206896554e-05,
      "loss": 0.0016,
      "step": 1961
    },
    {
      "epoch": 33.827586206896555,
      "grad_norm": 0.01334714237600565,
      "learning_rate": 1.940689655172414e-05,
      "loss": 0.0012,
      "step": 1962
    },
    {
      "epoch": 33.8448275862069,
      "grad_norm": 0.03733312711119652,
      "learning_rate": 1.9386206896551724e-05,
      "loss": 0.0018,
      "step": 1963
    },
    {
      "epoch": 33.86206896551724,
      "grad_norm": 0.015792006626725197,
      "learning_rate": 1.936551724137931e-05,
      "loss": 0.0012,
      "step": 1964
    },
    {
      "epoch": 33.87931034482759,
      "grad_norm": 0.012373175472021103,
      "learning_rate": 1.9344827586206897e-05,
      "loss": 0.001,
      "step": 1965
    },
    {
      "epoch": 33.89655172413793,
      "grad_norm": 0.024203089997172356,
      "learning_rate": 1.9324137931034483e-05,
      "loss": 0.0023,
      "step": 1966
    },
    {
      "epoch": 33.91379310344828,
      "grad_norm": 0.027578124776482582,
      "learning_rate": 1.930344827586207e-05,
      "loss": 0.0019,
      "step": 1967
    },
    {
      "epoch": 33.93103448275862,
      "grad_norm": 0.09695663303136826,
      "learning_rate": 1.9282758620689656e-05,
      "loss": 0.0018,
      "step": 1968
    },
    {
      "epoch": 33.94827586206897,
      "grad_norm": 0.01730969548225403,
      "learning_rate": 1.926206896551724e-05,
      "loss": 0.0014,
      "step": 1969
    },
    {
      "epoch": 33.96551724137931,
      "grad_norm": 0.024103647097945213,
      "learning_rate": 1.9241379310344826e-05,
      "loss": 0.0021,
      "step": 1970
    },
    {
      "epoch": 33.98275862068966,
      "grad_norm": 0.0193028561770916,
      "learning_rate": 1.9220689655172416e-05,
      "loss": 0.0014,
      "step": 1971
    },
    {
      "epoch": 34.0,
      "grad_norm": 0.016166390851140022,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 0.0014,
      "step": 1972
    },
    {
      "epoch": 34.01724137931034,
      "grad_norm": 0.01191688608378172,
      "learning_rate": 1.9179310344827586e-05,
      "loss": 0.0007,
      "step": 1973
    },
    {
      "epoch": 34.03448275862069,
      "grad_norm": 0.013942056335508823,
      "learning_rate": 1.9158620689655172e-05,
      "loss": 0.0011,
      "step": 1974
    },
    {
      "epoch": 34.05172413793103,
      "grad_norm": 0.012943754903972149,
      "learning_rate": 1.9137931034482762e-05,
      "loss": 0.0012,
      "step": 1975
    },
    {
      "epoch": 34.06896551724138,
      "grad_norm": 0.01955682970583439,
      "learning_rate": 1.9117241379310345e-05,
      "loss": 0.0015,
      "step": 1976
    },
    {
      "epoch": 34.08620689655172,
      "grad_norm": 0.00910091120749712,
      "learning_rate": 1.9096551724137932e-05,
      "loss": 0.0005,
      "step": 1977
    },
    {
      "epoch": 34.10344827586207,
      "grad_norm": 0.027374593541026115,
      "learning_rate": 1.9075862068965518e-05,
      "loss": 0.0019,
      "step": 1978
    },
    {
      "epoch": 34.12068965517241,
      "grad_norm": 0.020859036594629288,
      "learning_rate": 1.90551724137931e-05,
      "loss": 0.0017,
      "step": 1979
    },
    {
      "epoch": 34.13793103448276,
      "grad_norm": 0.02899196557700634,
      "learning_rate": 1.903448275862069e-05,
      "loss": 0.0018,
      "step": 1980
    },
    {
      "epoch": 34.13793103448276,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0013037037570029497,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.9073,
      "eval_samples_per_second": 2.659,
      "eval_steps_per_second": 1.375,
      "step": 1980
    },
    {
      "epoch": 34.1551724137931,
      "grad_norm": 0.03368542715907097,
      "learning_rate": 1.9013793103448278e-05,
      "loss": 0.0016,
      "step": 1981
    },
    {
      "epoch": 34.172413793103445,
      "grad_norm": 0.02617700770497322,
      "learning_rate": 1.899310344827586e-05,
      "loss": 0.0022,
      "step": 1982
    },
    {
      "epoch": 34.189655172413794,
      "grad_norm": 0.031028397381305695,
      "learning_rate": 1.8972413793103447e-05,
      "loss": 0.0018,
      "step": 1983
    },
    {
      "epoch": 34.206896551724135,
      "grad_norm": 0.022650260478258133,
      "learning_rate": 1.8951724137931034e-05,
      "loss": 0.0012,
      "step": 1984
    },
    {
      "epoch": 34.224137931034484,
      "grad_norm": 0.01902623474597931,
      "learning_rate": 1.8931034482758624e-05,
      "loss": 0.0014,
      "step": 1985
    },
    {
      "epoch": 34.241379310344826,
      "grad_norm": 0.01624908857047558,
      "learning_rate": 1.8910344827586207e-05,
      "loss": 0.0014,
      "step": 1986
    },
    {
      "epoch": 34.258620689655174,
      "grad_norm": 0.036388810724020004,
      "learning_rate": 1.8889655172413794e-05,
      "loss": 0.0014,
      "step": 1987
    },
    {
      "epoch": 34.275862068965516,
      "grad_norm": 0.02660461701452732,
      "learning_rate": 1.886896551724138e-05,
      "loss": 0.0014,
      "step": 1988
    },
    {
      "epoch": 34.293103448275865,
      "grad_norm": 0.03484923392534256,
      "learning_rate": 1.8848275862068963e-05,
      "loss": 0.0027,
      "step": 1989
    },
    {
      "epoch": 34.310344827586206,
      "grad_norm": 0.027534112334251404,
      "learning_rate": 1.8827586206896553e-05,
      "loss": 0.0021,
      "step": 1990
    },
    {
      "epoch": 34.327586206896555,
      "grad_norm": 0.01997818611562252,
      "learning_rate": 1.880689655172414e-05,
      "loss": 0.0013,
      "step": 1991
    },
    {
      "epoch": 34.3448275862069,
      "grad_norm": 0.01707613468170166,
      "learning_rate": 1.8786206896551723e-05,
      "loss": 0.0012,
      "step": 1992
    },
    {
      "epoch": 34.36206896551724,
      "grad_norm": 0.026145674288272858,
      "learning_rate": 1.876551724137931e-05,
      "loss": 0.0016,
      "step": 1993
    },
    {
      "epoch": 34.37931034482759,
      "grad_norm": 0.04577163979411125,
      "learning_rate": 1.87448275862069e-05,
      "loss": 0.0015,
      "step": 1994
    },
    {
      "epoch": 34.39655172413793,
      "grad_norm": 0.022229038178920746,
      "learning_rate": 1.8724137931034482e-05,
      "loss": 0.0013,
      "step": 1995
    },
    {
      "epoch": 34.41379310344828,
      "grad_norm": 0.02121751569211483,
      "learning_rate": 1.870344827586207e-05,
      "loss": 0.0012,
      "step": 1996
    },
    {
      "epoch": 34.43103448275862,
      "grad_norm": 0.01288007665425539,
      "learning_rate": 1.8682758620689655e-05,
      "loss": 0.001,
      "step": 1997
    },
    {
      "epoch": 34.44827586206897,
      "grad_norm": 0.016470644623041153,
      "learning_rate": 1.8662068965517242e-05,
      "loss": 0.0012,
      "step": 1998
    },
    {
      "epoch": 34.46551724137931,
      "grad_norm": 0.0184593815356493,
      "learning_rate": 1.864137931034483e-05,
      "loss": 0.0017,
      "step": 1999
    },
    {
      "epoch": 34.48275862068966,
      "grad_norm": 0.010180938057601452,
      "learning_rate": 1.8620689655172415e-05,
      "loss": 0.0009,
      "step": 2000
    },
    {
      "epoch": 34.48275862068966,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001263015205040574,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.3026,
      "eval_samples_per_second": 2.815,
      "eval_steps_per_second": 1.456,
      "step": 2000
    },
    {
      "epoch": 34.5,
      "grad_norm": 0.02244737185537815,
      "learning_rate": 1.86e-05,
      "loss": 0.0017,
      "step": 2001
    },
    {
      "epoch": 34.51724137931034,
      "grad_norm": 0.024128269404172897,
      "learning_rate": 1.8579310344827585e-05,
      "loss": 0.0019,
      "step": 2002
    },
    {
      "epoch": 34.53448275862069,
      "grad_norm": 0.011736033484339714,
      "learning_rate": 1.855862068965517e-05,
      "loss": 0.001,
      "step": 2003
    },
    {
      "epoch": 34.55172413793103,
      "grad_norm": 0.023123666644096375,
      "learning_rate": 1.853793103448276e-05,
      "loss": 0.0016,
      "step": 2004
    },
    {
      "epoch": 34.56896551724138,
      "grad_norm": 0.035131435841321945,
      "learning_rate": 1.8517241379310344e-05,
      "loss": 0.0014,
      "step": 2005
    },
    {
      "epoch": 34.58620689655172,
      "grad_norm": 0.0115705830976367,
      "learning_rate": 1.849655172413793e-05,
      "loss": 0.001,
      "step": 2006
    },
    {
      "epoch": 34.60344827586207,
      "grad_norm": 0.01731388457119465,
      "learning_rate": 1.8475862068965517e-05,
      "loss": 0.0013,
      "step": 2007
    },
    {
      "epoch": 34.62068965517241,
      "grad_norm": 0.0179749708622694,
      "learning_rate": 1.8455172413793107e-05,
      "loss": 0.0011,
      "step": 2008
    },
    {
      "epoch": 34.63793103448276,
      "grad_norm": 0.06936085969209671,
      "learning_rate": 1.843448275862069e-05,
      "loss": 0.0023,
      "step": 2009
    },
    {
      "epoch": 34.6551724137931,
      "grad_norm": 0.017603779211640358,
      "learning_rate": 1.8413793103448277e-05,
      "loss": 0.0016,
      "step": 2010
    },
    {
      "epoch": 34.672413793103445,
      "grad_norm": 0.020168760791420937,
      "learning_rate": 1.8393103448275863e-05,
      "loss": 0.0016,
      "step": 2011
    },
    {
      "epoch": 34.689655172413794,
      "grad_norm": 0.01982819475233555,
      "learning_rate": 1.8372413793103446e-05,
      "loss": 0.0015,
      "step": 2012
    },
    {
      "epoch": 34.706896551724135,
      "grad_norm": 0.017861664295196533,
      "learning_rate": 1.8351724137931036e-05,
      "loss": 0.0009,
      "step": 2013
    },
    {
      "epoch": 34.724137931034484,
      "grad_norm": 0.06409130245447159,
      "learning_rate": 1.8331034482758623e-05,
      "loss": 0.0019,
      "step": 2014
    },
    {
      "epoch": 34.741379310344826,
      "grad_norm": 0.01153535395860672,
      "learning_rate": 1.8310344827586206e-05,
      "loss": 0.0011,
      "step": 2015
    },
    {
      "epoch": 34.758620689655174,
      "grad_norm": 0.015028415247797966,
      "learning_rate": 1.8289655172413793e-05,
      "loss": 0.0014,
      "step": 2016
    },
    {
      "epoch": 34.775862068965516,
      "grad_norm": 0.020530354231595993,
      "learning_rate": 1.826896551724138e-05,
      "loss": 0.0015,
      "step": 2017
    },
    {
      "epoch": 34.793103448275865,
      "grad_norm": 0.02815999835729599,
      "learning_rate": 1.8248275862068966e-05,
      "loss": 0.0019,
      "step": 2018
    },
    {
      "epoch": 34.810344827586206,
      "grad_norm": 0.01649980992078781,
      "learning_rate": 1.8227586206896552e-05,
      "loss": 0.0012,
      "step": 2019
    },
    {
      "epoch": 34.827586206896555,
      "grad_norm": 0.02334323525428772,
      "learning_rate": 1.820689655172414e-05,
      "loss": 0.002,
      "step": 2020
    },
    {
      "epoch": 34.827586206896555,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001399569446220994,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.2337,
      "eval_samples_per_second": 2.191,
      "eval_steps_per_second": 1.133,
      "step": 2020
    },
    {
      "epoch": 34.8448275862069,
      "grad_norm": 0.015265071764588356,
      "learning_rate": 1.8186206896551725e-05,
      "loss": 0.0011,
      "step": 2021
    },
    {
      "epoch": 34.86206896551724,
      "grad_norm": 0.032267604023218155,
      "learning_rate": 1.816551724137931e-05,
      "loss": 0.0018,
      "step": 2022
    },
    {
      "epoch": 34.87931034482759,
      "grad_norm": 0.038331903517246246,
      "learning_rate": 1.8144827586206898e-05,
      "loss": 0.0009,
      "step": 2023
    },
    {
      "epoch": 34.89655172413793,
      "grad_norm": 0.02317662350833416,
      "learning_rate": 1.8124137931034485e-05,
      "loss": 0.002,
      "step": 2024
    },
    {
      "epoch": 34.91379310344828,
      "grad_norm": 0.031547993421554565,
      "learning_rate": 1.8103448275862068e-05,
      "loss": 0.0018,
      "step": 2025
    },
    {
      "epoch": 34.93103448275862,
      "grad_norm": 0.022922728210687637,
      "learning_rate": 1.8082758620689654e-05,
      "loss": 0.0019,
      "step": 2026
    },
    {
      "epoch": 34.94827586206897,
      "grad_norm": 0.013626555912196636,
      "learning_rate": 1.8062068965517244e-05,
      "loss": 0.0013,
      "step": 2027
    },
    {
      "epoch": 34.96551724137931,
      "grad_norm": 0.015509521588683128,
      "learning_rate": 1.8041379310344827e-05,
      "loss": 0.0013,
      "step": 2028
    },
    {
      "epoch": 34.98275862068966,
      "grad_norm": 0.028425272554159164,
      "learning_rate": 1.8020689655172414e-05,
      "loss": 0.0014,
      "step": 2029
    },
    {
      "epoch": 35.0,
      "grad_norm": 0.015412144362926483,
      "learning_rate": 1.8e-05,
      "loss": 0.0009,
      "step": 2030
    },
    {
      "epoch": 35.01724137931034,
      "grad_norm": 0.027299486100673676,
      "learning_rate": 1.7979310344827587e-05,
      "loss": 0.0012,
      "step": 2031
    },
    {
      "epoch": 35.03448275862069,
      "grad_norm": 0.02378571592271328,
      "learning_rate": 1.7958620689655173e-05,
      "loss": 0.0019,
      "step": 2032
    },
    {
      "epoch": 35.05172413793103,
      "grad_norm": 0.016574883833527565,
      "learning_rate": 1.793793103448276e-05,
      "loss": 0.0013,
      "step": 2033
    },
    {
      "epoch": 35.06896551724138,
      "grad_norm": 0.019575584679841995,
      "learning_rate": 1.7917241379310347e-05,
      "loss": 0.0017,
      "step": 2034
    },
    {
      "epoch": 35.08620689655172,
      "grad_norm": 0.039327602833509445,
      "learning_rate": 1.789655172413793e-05,
      "loss": 0.0014,
      "step": 2035
    },
    {
      "epoch": 35.10344827586207,
      "grad_norm": 0.012707467190921307,
      "learning_rate": 1.7875862068965516e-05,
      "loss": 0.0012,
      "step": 2036
    },
    {
      "epoch": 35.12068965517241,
      "grad_norm": 0.020843954756855965,
      "learning_rate": 1.7855172413793106e-05,
      "loss": 0.0015,
      "step": 2037
    },
    {
      "epoch": 35.13793103448276,
      "grad_norm": 0.020728163421154022,
      "learning_rate": 1.783448275862069e-05,
      "loss": 0.002,
      "step": 2038
    },
    {
      "epoch": 35.1551724137931,
      "grad_norm": 0.0307772196829319,
      "learning_rate": 1.7813793103448276e-05,
      "loss": 0.0014,
      "step": 2039
    },
    {
      "epoch": 35.172413793103445,
      "grad_norm": 0.017107661813497543,
      "learning_rate": 1.7793103448275862e-05,
      "loss": 0.0009,
      "step": 2040
    },
    {
      "epoch": 35.172413793103445,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0012658672640100121,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.5463,
      "eval_samples_per_second": 2.75,
      "eval_steps_per_second": 1.422,
      "step": 2040
    },
    {
      "epoch": 35.189655172413794,
      "grad_norm": 0.017385004088282585,
      "learning_rate": 1.777241379310345e-05,
      "loss": 0.0014,
      "step": 2041
    },
    {
      "epoch": 35.206896551724135,
      "grad_norm": 0.010424020700156689,
      "learning_rate": 1.7751724137931035e-05,
      "loss": 0.0008,
      "step": 2042
    },
    {
      "epoch": 35.224137931034484,
      "grad_norm": 0.017799945548176765,
      "learning_rate": 1.7731034482758622e-05,
      "loss": 0.0013,
      "step": 2043
    },
    {
      "epoch": 35.241379310344826,
      "grad_norm": 0.014727282337844372,
      "learning_rate": 1.771034482758621e-05,
      "loss": 0.0013,
      "step": 2044
    },
    {
      "epoch": 35.258620689655174,
      "grad_norm": 0.015036596916615963,
      "learning_rate": 1.768965517241379e-05,
      "loss": 0.0011,
      "step": 2045
    },
    {
      "epoch": 35.275862068965516,
      "grad_norm": 0.02513197809457779,
      "learning_rate": 1.766896551724138e-05,
      "loss": 0.0015,
      "step": 2046
    },
    {
      "epoch": 35.293103448275865,
      "grad_norm": 0.02893364429473877,
      "learning_rate": 1.7648275862068968e-05,
      "loss": 0.0012,
      "step": 2047
    },
    {
      "epoch": 35.310344827586206,
      "grad_norm": 0.011136156506836414,
      "learning_rate": 1.762758620689655e-05,
      "loss": 0.0008,
      "step": 2048
    },
    {
      "epoch": 35.327586206896555,
      "grad_norm": 0.011669248342514038,
      "learning_rate": 1.7606896551724138e-05,
      "loss": 0.0006,
      "step": 2049
    },
    {
      "epoch": 35.3448275862069,
      "grad_norm": 0.018207833170890808,
      "learning_rate": 1.7586206896551724e-05,
      "loss": 0.0018,
      "step": 2050
    },
    {
      "epoch": 35.36206896551724,
      "grad_norm": 0.023271173238754272,
      "learning_rate": 1.756551724137931e-05,
      "loss": 0.0018,
      "step": 2051
    },
    {
      "epoch": 35.37931034482759,
      "grad_norm": 0.010940773412585258,
      "learning_rate": 1.7544827586206897e-05,
      "loss": 0.001,
      "step": 2052
    },
    {
      "epoch": 35.39655172413793,
      "grad_norm": 0.01547631248831749,
      "learning_rate": 1.7524137931034484e-05,
      "loss": 0.0013,
      "step": 2053
    },
    {
      "epoch": 35.41379310344828,
      "grad_norm": 0.01697860099375248,
      "learning_rate": 1.7503448275862067e-05,
      "loss": 0.0014,
      "step": 2054
    },
    {
      "epoch": 35.43103448275862,
      "grad_norm": 0.02698943018913269,
      "learning_rate": 1.7482758620689657e-05,
      "loss": 0.002,
      "step": 2055
    },
    {
      "epoch": 35.44827586206897,
      "grad_norm": 0.011599820107221603,
      "learning_rate": 1.7462068965517243e-05,
      "loss": 0.0009,
      "step": 2056
    },
    {
      "epoch": 35.46551724137931,
      "grad_norm": 0.023687776178121567,
      "learning_rate": 1.744137931034483e-05,
      "loss": 0.0014,
      "step": 2057
    },
    {
      "epoch": 35.48275862068966,
      "grad_norm": 0.04174412786960602,
      "learning_rate": 1.7420689655172413e-05,
      "loss": 0.0021,
      "step": 2058
    },
    {
      "epoch": 35.5,
      "grad_norm": 0.015786591917276382,
      "learning_rate": 1.74e-05,
      "loss": 0.0015,
      "step": 2059
    },
    {
      "epoch": 35.51724137931034,
      "grad_norm": 0.015155058354139328,
      "learning_rate": 1.737931034482759e-05,
      "loss": 0.0011,
      "step": 2060
    },
    {
      "epoch": 35.51724137931034,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0012537202564999461,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.6082,
      "eval_samples_per_second": 2.498,
      "eval_steps_per_second": 1.292,
      "step": 2060
    },
    {
      "epoch": 35.53448275862069,
      "grad_norm": 0.01785980351269245,
      "learning_rate": 1.7358620689655172e-05,
      "loss": 0.0014,
      "step": 2061
    },
    {
      "epoch": 35.55172413793103,
      "grad_norm": 0.02415182814002037,
      "learning_rate": 1.733793103448276e-05,
      "loss": 0.0014,
      "step": 2062
    },
    {
      "epoch": 35.56896551724138,
      "grad_norm": 0.017157617956399918,
      "learning_rate": 1.7317241379310346e-05,
      "loss": 0.0016,
      "step": 2063
    },
    {
      "epoch": 35.58620689655172,
      "grad_norm": 0.010673528537154198,
      "learning_rate": 1.729655172413793e-05,
      "loss": 0.0009,
      "step": 2064
    },
    {
      "epoch": 35.60344827586207,
      "grad_norm": 0.02435348555445671,
      "learning_rate": 1.727586206896552e-05,
      "loss": 0.0019,
      "step": 2065
    },
    {
      "epoch": 35.62068965517241,
      "grad_norm": 0.01780281588435173,
      "learning_rate": 1.7255172413793105e-05,
      "loss": 0.0013,
      "step": 2066
    },
    {
      "epoch": 35.63793103448276,
      "grad_norm": 0.013310586102306843,
      "learning_rate": 1.7234482758620688e-05,
      "loss": 0.0012,
      "step": 2067
    },
    {
      "epoch": 35.6551724137931,
      "grad_norm": 0.03149907663464546,
      "learning_rate": 1.7213793103448275e-05,
      "loss": 0.0013,
      "step": 2068
    },
    {
      "epoch": 35.672413793103445,
      "grad_norm": 0.024901436641812325,
      "learning_rate": 1.719310344827586e-05,
      "loss": 0.0013,
      "step": 2069
    },
    {
      "epoch": 35.689655172413794,
      "grad_norm": 0.012367021292448044,
      "learning_rate": 1.717241379310345e-05,
      "loss": 0.0011,
      "step": 2070
    },
    {
      "epoch": 35.706896551724135,
      "grad_norm": 0.022703468799591064,
      "learning_rate": 1.7151724137931034e-05,
      "loss": 0.0022,
      "step": 2071
    },
    {
      "epoch": 35.724137931034484,
      "grad_norm": 0.009565509855747223,
      "learning_rate": 1.713103448275862e-05,
      "loss": 0.0007,
      "step": 2072
    },
    {
      "epoch": 35.741379310344826,
      "grad_norm": 0.0293393824249506,
      "learning_rate": 1.7110344827586207e-05,
      "loss": 0.0021,
      "step": 2073
    },
    {
      "epoch": 35.758620689655174,
      "grad_norm": 0.00867678876966238,
      "learning_rate": 1.7089655172413794e-05,
      "loss": 0.0007,
      "step": 2074
    },
    {
      "epoch": 35.775862068965516,
      "grad_norm": 0.03760102018713951,
      "learning_rate": 1.706896551724138e-05,
      "loss": 0.0016,
      "step": 2075
    },
    {
      "epoch": 35.793103448275865,
      "grad_norm": 0.01924715004861355,
      "learning_rate": 1.7048275862068967e-05,
      "loss": 0.0011,
      "step": 2076
    },
    {
      "epoch": 35.810344827586206,
      "grad_norm": 0.01757456734776497,
      "learning_rate": 1.702758620689655e-05,
      "loss": 0.0015,
      "step": 2077
    },
    {
      "epoch": 35.827586206896555,
      "grad_norm": 0.01721980795264244,
      "learning_rate": 1.7006896551724137e-05,
      "loss": 0.0017,
      "step": 2078
    },
    {
      "epoch": 35.8448275862069,
      "grad_norm": 0.04972844198346138,
      "learning_rate": 1.6986206896551726e-05,
      "loss": 0.0018,
      "step": 2079
    },
    {
      "epoch": 35.86206896551724,
      "grad_norm": 0.02899257093667984,
      "learning_rate": 1.6965517241379313e-05,
      "loss": 0.0014,
      "step": 2080
    },
    {
      "epoch": 35.86206896551724,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0012673933524638414,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.1124,
      "eval_samples_per_second": 2.61,
      "eval_steps_per_second": 1.35,
      "step": 2080
    },
    {
      "epoch": 35.87931034482759,
      "grad_norm": 0.013968906365334988,
      "learning_rate": 1.6944827586206896e-05,
      "loss": 0.0013,
      "step": 2081
    },
    {
      "epoch": 35.89655172413793,
      "grad_norm": 0.01868373714387417,
      "learning_rate": 1.6924137931034483e-05,
      "loss": 0.0014,
      "step": 2082
    },
    {
      "epoch": 35.91379310344828,
      "grad_norm": 0.015235522761940956,
      "learning_rate": 1.690344827586207e-05,
      "loss": 0.0015,
      "step": 2083
    },
    {
      "epoch": 35.93103448275862,
      "grad_norm": 0.041713036596775055,
      "learning_rate": 1.6882758620689656e-05,
      "loss": 0.002,
      "step": 2084
    },
    {
      "epoch": 35.94827586206897,
      "grad_norm": 0.028251372277736664,
      "learning_rate": 1.6862068965517242e-05,
      "loss": 0.0015,
      "step": 2085
    },
    {
      "epoch": 35.96551724137931,
      "grad_norm": 0.02651337720453739,
      "learning_rate": 1.684137931034483e-05,
      "loss": 0.0019,
      "step": 2086
    },
    {
      "epoch": 35.98275862068966,
      "grad_norm": 0.03570710867643356,
      "learning_rate": 1.6820689655172412e-05,
      "loss": 0.0022,
      "step": 2087
    },
    {
      "epoch": 36.0,
      "grad_norm": 0.030833104625344276,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 0.0021,
      "step": 2088
    },
    {
      "epoch": 36.01724137931034,
      "grad_norm": 0.013640675693750381,
      "learning_rate": 1.6779310344827588e-05,
      "loss": 0.001,
      "step": 2089
    },
    {
      "epoch": 36.03448275862069,
      "grad_norm": 0.015471797436475754,
      "learning_rate": 1.675862068965517e-05,
      "loss": 0.0013,
      "step": 2090
    },
    {
      "epoch": 36.05172413793103,
      "grad_norm": 0.019610028713941574,
      "learning_rate": 1.6737931034482758e-05,
      "loss": 0.0019,
      "step": 2091
    },
    {
      "epoch": 36.06896551724138,
      "grad_norm": 0.015442796051502228,
      "learning_rate": 1.6717241379310344e-05,
      "loss": 0.0014,
      "step": 2092
    },
    {
      "epoch": 36.08620689655172,
      "grad_norm": 0.011222125962376595,
      "learning_rate": 1.6696551724137934e-05,
      "loss": 0.0008,
      "step": 2093
    },
    {
      "epoch": 36.10344827586207,
      "grad_norm": 0.012431041337549686,
      "learning_rate": 1.6675862068965518e-05,
      "loss": 0.0011,
      "step": 2094
    },
    {
      "epoch": 36.12068965517241,
      "grad_norm": 0.01602952927350998,
      "learning_rate": 1.6655172413793104e-05,
      "loss": 0.0014,
      "step": 2095
    },
    {
      "epoch": 36.13793103448276,
      "grad_norm": 0.042952559888362885,
      "learning_rate": 1.663448275862069e-05,
      "loss": 0.0012,
      "step": 2096
    },
    {
      "epoch": 36.1551724137931,
      "grad_norm": 0.028259282931685448,
      "learning_rate": 1.6613793103448274e-05,
      "loss": 0.0011,
      "step": 2097
    },
    {
      "epoch": 36.172413793103445,
      "grad_norm": 0.012891963124275208,
      "learning_rate": 1.6593103448275864e-05,
      "loss": 0.0011,
      "step": 2098
    },
    {
      "epoch": 36.189655172413794,
      "grad_norm": 0.03151797130703926,
      "learning_rate": 1.657241379310345e-05,
      "loss": 0.0012,
      "step": 2099
    },
    {
      "epoch": 36.206896551724135,
      "grad_norm": 0.033815111964941025,
      "learning_rate": 1.6551724137931033e-05,
      "loss": 0.0023,
      "step": 2100
    },
    {
      "epoch": 36.206896551724135,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0012792774941772223,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.0337,
      "eval_samples_per_second": 3.21,
      "eval_steps_per_second": 1.66,
      "step": 2100
    },
    {
      "epoch": 36.224137931034484,
      "grad_norm": 0.012633668258786201,
      "learning_rate": 1.653103448275862e-05,
      "loss": 0.0012,
      "step": 2101
    },
    {
      "epoch": 36.241379310344826,
      "grad_norm": 0.018540551885962486,
      "learning_rate": 1.6510344827586206e-05,
      "loss": 0.0017,
      "step": 2102
    },
    {
      "epoch": 36.258620689655174,
      "grad_norm": 0.020947666838765144,
      "learning_rate": 1.6489655172413793e-05,
      "loss": 0.0009,
      "step": 2103
    },
    {
      "epoch": 36.275862068965516,
      "grad_norm": 0.019621945917606354,
      "learning_rate": 1.646896551724138e-05,
      "loss": 0.0016,
      "step": 2104
    },
    {
      "epoch": 36.293103448275865,
      "grad_norm": 0.017503727227449417,
      "learning_rate": 1.6448275862068966e-05,
      "loss": 0.0015,
      "step": 2105
    },
    {
      "epoch": 36.310344827586206,
      "grad_norm": 0.014765935018658638,
      "learning_rate": 1.6427586206896552e-05,
      "loss": 0.0009,
      "step": 2106
    },
    {
      "epoch": 36.327586206896555,
      "grad_norm": 0.025356119498610497,
      "learning_rate": 1.640689655172414e-05,
      "loss": 0.0015,
      "step": 2107
    },
    {
      "epoch": 36.3448275862069,
      "grad_norm": 0.01451739389449358,
      "learning_rate": 1.6386206896551725e-05,
      "loss": 0.0012,
      "step": 2108
    },
    {
      "epoch": 36.36206896551724,
      "grad_norm": 0.020563075318932533,
      "learning_rate": 1.6365517241379312e-05,
      "loss": 0.0011,
      "step": 2109
    },
    {
      "epoch": 36.37931034482759,
      "grad_norm": 0.01772204600274563,
      "learning_rate": 1.6344827586206895e-05,
      "loss": 0.0016,
      "step": 2110
    },
    {
      "epoch": 36.39655172413793,
      "grad_norm": 0.018138619139790535,
      "learning_rate": 1.632413793103448e-05,
      "loss": 0.0015,
      "step": 2111
    },
    {
      "epoch": 36.41379310344828,
      "grad_norm": 0.02811351604759693,
      "learning_rate": 1.630344827586207e-05,
      "loss": 0.0012,
      "step": 2112
    },
    {
      "epoch": 36.43103448275862,
      "grad_norm": 0.017736846581101418,
      "learning_rate": 1.6282758620689655e-05,
      "loss": 0.0016,
      "step": 2113
    },
    {
      "epoch": 36.44827586206897,
      "grad_norm": 0.012752111069858074,
      "learning_rate": 1.626206896551724e-05,
      "loss": 0.001,
      "step": 2114
    },
    {
      "epoch": 36.46551724137931,
      "grad_norm": 0.05265747010707855,
      "learning_rate": 1.6241379310344828e-05,
      "loss": 0.0017,
      "step": 2115
    },
    {
      "epoch": 36.48275862068966,
      "grad_norm": 0.01166393980383873,
      "learning_rate": 1.6220689655172414e-05,
      "loss": 0.001,
      "step": 2116
    },
    {
      "epoch": 36.5,
      "grad_norm": 0.01604631170630455,
      "learning_rate": 1.62e-05,
      "loss": 0.0013,
      "step": 2117
    },
    {
      "epoch": 36.51724137931034,
      "grad_norm": 0.0146062346175313,
      "learning_rate": 1.6179310344827587e-05,
      "loss": 0.0015,
      "step": 2118
    },
    {
      "epoch": 36.53448275862069,
      "grad_norm": 0.040360160171985626,
      "learning_rate": 1.6158620689655174e-05,
      "loss": 0.0018,
      "step": 2119
    },
    {
      "epoch": 36.55172413793103,
      "grad_norm": 0.03269040957093239,
      "learning_rate": 1.6137931034482757e-05,
      "loss": 0.002,
      "step": 2120
    },
    {
      "epoch": 36.55172413793103,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0013088886626064777,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.2696,
      "eval_samples_per_second": 2.185,
      "eval_steps_per_second": 1.13,
      "step": 2120
    },
    {
      "epoch": 36.56896551724138,
      "grad_norm": 0.015168646350502968,
      "learning_rate": 1.6117241379310347e-05,
      "loss": 0.0013,
      "step": 2121
    },
    {
      "epoch": 36.58620689655172,
      "grad_norm": 0.0311414897441864,
      "learning_rate": 1.6096551724137933e-05,
      "loss": 0.0017,
      "step": 2122
    },
    {
      "epoch": 36.60344827586207,
      "grad_norm": 0.0218220017850399,
      "learning_rate": 1.6075862068965516e-05,
      "loss": 0.0015,
      "step": 2123
    },
    {
      "epoch": 36.62068965517241,
      "grad_norm": 0.014363917522132397,
      "learning_rate": 1.6055172413793103e-05,
      "loss": 0.0013,
      "step": 2124
    },
    {
      "epoch": 36.63793103448276,
      "grad_norm": 0.013020096346735954,
      "learning_rate": 1.603448275862069e-05,
      "loss": 0.0012,
      "step": 2125
    },
    {
      "epoch": 36.6551724137931,
      "grad_norm": 0.04543689638376236,
      "learning_rate": 1.6013793103448276e-05,
      "loss": 0.0032,
      "step": 2126
    },
    {
      "epoch": 36.672413793103445,
      "grad_norm": 0.021612394601106644,
      "learning_rate": 1.5993103448275863e-05,
      "loss": 0.0017,
      "step": 2127
    },
    {
      "epoch": 36.689655172413794,
      "grad_norm": 0.015984443947672844,
      "learning_rate": 1.597241379310345e-05,
      "loss": 0.0016,
      "step": 2128
    },
    {
      "epoch": 36.706896551724135,
      "grad_norm": 0.023192329332232475,
      "learning_rate": 1.5951724137931036e-05,
      "loss": 0.0016,
      "step": 2129
    },
    {
      "epoch": 36.724137931034484,
      "grad_norm": 0.02498023584485054,
      "learning_rate": 1.593103448275862e-05,
      "loss": 0.0022,
      "step": 2130
    },
    {
      "epoch": 36.741379310344826,
      "grad_norm": 0.006764500867575407,
      "learning_rate": 1.591034482758621e-05,
      "loss": 0.0006,
      "step": 2131
    },
    {
      "epoch": 36.758620689655174,
      "grad_norm": 0.020756464451551437,
      "learning_rate": 1.5889655172413795e-05,
      "loss": 0.0016,
      "step": 2132
    },
    {
      "epoch": 36.775862068965516,
      "grad_norm": 0.02103603444993496,
      "learning_rate": 1.586896551724138e-05,
      "loss": 0.0012,
      "step": 2133
    },
    {
      "epoch": 36.793103448275865,
      "grad_norm": 0.01505731325596571,
      "learning_rate": 1.5848275862068965e-05,
      "loss": 0.0013,
      "step": 2134
    },
    {
      "epoch": 36.810344827586206,
      "grad_norm": 0.022191382944583893,
      "learning_rate": 1.5827586206896555e-05,
      "loss": 0.0022,
      "step": 2135
    },
    {
      "epoch": 36.827586206896555,
      "grad_norm": 0.01300407201051712,
      "learning_rate": 1.5806896551724138e-05,
      "loss": 0.001,
      "step": 2136
    },
    {
      "epoch": 36.8448275862069,
      "grad_norm": 0.013359974138438702,
      "learning_rate": 1.5786206896551724e-05,
      "loss": 0.0006,
      "step": 2137
    },
    {
      "epoch": 36.86206896551724,
      "grad_norm": 0.024991102516651154,
      "learning_rate": 1.576551724137931e-05,
      "loss": 0.0016,
      "step": 2138
    },
    {
      "epoch": 36.87931034482759,
      "grad_norm": 0.010716690681874752,
      "learning_rate": 1.5744827586206897e-05,
      "loss": 0.0009,
      "step": 2139
    },
    {
      "epoch": 36.89655172413793,
      "grad_norm": 0.012407911010086536,
      "learning_rate": 1.5724137931034484e-05,
      "loss": 0.0008,
      "step": 2140
    },
    {
      "epoch": 36.89655172413793,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001200222410261631,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.2143,
      "eval_samples_per_second": 2.586,
      "eval_steps_per_second": 1.338,
      "step": 2140
    },
    {
      "epoch": 36.91379310344828,
      "grad_norm": 0.013567900285124779,
      "learning_rate": 1.570344827586207e-05,
      "loss": 0.001,
      "step": 2141
    },
    {
      "epoch": 36.93103448275862,
      "grad_norm": 0.010801028460264206,
      "learning_rate": 1.5682758620689657e-05,
      "loss": 0.0009,
      "step": 2142
    },
    {
      "epoch": 36.94827586206897,
      "grad_norm": 0.03288646414875984,
      "learning_rate": 1.566206896551724e-05,
      "loss": 0.0015,
      "step": 2143
    },
    {
      "epoch": 36.96551724137931,
      "grad_norm": 0.014478609897196293,
      "learning_rate": 1.5641379310344827e-05,
      "loss": 0.0014,
      "step": 2144
    },
    {
      "epoch": 36.98275862068966,
      "grad_norm": 0.020929522812366486,
      "learning_rate": 1.5620689655172417e-05,
      "loss": 0.0019,
      "step": 2145
    },
    {
      "epoch": 37.0,
      "grad_norm": 0.022736329585313797,
      "learning_rate": 1.56e-05,
      "loss": 0.002,
      "step": 2146
    },
    {
      "epoch": 37.01724137931034,
      "grad_norm": 0.02147400937974453,
      "learning_rate": 1.5579310344827586e-05,
      "loss": 0.0012,
      "step": 2147
    },
    {
      "epoch": 37.03448275862069,
      "grad_norm": 0.02277693897485733,
      "learning_rate": 1.5558620689655173e-05,
      "loss": 0.001,
      "step": 2148
    },
    {
      "epoch": 37.05172413793103,
      "grad_norm": 0.028688538819551468,
      "learning_rate": 1.5537931034482756e-05,
      "loss": 0.0022,
      "step": 2149
    },
    {
      "epoch": 37.06896551724138,
      "grad_norm": 0.0161477942019701,
      "learning_rate": 1.5517241379310346e-05,
      "loss": 0.0013,
      "step": 2150
    },
    {
      "epoch": 37.08620689655172,
      "grad_norm": 0.021411655470728874,
      "learning_rate": 1.5496551724137932e-05,
      "loss": 0.0017,
      "step": 2151
    },
    {
      "epoch": 37.10344827586207,
      "grad_norm": 0.02877677232027054,
      "learning_rate": 1.547586206896552e-05,
      "loss": 0.0013,
      "step": 2152
    },
    {
      "epoch": 37.12068965517241,
      "grad_norm": 0.016623934730887413,
      "learning_rate": 1.5455172413793102e-05,
      "loss": 0.0014,
      "step": 2153
    },
    {
      "epoch": 37.13793103448276,
      "grad_norm": 0.028893020004034042,
      "learning_rate": 1.5434482758620692e-05,
      "loss": 0.0013,
      "step": 2154
    },
    {
      "epoch": 37.1551724137931,
      "grad_norm": 0.018998609855771065,
      "learning_rate": 1.541379310344828e-05,
      "loss": 0.0012,
      "step": 2155
    },
    {
      "epoch": 37.172413793103445,
      "grad_norm": 0.026007497683167458,
      "learning_rate": 1.539310344827586e-05,
      "loss": 0.0017,
      "step": 2156
    },
    {
      "epoch": 37.189655172413794,
      "grad_norm": 0.013395873829722404,
      "learning_rate": 1.5372413793103448e-05,
      "loss": 0.0012,
      "step": 2157
    },
    {
      "epoch": 37.206896551724135,
      "grad_norm": 0.013939158990979195,
      "learning_rate": 1.5351724137931035e-05,
      "loss": 0.0014,
      "step": 2158
    },
    {
      "epoch": 37.224137931034484,
      "grad_norm": 0.015332109294831753,
      "learning_rate": 1.533103448275862e-05,
      "loss": 0.0014,
      "step": 2159
    },
    {
      "epoch": 37.241379310344826,
      "grad_norm": 0.030398234724998474,
      "learning_rate": 1.5310344827586208e-05,
      "loss": 0.0011,
      "step": 2160
    },
    {
      "epoch": 37.241379310344826,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001308733713813126,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.6425,
      "eval_samples_per_second": 2.725,
      "eval_steps_per_second": 1.409,
      "step": 2160
    },
    {
      "epoch": 37.258620689655174,
      "grad_norm": 0.015592389740049839,
      "learning_rate": 1.5289655172413794e-05,
      "loss": 0.0013,
      "step": 2161
    },
    {
      "epoch": 37.275862068965516,
      "grad_norm": 0.022592870518565178,
      "learning_rate": 1.5268965517241377e-05,
      "loss": 0.0021,
      "step": 2162
    },
    {
      "epoch": 37.293103448275865,
      "grad_norm": 0.016094883903861046,
      "learning_rate": 1.5248275862068964e-05,
      "loss": 0.0015,
      "step": 2163
    },
    {
      "epoch": 37.310344827586206,
      "grad_norm": 0.018378887325525284,
      "learning_rate": 1.5227586206896554e-05,
      "loss": 0.001,
      "step": 2164
    },
    {
      "epoch": 37.327586206896555,
      "grad_norm": 0.01602247729897499,
      "learning_rate": 1.5206896551724139e-05,
      "loss": 0.0012,
      "step": 2165
    },
    {
      "epoch": 37.3448275862069,
      "grad_norm": 0.019141795113682747,
      "learning_rate": 1.5186206896551725e-05,
      "loss": 0.0015,
      "step": 2166
    },
    {
      "epoch": 37.36206896551724,
      "grad_norm": 0.017110725864768028,
      "learning_rate": 1.516551724137931e-05,
      "loss": 0.0017,
      "step": 2167
    },
    {
      "epoch": 37.37931034482759,
      "grad_norm": 0.021583419293165207,
      "learning_rate": 1.5144827586206898e-05,
      "loss": 0.0012,
      "step": 2168
    },
    {
      "epoch": 37.39655172413793,
      "grad_norm": 0.04086422175168991,
      "learning_rate": 1.5124137931034485e-05,
      "loss": 0.0014,
      "step": 2169
    },
    {
      "epoch": 37.41379310344828,
      "grad_norm": 0.018236542120575905,
      "learning_rate": 1.510344827586207e-05,
      "loss": 0.0013,
      "step": 2170
    },
    {
      "epoch": 37.43103448275862,
      "grad_norm": 0.013554293662309647,
      "learning_rate": 1.5082758620689654e-05,
      "loss": 0.0007,
      "step": 2171
    },
    {
      "epoch": 37.44827586206897,
      "grad_norm": 0.03692188113927841,
      "learning_rate": 1.506206896551724e-05,
      "loss": 0.0022,
      "step": 2172
    },
    {
      "epoch": 37.46551724137931,
      "grad_norm": 0.013032093644142151,
      "learning_rate": 1.5041379310344829e-05,
      "loss": 0.0013,
      "step": 2173
    },
    {
      "epoch": 37.48275862068966,
      "grad_norm": 0.021638385951519012,
      "learning_rate": 1.5020689655172416e-05,
      "loss": 0.0019,
      "step": 2174
    },
    {
      "epoch": 37.5,
      "grad_norm": 0.018063809722661972,
      "learning_rate": 1.5e-05,
      "loss": 0.0014,
      "step": 2175
    },
    {
      "epoch": 37.51724137931034,
      "grad_norm": 0.018799178302288055,
      "learning_rate": 1.4979310344827585e-05,
      "loss": 0.0015,
      "step": 2176
    },
    {
      "epoch": 37.53448275862069,
      "grad_norm": 0.017859112471342087,
      "learning_rate": 1.4958620689655173e-05,
      "loss": 0.0008,
      "step": 2177
    },
    {
      "epoch": 37.55172413793103,
      "grad_norm": 0.020199444144964218,
      "learning_rate": 1.4937931034482758e-05,
      "loss": 0.0014,
      "step": 2178
    },
    {
      "epoch": 37.56896551724138,
      "grad_norm": 0.018188510090112686,
      "learning_rate": 1.4917241379310346e-05,
      "loss": 0.0011,
      "step": 2179
    },
    {
      "epoch": 37.58620689655172,
      "grad_norm": 0.012202423997223377,
      "learning_rate": 1.4896551724137931e-05,
      "loss": 0.0011,
      "step": 2180
    },
    {
      "epoch": 37.58620689655172,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0011999245034530759,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.8068,
      "eval_samples_per_second": 2.456,
      "eval_steps_per_second": 1.27,
      "step": 2180
    },
    {
      "epoch": 37.60344827586207,
      "grad_norm": 0.026829157024621964,
      "learning_rate": 1.4875862068965518e-05,
      "loss": 0.0013,
      "step": 2181
    },
    {
      "epoch": 37.62068965517241,
      "grad_norm": 0.047503165900707245,
      "learning_rate": 1.4855172413793104e-05,
      "loss": 0.002,
      "step": 2182
    },
    {
      "epoch": 37.63793103448276,
      "grad_norm": 0.017206039279699326,
      "learning_rate": 1.483448275862069e-05,
      "loss": 0.0011,
      "step": 2183
    },
    {
      "epoch": 37.6551724137931,
      "grad_norm": 0.020729560405015945,
      "learning_rate": 1.4813793103448276e-05,
      "loss": 0.0008,
      "step": 2184
    },
    {
      "epoch": 37.672413793103445,
      "grad_norm": 0.012542099691927433,
      "learning_rate": 1.4793103448275862e-05,
      "loss": 0.0008,
      "step": 2185
    },
    {
      "epoch": 37.689655172413794,
      "grad_norm": 0.012741087935864925,
      "learning_rate": 1.4772413793103449e-05,
      "loss": 0.001,
      "step": 2186
    },
    {
      "epoch": 37.706896551724135,
      "grad_norm": 0.01312162633985281,
      "learning_rate": 1.4751724137931035e-05,
      "loss": 0.001,
      "step": 2187
    },
    {
      "epoch": 37.724137931034484,
      "grad_norm": 0.017157426103949547,
      "learning_rate": 1.4731034482758622e-05,
      "loss": 0.0012,
      "step": 2188
    },
    {
      "epoch": 37.741379310344826,
      "grad_norm": 0.021558890119194984,
      "learning_rate": 1.4710344827586207e-05,
      "loss": 0.0021,
      "step": 2189
    },
    {
      "epoch": 37.758620689655174,
      "grad_norm": 0.016406554728746414,
      "learning_rate": 1.4689655172413793e-05,
      "loss": 0.0014,
      "step": 2190
    },
    {
      "epoch": 37.775862068965516,
      "grad_norm": 0.020005108788609505,
      "learning_rate": 1.466896551724138e-05,
      "loss": 0.0009,
      "step": 2191
    },
    {
      "epoch": 37.793103448275865,
      "grad_norm": 0.012314903549849987,
      "learning_rate": 1.4648275862068966e-05,
      "loss": 0.001,
      "step": 2192
    },
    {
      "epoch": 37.810344827586206,
      "grad_norm": 0.016437843441963196,
      "learning_rate": 1.4627586206896553e-05,
      "loss": 0.0012,
      "step": 2193
    },
    {
      "epoch": 37.827586206896555,
      "grad_norm": 0.015866493806242943,
      "learning_rate": 1.4606896551724138e-05,
      "loss": 0.0014,
      "step": 2194
    },
    {
      "epoch": 37.8448275862069,
      "grad_norm": 0.014278199523687363,
      "learning_rate": 1.4586206896551724e-05,
      "loss": 0.0014,
      "step": 2195
    },
    {
      "epoch": 37.86206896551724,
      "grad_norm": 0.0403444766998291,
      "learning_rate": 1.456551724137931e-05,
      "loss": 0.002,
      "step": 2196
    },
    {
      "epoch": 37.87931034482759,
      "grad_norm": 0.030247274786233902,
      "learning_rate": 1.4544827586206897e-05,
      "loss": 0.0012,
      "step": 2197
    },
    {
      "epoch": 37.89655172413793,
      "grad_norm": 0.025940898805856705,
      "learning_rate": 1.4524137931034484e-05,
      "loss": 0.0014,
      "step": 2198
    },
    {
      "epoch": 37.91379310344828,
      "grad_norm": 0.029122203588485718,
      "learning_rate": 1.4503448275862068e-05,
      "loss": 0.0016,
      "step": 2199
    },
    {
      "epoch": 37.93103448275862,
      "grad_norm": 0.013103623874485493,
      "learning_rate": 1.4482758620689657e-05,
      "loss": 0.0013,
      "step": 2200
    },
    {
      "epoch": 37.93103448275862,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0012271757004782557,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.3527,
      "eval_samples_per_second": 2.554,
      "eval_steps_per_second": 1.321,
      "step": 2200
    },
    {
      "epoch": 37.94827586206897,
      "grad_norm": 0.011520487256348133,
      "learning_rate": 1.4462068965517241e-05,
      "loss": 0.001,
      "step": 2201
    },
    {
      "epoch": 37.96551724137931,
      "grad_norm": 0.011913605965673923,
      "learning_rate": 1.4441379310344828e-05,
      "loss": 0.0011,
      "step": 2202
    },
    {
      "epoch": 37.98275862068966,
      "grad_norm": 0.010330015793442726,
      "learning_rate": 1.4420689655172415e-05,
      "loss": 0.0008,
      "step": 2203
    },
    {
      "epoch": 38.0,
      "grad_norm": 0.012982151471078396,
      "learning_rate": 1.44e-05,
      "loss": 0.001,
      "step": 2204
    },
    {
      "epoch": 38.01724137931034,
      "grad_norm": 0.013720497488975525,
      "learning_rate": 1.4379310344827588e-05,
      "loss": 0.0012,
      "step": 2205
    },
    {
      "epoch": 38.03448275862069,
      "grad_norm": 0.014853655360639095,
      "learning_rate": 1.4358620689655172e-05,
      "loss": 0.0013,
      "step": 2206
    },
    {
      "epoch": 38.05172413793103,
      "grad_norm": 0.024543115869164467,
      "learning_rate": 1.4337931034482759e-05,
      "loss": 0.0016,
      "step": 2207
    },
    {
      "epoch": 38.06896551724138,
      "grad_norm": 0.012257869355380535,
      "learning_rate": 1.4317241379310345e-05,
      "loss": 0.0011,
      "step": 2208
    },
    {
      "epoch": 38.08620689655172,
      "grad_norm": 0.02069980464875698,
      "learning_rate": 1.429655172413793e-05,
      "loss": 0.0017,
      "step": 2209
    },
    {
      "epoch": 38.10344827586207,
      "grad_norm": 0.01910669170320034,
      "learning_rate": 1.4275862068965518e-05,
      "loss": 0.0016,
      "step": 2210
    },
    {
      "epoch": 38.12068965517241,
      "grad_norm": 0.04500601068139076,
      "learning_rate": 1.4255172413793103e-05,
      "loss": 0.0017,
      "step": 2211
    },
    {
      "epoch": 38.13793103448276,
      "grad_norm": 0.01417578849941492,
      "learning_rate": 1.423448275862069e-05,
      "loss": 0.0011,
      "step": 2212
    },
    {
      "epoch": 38.1551724137931,
      "grad_norm": 0.02557709813117981,
      "learning_rate": 1.4213793103448276e-05,
      "loss": 0.0018,
      "step": 2213
    },
    {
      "epoch": 38.172413793103445,
      "grad_norm": 0.026647306978702545,
      "learning_rate": 1.4193103448275863e-05,
      "loss": 0.0015,
      "step": 2214
    },
    {
      "epoch": 38.189655172413794,
      "grad_norm": 0.01808273233473301,
      "learning_rate": 1.417241379310345e-05,
      "loss": 0.0016,
      "step": 2215
    },
    {
      "epoch": 38.206896551724135,
      "grad_norm": 0.022305317223072052,
      "learning_rate": 1.4151724137931034e-05,
      "loss": 0.0011,
      "step": 2216
    },
    {
      "epoch": 38.224137931034484,
      "grad_norm": 0.01804821938276291,
      "learning_rate": 1.413103448275862e-05,
      "loss": 0.001,
      "step": 2217
    },
    {
      "epoch": 38.241379310344826,
      "grad_norm": 0.015000784769654274,
      "learning_rate": 1.4110344827586207e-05,
      "loss": 0.0015,
      "step": 2218
    },
    {
      "epoch": 38.258620689655174,
      "grad_norm": 0.017240555956959724,
      "learning_rate": 1.4089655172413794e-05,
      "loss": 0.0016,
      "step": 2219
    },
    {
      "epoch": 38.275862068965516,
      "grad_norm": 0.012730796821415424,
      "learning_rate": 1.406896551724138e-05,
      "loss": 0.0009,
      "step": 2220
    },
    {
      "epoch": 38.275862068965516,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001233200542628765,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.3069,
      "eval_samples_per_second": 2.565,
      "eval_steps_per_second": 1.327,
      "step": 2220
    },
    {
      "epoch": 38.293103448275865,
      "grad_norm": 0.020438382402062416,
      "learning_rate": 1.4048275862068967e-05,
      "loss": 0.0013,
      "step": 2221
    },
    {
      "epoch": 38.310344827586206,
      "grad_norm": 0.015051690861582756,
      "learning_rate": 1.4027586206896552e-05,
      "loss": 0.0012,
      "step": 2222
    },
    {
      "epoch": 38.327586206896555,
      "grad_norm": 0.014369224198162556,
      "learning_rate": 1.4006896551724138e-05,
      "loss": 0.0013,
      "step": 2223
    },
    {
      "epoch": 38.3448275862069,
      "grad_norm": 0.02440926618874073,
      "learning_rate": 1.3986206896551725e-05,
      "loss": 0.0011,
      "step": 2224
    },
    {
      "epoch": 38.36206896551724,
      "grad_norm": 0.008308674208819866,
      "learning_rate": 1.396551724137931e-05,
      "loss": 0.0008,
      "step": 2225
    },
    {
      "epoch": 38.37931034482759,
      "grad_norm": 0.021425293758511543,
      "learning_rate": 1.3944827586206898e-05,
      "loss": 0.0009,
      "step": 2226
    },
    {
      "epoch": 38.39655172413793,
      "grad_norm": 0.01521150954067707,
      "learning_rate": 1.3924137931034483e-05,
      "loss": 0.0009,
      "step": 2227
    },
    {
      "epoch": 38.41379310344828,
      "grad_norm": 0.02544720657169819,
      "learning_rate": 1.390344827586207e-05,
      "loss": 0.0012,
      "step": 2228
    },
    {
      "epoch": 38.43103448275862,
      "grad_norm": 0.00825134851038456,
      "learning_rate": 1.3882758620689656e-05,
      "loss": 0.0006,
      "step": 2229
    },
    {
      "epoch": 38.44827586206897,
      "grad_norm": 0.015797823667526245,
      "learning_rate": 1.386206896551724e-05,
      "loss": 0.0013,
      "step": 2230
    },
    {
      "epoch": 38.46551724137931,
      "grad_norm": 0.015705512836575508,
      "learning_rate": 1.3841379310344829e-05,
      "loss": 0.0016,
      "step": 2231
    },
    {
      "epoch": 38.48275862068966,
      "grad_norm": 0.0121800247579813,
      "learning_rate": 1.3820689655172413e-05,
      "loss": 0.001,
      "step": 2232
    },
    {
      "epoch": 38.5,
      "grad_norm": 0.009699806571006775,
      "learning_rate": 1.3800000000000002e-05,
      "loss": 0.0008,
      "step": 2233
    },
    {
      "epoch": 38.51724137931034,
      "grad_norm": 0.02446112409234047,
      "learning_rate": 1.3779310344827587e-05,
      "loss": 0.0015,
      "step": 2234
    },
    {
      "epoch": 38.53448275862069,
      "grad_norm": 0.01194690726697445,
      "learning_rate": 1.3758620689655171e-05,
      "loss": 0.0011,
      "step": 2235
    },
    {
      "epoch": 38.55172413793103,
      "grad_norm": 0.011440793052315712,
      "learning_rate": 1.373793103448276e-05,
      "loss": 0.001,
      "step": 2236
    },
    {
      "epoch": 38.56896551724138,
      "grad_norm": 0.03376033529639244,
      "learning_rate": 1.3717241379310344e-05,
      "loss": 0.0015,
      "step": 2237
    },
    {
      "epoch": 38.58620689655172,
      "grad_norm": 0.0262239258736372,
      "learning_rate": 1.3696551724137933e-05,
      "loss": 0.0016,
      "step": 2238
    },
    {
      "epoch": 38.60344827586207,
      "grad_norm": 0.018842607736587524,
      "learning_rate": 1.3675862068965517e-05,
      "loss": 0.0011,
      "step": 2239
    },
    {
      "epoch": 38.62068965517241,
      "grad_norm": 0.018231162801384926,
      "learning_rate": 1.3655172413793104e-05,
      "loss": 0.0019,
      "step": 2240
    },
    {
      "epoch": 38.62068965517241,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0011705467477440834,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.1263,
      "eval_samples_per_second": 2.209,
      "eval_steps_per_second": 1.143,
      "step": 2240
    },
    {
      "epoch": 38.63793103448276,
      "grad_norm": 0.011091441847383976,
      "learning_rate": 1.363448275862069e-05,
      "loss": 0.0009,
      "step": 2241
    },
    {
      "epoch": 38.6551724137931,
      "grad_norm": 0.036963872611522675,
      "learning_rate": 1.3613793103448275e-05,
      "loss": 0.002,
      "step": 2242
    },
    {
      "epoch": 38.672413793103445,
      "grad_norm": 0.01054028607904911,
      "learning_rate": 1.3593103448275862e-05,
      "loss": 0.001,
      "step": 2243
    },
    {
      "epoch": 38.689655172413794,
      "grad_norm": 0.014349733479321003,
      "learning_rate": 1.3572413793103448e-05,
      "loss": 0.0006,
      "step": 2244
    },
    {
      "epoch": 38.706896551724135,
      "grad_norm": 0.013884608633816242,
      "learning_rate": 1.3551724137931035e-05,
      "loss": 0.0013,
      "step": 2245
    },
    {
      "epoch": 38.724137931034484,
      "grad_norm": 0.016395078971982002,
      "learning_rate": 1.3531034482758621e-05,
      "loss": 0.0013,
      "step": 2246
    },
    {
      "epoch": 38.741379310344826,
      "grad_norm": 0.02132219634950161,
      "learning_rate": 1.3510344827586208e-05,
      "loss": 0.0012,
      "step": 2247
    },
    {
      "epoch": 38.758620689655174,
      "grad_norm": 0.014147753827273846,
      "learning_rate": 1.3489655172413793e-05,
      "loss": 0.0014,
      "step": 2248
    },
    {
      "epoch": 38.775862068965516,
      "grad_norm": 0.011342765763401985,
      "learning_rate": 1.346896551724138e-05,
      "loss": 0.0008,
      "step": 2249
    },
    {
      "epoch": 38.793103448275865,
      "grad_norm": 0.010795637965202332,
      "learning_rate": 1.3448275862068966e-05,
      "loss": 0.0008,
      "step": 2250
    },
    {
      "epoch": 38.810344827586206,
      "grad_norm": 0.019534891471266747,
      "learning_rate": 1.3427586206896552e-05,
      "loss": 0.0015,
      "step": 2251
    },
    {
      "epoch": 38.827586206896555,
      "grad_norm": 0.012315130792558193,
      "learning_rate": 1.3406896551724139e-05,
      "loss": 0.0009,
      "step": 2252
    },
    {
      "epoch": 38.8448275862069,
      "grad_norm": 0.014699478633701801,
      "learning_rate": 1.3386206896551724e-05,
      "loss": 0.0011,
      "step": 2253
    },
    {
      "epoch": 38.86206896551724,
      "grad_norm": 0.017304740846157074,
      "learning_rate": 1.3365517241379312e-05,
      "loss": 0.0014,
      "step": 2254
    },
    {
      "epoch": 38.87931034482759,
      "grad_norm": 0.010680804960429668,
      "learning_rate": 1.3344827586206897e-05,
      "loss": 0.001,
      "step": 2255
    },
    {
      "epoch": 38.89655172413793,
      "grad_norm": 0.016185905784368515,
      "learning_rate": 1.3324137931034483e-05,
      "loss": 0.0015,
      "step": 2256
    },
    {
      "epoch": 38.91379310344828,
      "grad_norm": 0.019891701638698578,
      "learning_rate": 1.330344827586207e-05,
      "loss": 0.001,
      "step": 2257
    },
    {
      "epoch": 38.93103448275862,
      "grad_norm": 0.04243754222989082,
      "learning_rate": 1.3282758620689655e-05,
      "loss": 0.0017,
      "step": 2258
    },
    {
      "epoch": 38.94827586206897,
      "grad_norm": 0.02442021481692791,
      "learning_rate": 1.3262068965517243e-05,
      "loss": 0.0021,
      "step": 2259
    },
    {
      "epoch": 38.96551724137931,
      "grad_norm": 0.07844947278499603,
      "learning_rate": 1.3241379310344828e-05,
      "loss": 0.0019,
      "step": 2260
    },
    {
      "epoch": 38.96551724137931,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0012589507969096303,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.9476,
      "eval_samples_per_second": 2.24,
      "eval_steps_per_second": 1.159,
      "step": 2260
    },
    {
      "epoch": 38.98275862068966,
      "grad_norm": 0.030601967126131058,
      "learning_rate": 1.3220689655172414e-05,
      "loss": 0.0015,
      "step": 2261
    },
    {
      "epoch": 39.0,
      "grad_norm": 0.03813064843416214,
      "learning_rate": 1.32e-05,
      "loss": 0.0017,
      "step": 2262
    },
    {
      "epoch": 39.01724137931034,
      "grad_norm": 0.01286629680544138,
      "learning_rate": 1.3179310344827586e-05,
      "loss": 0.0011,
      "step": 2263
    },
    {
      "epoch": 39.03448275862069,
      "grad_norm": 0.019983353093266487,
      "learning_rate": 1.3158620689655174e-05,
      "loss": 0.0018,
      "step": 2264
    },
    {
      "epoch": 39.05172413793103,
      "grad_norm": 0.024967070668935776,
      "learning_rate": 1.3137931034482759e-05,
      "loss": 0.0015,
      "step": 2265
    },
    {
      "epoch": 39.06896551724138,
      "grad_norm": 0.014498346485197544,
      "learning_rate": 1.3117241379310345e-05,
      "loss": 0.0013,
      "step": 2266
    },
    {
      "epoch": 39.08620689655172,
      "grad_norm": 0.008831191807985306,
      "learning_rate": 1.3096551724137932e-05,
      "loss": 0.0008,
      "step": 2267
    },
    {
      "epoch": 39.10344827586207,
      "grad_norm": 0.03807450085878372,
      "learning_rate": 1.3075862068965518e-05,
      "loss": 0.0011,
      "step": 2268
    },
    {
      "epoch": 39.12068965517241,
      "grad_norm": 0.015088967978954315,
      "learning_rate": 1.3055172413793105e-05,
      "loss": 0.0013,
      "step": 2269
    },
    {
      "epoch": 39.13793103448276,
      "grad_norm": 0.014808113686740398,
      "learning_rate": 1.303448275862069e-05,
      "loss": 0.0014,
      "step": 2270
    },
    {
      "epoch": 39.1551724137931,
      "grad_norm": 0.01894516870379448,
      "learning_rate": 1.3013793103448276e-05,
      "loss": 0.0018,
      "step": 2271
    },
    {
      "epoch": 39.172413793103445,
      "grad_norm": 0.018414540216326714,
      "learning_rate": 1.2993103448275863e-05,
      "loss": 0.001,
      "step": 2272
    },
    {
      "epoch": 39.189655172413794,
      "grad_norm": 0.029661381617188454,
      "learning_rate": 1.2972413793103449e-05,
      "loss": 0.001,
      "step": 2273
    },
    {
      "epoch": 39.206896551724135,
      "grad_norm": 0.02460774965584278,
      "learning_rate": 1.2951724137931036e-05,
      "loss": 0.0012,
      "step": 2274
    },
    {
      "epoch": 39.224137931034484,
      "grad_norm": 0.034036412835121155,
      "learning_rate": 1.293103448275862e-05,
      "loss": 0.0014,
      "step": 2275
    },
    {
      "epoch": 39.241379310344826,
      "grad_norm": 0.010353672318160534,
      "learning_rate": 1.2910344827586207e-05,
      "loss": 0.0009,
      "step": 2276
    },
    {
      "epoch": 39.258620689655174,
      "grad_norm": 0.0535803884267807,
      "learning_rate": 1.2889655172413793e-05,
      "loss": 0.0017,
      "step": 2277
    },
    {
      "epoch": 39.275862068965516,
      "grad_norm": 0.013294034637510777,
      "learning_rate": 1.286896551724138e-05,
      "loss": 0.0012,
      "step": 2278
    },
    {
      "epoch": 39.293103448275865,
      "grad_norm": 0.015237466432154179,
      "learning_rate": 1.2848275862068965e-05,
      "loss": 0.0009,
      "step": 2279
    },
    {
      "epoch": 39.310344827586206,
      "grad_norm": 0.010412423871457577,
      "learning_rate": 1.2827586206896553e-05,
      "loss": 0.0009,
      "step": 2280
    },
    {
      "epoch": 39.310344827586206,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0011153306113556027,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.3014,
      "eval_samples_per_second": 2.566,
      "eval_steps_per_second": 1.327,
      "step": 2280
    },
    {
      "epoch": 39.327586206896555,
      "grad_norm": 0.03332224860787392,
      "learning_rate": 1.2806896551724138e-05,
      "loss": 0.0014,
      "step": 2281
    },
    {
      "epoch": 39.3448275862069,
      "grad_norm": 0.013850311748683453,
      "learning_rate": 1.2786206896551724e-05,
      "loss": 0.0011,
      "step": 2282
    },
    {
      "epoch": 39.36206896551724,
      "grad_norm": 0.031332094222307205,
      "learning_rate": 1.2765517241379311e-05,
      "loss": 0.001,
      "step": 2283
    },
    {
      "epoch": 39.37931034482759,
      "grad_norm": 0.01741112396121025,
      "learning_rate": 1.2744827586206896e-05,
      "loss": 0.0015,
      "step": 2284
    },
    {
      "epoch": 39.39655172413793,
      "grad_norm": 0.018152575939893723,
      "learning_rate": 1.2724137931034484e-05,
      "loss": 0.0017,
      "step": 2285
    },
    {
      "epoch": 39.41379310344828,
      "grad_norm": 0.021344786509871483,
      "learning_rate": 1.2703448275862069e-05,
      "loss": 0.0015,
      "step": 2286
    },
    {
      "epoch": 39.43103448275862,
      "grad_norm": 0.030757198110222816,
      "learning_rate": 1.2682758620689657e-05,
      "loss": 0.0012,
      "step": 2287
    },
    {
      "epoch": 39.44827586206897,
      "grad_norm": 0.014575311914086342,
      "learning_rate": 1.2662068965517242e-05,
      "loss": 0.0013,
      "step": 2288
    },
    {
      "epoch": 39.46551724137931,
      "grad_norm": 0.016226209700107574,
      "learning_rate": 1.2641379310344827e-05,
      "loss": 0.0011,
      "step": 2289
    },
    {
      "epoch": 39.48275862068966,
      "grad_norm": 0.03921894729137421,
      "learning_rate": 1.2620689655172415e-05,
      "loss": 0.0016,
      "step": 2290
    },
    {
      "epoch": 39.5,
      "grad_norm": 0.009763416834175587,
      "learning_rate": 1.26e-05,
      "loss": 0.0009,
      "step": 2291
    },
    {
      "epoch": 39.51724137931034,
      "grad_norm": 2.573286771774292,
      "learning_rate": 1.2579310344827588e-05,
      "loss": 0.0048,
      "step": 2292
    },
    {
      "epoch": 39.53448275862069,
      "grad_norm": 0.016796952113509178,
      "learning_rate": 1.2558620689655173e-05,
      "loss": 0.0014,
      "step": 2293
    },
    {
      "epoch": 39.55172413793103,
      "grad_norm": 0.014772890135645866,
      "learning_rate": 1.253793103448276e-05,
      "loss": 0.0011,
      "step": 2294
    },
    {
      "epoch": 39.56896551724138,
      "grad_norm": 0.017819946631789207,
      "learning_rate": 1.2517241379310346e-05,
      "loss": 0.0008,
      "step": 2295
    },
    {
      "epoch": 39.58620689655172,
      "grad_norm": 0.02329285442829132,
      "learning_rate": 1.249655172413793e-05,
      "loss": 0.0008,
      "step": 2296
    },
    {
      "epoch": 39.60344827586207,
      "grad_norm": 0.009211907163262367,
      "learning_rate": 1.2475862068965517e-05,
      "loss": 0.0005,
      "step": 2297
    },
    {
      "epoch": 39.62068965517241,
      "grad_norm": 0.01257126871496439,
      "learning_rate": 1.2455172413793104e-05,
      "loss": 0.0012,
      "step": 2298
    },
    {
      "epoch": 39.63793103448276,
      "grad_norm": 0.01159930881112814,
      "learning_rate": 1.243448275862069e-05,
      "loss": 0.0009,
      "step": 2299
    },
    {
      "epoch": 39.6551724137931,
      "grad_norm": 0.016790855675935745,
      "learning_rate": 1.2413793103448277e-05,
      "loss": 0.001,
      "step": 2300
    },
    {
      "epoch": 39.6551724137931,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0009406174067407846,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 14.102,
      "eval_samples_per_second": 2.056,
      "eval_steps_per_second": 1.064,
      "step": 2300
    },
    {
      "epoch": 39.672413793103445,
      "grad_norm": 0.018162624910473824,
      "learning_rate": 1.2393103448275863e-05,
      "loss": 0.0016,
      "step": 2301
    },
    {
      "epoch": 39.689655172413794,
      "grad_norm": 0.020395293831825256,
      "learning_rate": 1.2372413793103448e-05,
      "loss": 0.0018,
      "step": 2302
    },
    {
      "epoch": 39.706896551724135,
      "grad_norm": 0.018057653680443764,
      "learning_rate": 1.2351724137931035e-05,
      "loss": 0.0016,
      "step": 2303
    },
    {
      "epoch": 39.724137931034484,
      "grad_norm": 0.030435049906373024,
      "learning_rate": 1.2331034482758621e-05,
      "loss": 0.0017,
      "step": 2304
    },
    {
      "epoch": 39.741379310344826,
      "grad_norm": 0.021267449483275414,
      "learning_rate": 1.2310344827586208e-05,
      "loss": 0.0011,
      "step": 2305
    },
    {
      "epoch": 39.758620689655174,
      "grad_norm": 0.010829751379787922,
      "learning_rate": 1.2289655172413794e-05,
      "loss": 0.001,
      "step": 2306
    },
    {
      "epoch": 39.775862068965516,
      "grad_norm": 0.011283806525170803,
      "learning_rate": 1.2268965517241379e-05,
      "loss": 0.001,
      "step": 2307
    },
    {
      "epoch": 39.793103448275865,
      "grad_norm": 0.021990973502397537,
      "learning_rate": 1.2248275862068967e-05,
      "loss": 0.0016,
      "step": 2308
    },
    {
      "epoch": 39.810344827586206,
      "grad_norm": 0.016767043620347977,
      "learning_rate": 1.2227586206896552e-05,
      "loss": 0.0016,
      "step": 2309
    },
    {
      "epoch": 39.827586206896555,
      "grad_norm": 0.011530056595802307,
      "learning_rate": 1.2206896551724138e-05,
      "loss": 0.001,
      "step": 2310
    },
    {
      "epoch": 39.8448275862069,
      "grad_norm": 0.0227969940751791,
      "learning_rate": 1.2186206896551725e-05,
      "loss": 0.0012,
      "step": 2311
    },
    {
      "epoch": 39.86206896551724,
      "grad_norm": 0.020204387605190277,
      "learning_rate": 1.216551724137931e-05,
      "loss": 0.0018,
      "step": 2312
    },
    {
      "epoch": 39.87931034482759,
      "grad_norm": 0.009824306704103947,
      "learning_rate": 1.2144827586206898e-05,
      "loss": 0.0009,
      "step": 2313
    },
    {
      "epoch": 39.89655172413793,
      "grad_norm": 0.04725850373506546,
      "learning_rate": 1.2124137931034483e-05,
      "loss": 0.0018,
      "step": 2314
    },
    {
      "epoch": 39.91379310344828,
      "grad_norm": 0.012876796536147594,
      "learning_rate": 1.2103448275862068e-05,
      "loss": 0.0011,
      "step": 2315
    },
    {
      "epoch": 39.93103448275862,
      "grad_norm": 0.018672330304980278,
      "learning_rate": 1.2082758620689656e-05,
      "loss": 0.0018,
      "step": 2316
    },
    {
      "epoch": 39.94827586206897,
      "grad_norm": 0.026865830644965172,
      "learning_rate": 1.206206896551724e-05,
      "loss": 0.0013,
      "step": 2317
    },
    {
      "epoch": 39.96551724137931,
      "grad_norm": 0.014494047500193119,
      "learning_rate": 1.2041379310344829e-05,
      "loss": 0.0015,
      "step": 2318
    },
    {
      "epoch": 39.98275862068966,
      "grad_norm": 0.025665704160928726,
      "learning_rate": 1.2020689655172414e-05,
      "loss": 0.0014,
      "step": 2319
    },
    {
      "epoch": 40.0,
      "grad_norm": 0.020398009568452835,
      "learning_rate": 1.2e-05,
      "loss": 0.0007,
      "step": 2320
    },
    {
      "epoch": 40.0,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001153062330558896,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.5316,
      "eval_samples_per_second": 3.042,
      "eval_steps_per_second": 1.574,
      "step": 2320
    },
    {
      "epoch": 40.01724137931034,
      "grad_norm": 0.02071906439960003,
      "learning_rate": 1.1979310344827587e-05,
      "loss": 0.0014,
      "step": 2321
    },
    {
      "epoch": 40.03448275862069,
      "grad_norm": 0.02457084320485592,
      "learning_rate": 1.1958620689655172e-05,
      "loss": 0.0013,
      "step": 2322
    },
    {
      "epoch": 40.05172413793103,
      "grad_norm": 0.0255174171179533,
      "learning_rate": 1.193793103448276e-05,
      "loss": 0.0018,
      "step": 2323
    },
    {
      "epoch": 40.06896551724138,
      "grad_norm": 0.01288112998008728,
      "learning_rate": 1.1917241379310345e-05,
      "loss": 0.0011,
      "step": 2324
    },
    {
      "epoch": 40.08620689655172,
      "grad_norm": 0.01804046519100666,
      "learning_rate": 1.1896551724137931e-05,
      "loss": 0.0011,
      "step": 2325
    },
    {
      "epoch": 40.10344827586207,
      "grad_norm": 0.019227612763643265,
      "learning_rate": 1.1875862068965518e-05,
      "loss": 0.0015,
      "step": 2326
    },
    {
      "epoch": 40.12068965517241,
      "grad_norm": 0.02339119277894497,
      "learning_rate": 1.1855172413793104e-05,
      "loss": 0.0015,
      "step": 2327
    },
    {
      "epoch": 40.13793103448276,
      "grad_norm": 0.017271017655730247,
      "learning_rate": 1.183448275862069e-05,
      "loss": 0.0009,
      "step": 2328
    },
    {
      "epoch": 40.1551724137931,
      "grad_norm": 0.025336148217320442,
      "learning_rate": 1.1813793103448276e-05,
      "loss": 0.0017,
      "step": 2329
    },
    {
      "epoch": 40.172413793103445,
      "grad_norm": 0.02307095006108284,
      "learning_rate": 1.1793103448275862e-05,
      "loss": 0.0015,
      "step": 2330
    },
    {
      "epoch": 40.189655172413794,
      "grad_norm": 0.02197914756834507,
      "learning_rate": 1.1772413793103449e-05,
      "loss": 0.0019,
      "step": 2331
    },
    {
      "epoch": 40.206896551724135,
      "grad_norm": 0.015602834522724152,
      "learning_rate": 1.1751724137931035e-05,
      "loss": 0.0015,
      "step": 2332
    },
    {
      "epoch": 40.224137931034484,
      "grad_norm": 0.014743163250386715,
      "learning_rate": 1.173103448275862e-05,
      "loss": 0.0012,
      "step": 2333
    },
    {
      "epoch": 40.241379310344826,
      "grad_norm": 0.01209969725459814,
      "learning_rate": 1.1710344827586208e-05,
      "loss": 0.0011,
      "step": 2334
    },
    {
      "epoch": 40.258620689655174,
      "grad_norm": 0.010944929905235767,
      "learning_rate": 1.1689655172413793e-05,
      "loss": 0.0008,
      "step": 2335
    },
    {
      "epoch": 40.275862068965516,
      "grad_norm": 0.030160535126924515,
      "learning_rate": 1.166896551724138e-05,
      "loss": 0.001,
      "step": 2336
    },
    {
      "epoch": 40.293103448275865,
      "grad_norm": 0.016153840348124504,
      "learning_rate": 1.1648275862068966e-05,
      "loss": 0.0011,
      "step": 2337
    },
    {
      "epoch": 40.310344827586206,
      "grad_norm": 0.013606426306068897,
      "learning_rate": 1.1627586206896551e-05,
      "loss": 0.0012,
      "step": 2338
    },
    {
      "epoch": 40.327586206896555,
      "grad_norm": 0.009317646734416485,
      "learning_rate": 1.1606896551724139e-05,
      "loss": 0.0007,
      "step": 2339
    },
    {
      "epoch": 40.3448275862069,
      "grad_norm": 0.014587792567908764,
      "learning_rate": 1.1586206896551724e-05,
      "loss": 0.0011,
      "step": 2340
    },
    {
      "epoch": 40.3448275862069,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010764680337160826,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.1651,
      "eval_samples_per_second": 2.853,
      "eval_steps_per_second": 1.476,
      "step": 2340
    },
    {
      "epoch": 40.36206896551724,
      "grad_norm": 0.013095982372760773,
      "learning_rate": 1.1565517241379312e-05,
      "loss": 0.0012,
      "step": 2341
    },
    {
      "epoch": 40.37931034482759,
      "grad_norm": 0.010137304663658142,
      "learning_rate": 1.1544827586206897e-05,
      "loss": 0.0009,
      "step": 2342
    },
    {
      "epoch": 40.39655172413793,
      "grad_norm": 0.031074441969394684,
      "learning_rate": 1.1524137931034482e-05,
      "loss": 0.0015,
      "step": 2343
    },
    {
      "epoch": 40.41379310344828,
      "grad_norm": 0.01782269775867462,
      "learning_rate": 1.150344827586207e-05,
      "loss": 0.0014,
      "step": 2344
    },
    {
      "epoch": 40.43103448275862,
      "grad_norm": 0.021295856684446335,
      "learning_rate": 1.1482758620689655e-05,
      "loss": 0.0013,
      "step": 2345
    },
    {
      "epoch": 40.44827586206897,
      "grad_norm": 0.009901045821607113,
      "learning_rate": 1.1462068965517243e-05,
      "loss": 0.0007,
      "step": 2346
    },
    {
      "epoch": 40.46551724137931,
      "grad_norm": 0.020618626847863197,
      "learning_rate": 1.1441379310344828e-05,
      "loss": 0.0013,
      "step": 2347
    },
    {
      "epoch": 40.48275862068966,
      "grad_norm": 0.012020851485431194,
      "learning_rate": 1.1420689655172413e-05,
      "loss": 0.0008,
      "step": 2348
    },
    {
      "epoch": 40.5,
      "grad_norm": 0.017477065324783325,
      "learning_rate": 1.1400000000000001e-05,
      "loss": 0.0016,
      "step": 2349
    },
    {
      "epoch": 40.51724137931034,
      "grad_norm": 0.021709417924284935,
      "learning_rate": 1.1379310344827586e-05,
      "loss": 0.0015,
      "step": 2350
    },
    {
      "epoch": 40.53448275862069,
      "grad_norm": 0.021192070096731186,
      "learning_rate": 1.1358620689655172e-05,
      "loss": 0.0012,
      "step": 2351
    },
    {
      "epoch": 40.55172413793103,
      "grad_norm": 0.018338559195399284,
      "learning_rate": 1.1337931034482759e-05,
      "loss": 0.0013,
      "step": 2352
    },
    {
      "epoch": 40.56896551724138,
      "grad_norm": 0.015045332722365856,
      "learning_rate": 1.1317241379310345e-05,
      "loss": 0.0012,
      "step": 2353
    },
    {
      "epoch": 40.58620689655172,
      "grad_norm": 0.019144494086503983,
      "learning_rate": 1.1296551724137932e-05,
      "loss": 0.0012,
      "step": 2354
    },
    {
      "epoch": 40.60344827586207,
      "grad_norm": 0.017589019611477852,
      "learning_rate": 1.1275862068965517e-05,
      "loss": 0.0007,
      "step": 2355
    },
    {
      "epoch": 40.62068965517241,
      "grad_norm": 0.01348591223359108,
      "learning_rate": 1.1255172413793103e-05,
      "loss": 0.001,
      "step": 2356
    },
    {
      "epoch": 40.63793103448276,
      "grad_norm": 0.019232064485549927,
      "learning_rate": 1.123448275862069e-05,
      "loss": 0.001,
      "step": 2357
    },
    {
      "epoch": 40.6551724137931,
      "grad_norm": 0.012566917575895786,
      "learning_rate": 1.1213793103448276e-05,
      "loss": 0.0009,
      "step": 2358
    },
    {
      "epoch": 40.672413793103445,
      "grad_norm": 0.01623922400176525,
      "learning_rate": 1.1193103448275863e-05,
      "loss": 0.0009,
      "step": 2359
    },
    {
      "epoch": 40.689655172413794,
      "grad_norm": 0.01493439357727766,
      "learning_rate": 1.117241379310345e-05,
      "loss": 0.0009,
      "step": 2360
    },
    {
      "epoch": 40.689655172413794,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0009874618845060468,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.2361,
      "eval_samples_per_second": 2.191,
      "eval_steps_per_second": 1.133,
      "step": 2360
    },
    {
      "epoch": 40.706896551724135,
      "grad_norm": 0.01979527436196804,
      "learning_rate": 1.1151724137931034e-05,
      "loss": 0.001,
      "step": 2361
    },
    {
      "epoch": 40.724137931034484,
      "grad_norm": 0.020734524354338646,
      "learning_rate": 1.113103448275862e-05,
      "loss": 0.0011,
      "step": 2362
    },
    {
      "epoch": 40.741379310344826,
      "grad_norm": 0.01717287488281727,
      "learning_rate": 1.1110344827586207e-05,
      "loss": 0.0016,
      "step": 2363
    },
    {
      "epoch": 40.758620689655174,
      "grad_norm": 0.010033348575234413,
      "learning_rate": 1.1089655172413794e-05,
      "loss": 0.0008,
      "step": 2364
    },
    {
      "epoch": 40.775862068965516,
      "grad_norm": 0.026308447122573853,
      "learning_rate": 1.106896551724138e-05,
      "loss": 0.0016,
      "step": 2365
    },
    {
      "epoch": 40.793103448275865,
      "grad_norm": 0.017752543091773987,
      "learning_rate": 1.1048275862068965e-05,
      "loss": 0.0015,
      "step": 2366
    },
    {
      "epoch": 40.810344827586206,
      "grad_norm": 0.048361875116825104,
      "learning_rate": 1.1027586206896553e-05,
      "loss": 0.0016,
      "step": 2367
    },
    {
      "epoch": 40.827586206896555,
      "grad_norm": 0.018788961693644524,
      "learning_rate": 1.1006896551724138e-05,
      "loss": 0.0015,
      "step": 2368
    },
    {
      "epoch": 40.8448275862069,
      "grad_norm": 0.023862095549702644,
      "learning_rate": 1.0986206896551723e-05,
      "loss": 0.0013,
      "step": 2369
    },
    {
      "epoch": 40.86206896551724,
      "grad_norm": 0.026460040360689163,
      "learning_rate": 1.0965517241379311e-05,
      "loss": 0.0013,
      "step": 2370
    },
    {
      "epoch": 40.87931034482759,
      "grad_norm": 0.020207397639751434,
      "learning_rate": 1.0944827586206896e-05,
      "loss": 0.0014,
      "step": 2371
    },
    {
      "epoch": 40.89655172413793,
      "grad_norm": 0.015110158361494541,
      "learning_rate": 1.0924137931034484e-05,
      "loss": 0.0012,
      "step": 2372
    },
    {
      "epoch": 40.91379310344828,
      "grad_norm": 0.008922623470425606,
      "learning_rate": 1.0903448275862069e-05,
      "loss": 0.0008,
      "step": 2373
    },
    {
      "epoch": 40.93103448275862,
      "grad_norm": 0.014068719930946827,
      "learning_rate": 1.0882758620689656e-05,
      "loss": 0.0012,
      "step": 2374
    },
    {
      "epoch": 40.94827586206897,
      "grad_norm": 0.03948594629764557,
      "learning_rate": 1.0862068965517242e-05,
      "loss": 0.0012,
      "step": 2375
    },
    {
      "epoch": 40.96551724137931,
      "grad_norm": 0.013559658080339432,
      "learning_rate": 1.0841379310344827e-05,
      "loss": 0.001,
      "step": 2376
    },
    {
      "epoch": 40.98275862068966,
      "grad_norm": 0.01223253645002842,
      "learning_rate": 1.0820689655172415e-05,
      "loss": 0.0007,
      "step": 2377
    },
    {
      "epoch": 41.0,
      "grad_norm": 0.029880722984671593,
      "learning_rate": 1.08e-05,
      "loss": 0.0013,
      "step": 2378
    },
    {
      "epoch": 41.01724137931034,
      "grad_norm": 0.016941012814641,
      "learning_rate": 1.0779310344827586e-05,
      "loss": 0.001,
      "step": 2379
    },
    {
      "epoch": 41.03448275862069,
      "grad_norm": 0.024165362119674683,
      "learning_rate": 1.0758620689655173e-05,
      "loss": 0.0017,
      "step": 2380
    },
    {
      "epoch": 41.03448275862069,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001131700468249619,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.8916,
      "eval_samples_per_second": 2.663,
      "eval_steps_per_second": 1.377,
      "step": 2380
    },
    {
      "epoch": 41.05172413793103,
      "grad_norm": 0.0334351621568203,
      "learning_rate": 1.073793103448276e-05,
      "loss": 0.0013,
      "step": 2381
    },
    {
      "epoch": 41.06896551724138,
      "grad_norm": 0.029155118390917778,
      "learning_rate": 1.0717241379310346e-05,
      "loss": 0.0015,
      "step": 2382
    },
    {
      "epoch": 41.08620689655172,
      "grad_norm": 0.012802444398403168,
      "learning_rate": 1.0696551724137931e-05,
      "loss": 0.0012,
      "step": 2383
    },
    {
      "epoch": 41.10344827586207,
      "grad_norm": 0.017882036045193672,
      "learning_rate": 1.0675862068965517e-05,
      "loss": 0.0007,
      "step": 2384
    },
    {
      "epoch": 41.12068965517241,
      "grad_norm": 0.022874046117067337,
      "learning_rate": 1.0655172413793104e-05,
      "loss": 0.0012,
      "step": 2385
    },
    {
      "epoch": 41.13793103448276,
      "grad_norm": 0.013430150225758553,
      "learning_rate": 1.063448275862069e-05,
      "loss": 0.0011,
      "step": 2386
    },
    {
      "epoch": 41.1551724137931,
      "grad_norm": 0.030891887843608856,
      "learning_rate": 1.0613793103448275e-05,
      "loss": 0.0013,
      "step": 2387
    },
    {
      "epoch": 41.172413793103445,
      "grad_norm": 0.03427508473396301,
      "learning_rate": 1.0593103448275862e-05,
      "loss": 0.002,
      "step": 2388
    },
    {
      "epoch": 41.189655172413794,
      "grad_norm": 0.016671227291226387,
      "learning_rate": 1.0572413793103448e-05,
      "loss": 0.0007,
      "step": 2389
    },
    {
      "epoch": 41.206896551724135,
      "grad_norm": 0.015127066522836685,
      "learning_rate": 1.0551724137931035e-05,
      "loss": 0.0013,
      "step": 2390
    },
    {
      "epoch": 41.224137931034484,
      "grad_norm": 0.03668701648712158,
      "learning_rate": 1.0531034482758621e-05,
      "loss": 0.0011,
      "step": 2391
    },
    {
      "epoch": 41.241379310344826,
      "grad_norm": 0.02270500175654888,
      "learning_rate": 1.0510344827586206e-05,
      "loss": 0.001,
      "step": 2392
    },
    {
      "epoch": 41.258620689655174,
      "grad_norm": 0.022516552358865738,
      "learning_rate": 1.0489655172413794e-05,
      "loss": 0.0015,
      "step": 2393
    },
    {
      "epoch": 41.275862068965516,
      "grad_norm": 0.02031910978257656,
      "learning_rate": 1.046896551724138e-05,
      "loss": 0.0013,
      "step": 2394
    },
    {
      "epoch": 41.293103448275865,
      "grad_norm": 0.012788510881364346,
      "learning_rate": 1.0448275862068966e-05,
      "loss": 0.0011,
      "step": 2395
    },
    {
      "epoch": 41.310344827586206,
      "grad_norm": 0.013813499361276627,
      "learning_rate": 1.0427586206896552e-05,
      "loss": 0.0013,
      "step": 2396
    },
    {
      "epoch": 41.327586206896555,
      "grad_norm": 0.020283542573451996,
      "learning_rate": 1.0406896551724137e-05,
      "loss": 0.0015,
      "step": 2397
    },
    {
      "epoch": 41.3448275862069,
      "grad_norm": 0.02578747831285,
      "learning_rate": 1.0386206896551725e-05,
      "loss": 0.0014,
      "step": 2398
    },
    {
      "epoch": 41.36206896551724,
      "grad_norm": 0.015974417328834534,
      "learning_rate": 1.036551724137931e-05,
      "loss": 0.0014,
      "step": 2399
    },
    {
      "epoch": 41.37931034482759,
      "grad_norm": 0.01902732439339161,
      "learning_rate": 1.0344827586206898e-05,
      "loss": 0.0014,
      "step": 2400
    },
    {
      "epoch": 41.37931034482759,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0012140813050791621,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.2911,
      "eval_samples_per_second": 2.818,
      "eval_steps_per_second": 1.458,
      "step": 2400
    },
    {
      "epoch": 41.39655172413793,
      "grad_norm": 0.014891702681779861,
      "learning_rate": 1.0324137931034483e-05,
      "loss": 0.0012,
      "step": 2401
    },
    {
      "epoch": 41.41379310344828,
      "grad_norm": 0.009821251966059208,
      "learning_rate": 1.0303448275862068e-05,
      "loss": 0.0008,
      "step": 2402
    },
    {
      "epoch": 41.43103448275862,
      "grad_norm": 0.033992212265729904,
      "learning_rate": 1.0282758620689656e-05,
      "loss": 0.002,
      "step": 2403
    },
    {
      "epoch": 41.44827586206897,
      "grad_norm": 0.04379647597670555,
      "learning_rate": 1.0262068965517241e-05,
      "loss": 0.0013,
      "step": 2404
    },
    {
      "epoch": 41.46551724137931,
      "grad_norm": 0.03283561393618584,
      "learning_rate": 1.0241379310344828e-05,
      "loss": 0.0016,
      "step": 2405
    },
    {
      "epoch": 41.48275862068966,
      "grad_norm": 0.013914021663367748,
      "learning_rate": 1.0220689655172414e-05,
      "loss": 0.0011,
      "step": 2406
    },
    {
      "epoch": 41.5,
      "grad_norm": 0.012669979594647884,
      "learning_rate": 1.02e-05,
      "loss": 0.0007,
      "step": 2407
    },
    {
      "epoch": 41.51724137931034,
      "grad_norm": 0.009896996431052685,
      "learning_rate": 1.0179310344827587e-05,
      "loss": 0.0009,
      "step": 2408
    },
    {
      "epoch": 41.53448275862069,
      "grad_norm": 0.018069040030241013,
      "learning_rate": 1.0158620689655172e-05,
      "loss": 0.001,
      "step": 2409
    },
    {
      "epoch": 41.55172413793103,
      "grad_norm": 0.01580766588449478,
      "learning_rate": 1.0137931034482758e-05,
      "loss": 0.0012,
      "step": 2410
    },
    {
      "epoch": 41.56896551724138,
      "grad_norm": 0.016935432329773903,
      "learning_rate": 1.0117241379310345e-05,
      "loss": 0.0011,
      "step": 2411
    },
    {
      "epoch": 41.58620689655172,
      "grad_norm": 0.01472023781388998,
      "learning_rate": 1.0096551724137932e-05,
      "loss": 0.0012,
      "step": 2412
    },
    {
      "epoch": 41.60344827586207,
      "grad_norm": 0.016490083187818527,
      "learning_rate": 1.0075862068965518e-05,
      "loss": 0.0014,
      "step": 2413
    },
    {
      "epoch": 41.62068965517241,
      "grad_norm": 0.012118223123252392,
      "learning_rate": 1.0055172413793105e-05,
      "loss": 0.001,
      "step": 2414
    },
    {
      "epoch": 41.63793103448276,
      "grad_norm": 0.017493927851319313,
      "learning_rate": 1.003448275862069e-05,
      "loss": 0.0009,
      "step": 2415
    },
    {
      "epoch": 41.6551724137931,
      "grad_norm": 0.018450602889060974,
      "learning_rate": 1.0013793103448276e-05,
      "loss": 0.0017,
      "step": 2416
    },
    {
      "epoch": 41.672413793103445,
      "grad_norm": 0.010620638728141785,
      "learning_rate": 9.993103448275862e-06,
      "loss": 0.0009,
      "step": 2417
    },
    {
      "epoch": 41.689655172413794,
      "grad_norm": 0.015281335450708866,
      "learning_rate": 9.972413793103449e-06,
      "loss": 0.0009,
      "step": 2418
    },
    {
      "epoch": 41.706896551724135,
      "grad_norm": 0.011823184788227081,
      "learning_rate": 9.951724137931035e-06,
      "loss": 0.0008,
      "step": 2419
    },
    {
      "epoch": 41.724137931034484,
      "grad_norm": 0.012146104127168655,
      "learning_rate": 9.93103448275862e-06,
      "loss": 0.001,
      "step": 2420
    },
    {
      "epoch": 41.724137931034484,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010234150104224682,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.1131,
      "eval_samples_per_second": 2.868,
      "eval_steps_per_second": 1.483,
      "step": 2420
    },
    {
      "epoch": 41.741379310344826,
      "grad_norm": 0.023257901892066002,
      "learning_rate": 9.910344827586209e-06,
      "loss": 0.001,
      "step": 2421
    },
    {
      "epoch": 41.758620689655174,
      "grad_norm": 0.011952235363423824,
      "learning_rate": 9.889655172413793e-06,
      "loss": 0.0011,
      "step": 2422
    },
    {
      "epoch": 41.775862068965516,
      "grad_norm": 0.02097274549305439,
      "learning_rate": 9.868965517241378e-06,
      "loss": 0.0018,
      "step": 2423
    },
    {
      "epoch": 41.793103448275865,
      "grad_norm": 0.015601377934217453,
      "learning_rate": 9.848275862068966e-06,
      "loss": 0.0015,
      "step": 2424
    },
    {
      "epoch": 41.810344827586206,
      "grad_norm": 0.014772315509617329,
      "learning_rate": 9.827586206896551e-06,
      "loss": 0.0014,
      "step": 2425
    },
    {
      "epoch": 41.827586206896555,
      "grad_norm": 0.018763741478323936,
      "learning_rate": 9.80689655172414e-06,
      "loss": 0.0013,
      "step": 2426
    },
    {
      "epoch": 41.8448275862069,
      "grad_norm": 0.027206314727663994,
      "learning_rate": 9.786206896551724e-06,
      "loss": 0.0015,
      "step": 2427
    },
    {
      "epoch": 41.86206896551724,
      "grad_norm": 0.010881125926971436,
      "learning_rate": 9.765517241379309e-06,
      "loss": 0.0007,
      "step": 2428
    },
    {
      "epoch": 41.87931034482759,
      "grad_norm": 0.017439058050513268,
      "learning_rate": 9.744827586206897e-06,
      "loss": 0.0011,
      "step": 2429
    },
    {
      "epoch": 41.89655172413793,
      "grad_norm": 0.014725295826792717,
      "learning_rate": 9.724137931034482e-06,
      "loss": 0.0014,
      "step": 2430
    },
    {
      "epoch": 41.91379310344828,
      "grad_norm": 0.004665122367441654,
      "learning_rate": 9.70344827586207e-06,
      "loss": 0.0003,
      "step": 2431
    },
    {
      "epoch": 41.93103448275862,
      "grad_norm": 0.039041705429553986,
      "learning_rate": 9.682758620689655e-06,
      "loss": 0.0013,
      "step": 2432
    },
    {
      "epoch": 41.94827586206897,
      "grad_norm": 0.04002949967980385,
      "learning_rate": 9.662068965517242e-06,
      "loss": 0.0018,
      "step": 2433
    },
    {
      "epoch": 41.96551724137931,
      "grad_norm": 0.017659703269600868,
      "learning_rate": 9.641379310344828e-06,
      "loss": 0.0011,
      "step": 2434
    },
    {
      "epoch": 41.98275862068966,
      "grad_norm": 0.01696072146296501,
      "learning_rate": 9.620689655172413e-06,
      "loss": 0.0013,
      "step": 2435
    },
    {
      "epoch": 42.0,
      "grad_norm": 0.030949098989367485,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.0015,
      "step": 2436
    },
    {
      "epoch": 42.01724137931034,
      "grad_norm": 0.028458118438720703,
      "learning_rate": 9.579310344827586e-06,
      "loss": 0.0016,
      "step": 2437
    },
    {
      "epoch": 42.03448275862069,
      "grad_norm": 0.010077303275465965,
      "learning_rate": 9.558620689655173e-06,
      "loss": 0.001,
      "step": 2438
    },
    {
      "epoch": 42.05172413793103,
      "grad_norm": 0.00951367523521185,
      "learning_rate": 9.537931034482759e-06,
      "loss": 0.0009,
      "step": 2439
    },
    {
      "epoch": 42.06896551724138,
      "grad_norm": 0.021313389763236046,
      "learning_rate": 9.517241379310346e-06,
      "loss": 0.0015,
      "step": 2440
    },
    {
      "epoch": 42.06896551724138,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0011022097896784544,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.5601,
      "eval_samples_per_second": 3.033,
      "eval_steps_per_second": 1.569,
      "step": 2440
    },
    {
      "epoch": 42.08620689655172,
      "grad_norm": 0.01154314074665308,
      "learning_rate": 9.49655172413793e-06,
      "loss": 0.0011,
      "step": 2441
    },
    {
      "epoch": 42.10344827586207,
      "grad_norm": 0.026014233008027077,
      "learning_rate": 9.475862068965517e-06,
      "loss": 0.0014,
      "step": 2442
    },
    {
      "epoch": 42.12068965517241,
      "grad_norm": 0.011683314107358456,
      "learning_rate": 9.455172413793104e-06,
      "loss": 0.0009,
      "step": 2443
    },
    {
      "epoch": 42.13793103448276,
      "grad_norm": 0.022836048156023026,
      "learning_rate": 9.43448275862069e-06,
      "loss": 0.0012,
      "step": 2444
    },
    {
      "epoch": 42.1551724137931,
      "grad_norm": 0.010580840520560741,
      "learning_rate": 9.413793103448277e-06,
      "loss": 0.001,
      "step": 2445
    },
    {
      "epoch": 42.172413793103445,
      "grad_norm": 0.012193833477795124,
      "learning_rate": 9.393103448275861e-06,
      "loss": 0.0011,
      "step": 2446
    },
    {
      "epoch": 42.189655172413794,
      "grad_norm": 0.011360234580934048,
      "learning_rate": 9.37241379310345e-06,
      "loss": 0.0009,
      "step": 2447
    },
    {
      "epoch": 42.206896551724135,
      "grad_norm": 0.023046376183629036,
      "learning_rate": 9.351724137931034e-06,
      "loss": 0.0016,
      "step": 2448
    },
    {
      "epoch": 42.224137931034484,
      "grad_norm": 0.04589926823973656,
      "learning_rate": 9.331034482758621e-06,
      "loss": 0.0012,
      "step": 2449
    },
    {
      "epoch": 42.241379310344826,
      "grad_norm": 0.01128745824098587,
      "learning_rate": 9.310344827586207e-06,
      "loss": 0.0006,
      "step": 2450
    },
    {
      "epoch": 42.258620689655174,
      "grad_norm": 0.01302239578217268,
      "learning_rate": 9.289655172413792e-06,
      "loss": 0.0012,
      "step": 2451
    },
    {
      "epoch": 42.275862068965516,
      "grad_norm": 0.014373456127941608,
      "learning_rate": 9.26896551724138e-06,
      "loss": 0.001,
      "step": 2452
    },
    {
      "epoch": 42.293103448275865,
      "grad_norm": 0.012599561363458633,
      "learning_rate": 9.248275862068965e-06,
      "loss": 0.001,
      "step": 2453
    },
    {
      "epoch": 42.310344827586206,
      "grad_norm": 0.01340905949473381,
      "learning_rate": 9.227586206896554e-06,
      "loss": 0.001,
      "step": 2454
    },
    {
      "epoch": 42.327586206896555,
      "grad_norm": 0.013665677048265934,
      "learning_rate": 9.206896551724138e-06,
      "loss": 0.0011,
      "step": 2455
    },
    {
      "epoch": 42.3448275862069,
      "grad_norm": 0.01782718487083912,
      "learning_rate": 9.186206896551723e-06,
      "loss": 0.0015,
      "step": 2456
    },
    {
      "epoch": 42.36206896551724,
      "grad_norm": 0.022406671196222305,
      "learning_rate": 9.165517241379311e-06,
      "loss": 0.001,
      "step": 2457
    },
    {
      "epoch": 42.37931034482759,
      "grad_norm": 0.02384784072637558,
      "learning_rate": 9.144827586206896e-06,
      "loss": 0.0008,
      "step": 2458
    },
    {
      "epoch": 42.39655172413793,
      "grad_norm": 0.020534643903374672,
      "learning_rate": 9.124137931034483e-06,
      "loss": 0.0019,
      "step": 2459
    },
    {
      "epoch": 42.41379310344828,
      "grad_norm": 0.012934105470776558,
      "learning_rate": 9.10344827586207e-06,
      "loss": 0.0007,
      "step": 2460
    },
    {
      "epoch": 42.41379310344828,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010235474910587072,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.0009,
      "eval_samples_per_second": 2.416,
      "eval_steps_per_second": 1.25,
      "step": 2460
    },
    {
      "epoch": 42.43103448275862,
      "grad_norm": 0.015270005911588669,
      "learning_rate": 9.082758620689656e-06,
      "loss": 0.0012,
      "step": 2461
    },
    {
      "epoch": 42.44827586206897,
      "grad_norm": 0.021286096423864365,
      "learning_rate": 9.062068965517242e-06,
      "loss": 0.0017,
      "step": 2462
    },
    {
      "epoch": 42.46551724137931,
      "grad_norm": 0.017697812989354134,
      "learning_rate": 9.041379310344827e-06,
      "loss": 0.0016,
      "step": 2463
    },
    {
      "epoch": 42.48275862068966,
      "grad_norm": 0.0156997237354517,
      "learning_rate": 9.020689655172414e-06,
      "loss": 0.0015,
      "step": 2464
    },
    {
      "epoch": 42.5,
      "grad_norm": 0.020857980474829674,
      "learning_rate": 9e-06,
      "loss": 0.0014,
      "step": 2465
    },
    {
      "epoch": 42.51724137931034,
      "grad_norm": 0.010432873852550983,
      "learning_rate": 8.979310344827587e-06,
      "loss": 0.0008,
      "step": 2466
    },
    {
      "epoch": 42.53448275862069,
      "grad_norm": 0.019156599417328835,
      "learning_rate": 8.958620689655173e-06,
      "loss": 0.001,
      "step": 2467
    },
    {
      "epoch": 42.55172413793103,
      "grad_norm": 0.026960181072354317,
      "learning_rate": 8.937931034482758e-06,
      "loss": 0.0016,
      "step": 2468
    },
    {
      "epoch": 42.56896551724138,
      "grad_norm": 0.01773618720471859,
      "learning_rate": 8.917241379310345e-06,
      "loss": 0.0008,
      "step": 2469
    },
    {
      "epoch": 42.58620689655172,
      "grad_norm": 0.014098314568400383,
      "learning_rate": 8.896551724137931e-06,
      "loss": 0.0013,
      "step": 2470
    },
    {
      "epoch": 42.60344827586207,
      "grad_norm": 0.03619956225156784,
      "learning_rate": 8.875862068965518e-06,
      "loss": 0.0011,
      "step": 2471
    },
    {
      "epoch": 42.62068965517241,
      "grad_norm": 0.015534200705587864,
      "learning_rate": 8.855172413793104e-06,
      "loss": 0.0012,
      "step": 2472
    },
    {
      "epoch": 42.63793103448276,
      "grad_norm": 0.017959188669919968,
      "learning_rate": 8.83448275862069e-06,
      "loss": 0.0013,
      "step": 2473
    },
    {
      "epoch": 42.6551724137931,
      "grad_norm": 0.013670934364199638,
      "learning_rate": 8.813793103448276e-06,
      "loss": 0.0008,
      "step": 2474
    },
    {
      "epoch": 42.672413793103445,
      "grad_norm": 0.01469118520617485,
      "learning_rate": 8.793103448275862e-06,
      "loss": 0.0011,
      "step": 2475
    },
    {
      "epoch": 42.689655172413794,
      "grad_norm": 0.010121462866663933,
      "learning_rate": 8.772413793103449e-06,
      "loss": 0.0007,
      "step": 2476
    },
    {
      "epoch": 42.706896551724135,
      "grad_norm": 0.029848376289010048,
      "learning_rate": 8.751724137931033e-06,
      "loss": 0.0009,
      "step": 2477
    },
    {
      "epoch": 42.724137931034484,
      "grad_norm": 0.012880944646894932,
      "learning_rate": 8.731034482758622e-06,
      "loss": 0.0012,
      "step": 2478
    },
    {
      "epoch": 42.741379310344826,
      "grad_norm": 0.029387308284640312,
      "learning_rate": 8.710344827586206e-06,
      "loss": 0.0013,
      "step": 2479
    },
    {
      "epoch": 42.758620689655174,
      "grad_norm": 0.019111303612589836,
      "learning_rate": 8.689655172413795e-06,
      "loss": 0.0014,
      "step": 2480
    },
    {
      "epoch": 42.758620689655174,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010891746496781707,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.7181,
      "eval_samples_per_second": 2.706,
      "eval_steps_per_second": 1.4,
      "step": 2480
    },
    {
      "epoch": 42.775862068965516,
      "grad_norm": 0.019182603806257248,
      "learning_rate": 8.66896551724138e-06,
      "loss": 0.0008,
      "step": 2481
    },
    {
      "epoch": 42.793103448275865,
      "grad_norm": 0.026047004386782646,
      "learning_rate": 8.648275862068964e-06,
      "loss": 0.0014,
      "step": 2482
    },
    {
      "epoch": 42.810344827586206,
      "grad_norm": 0.01927054114639759,
      "learning_rate": 8.627586206896553e-06,
      "loss": 0.0018,
      "step": 2483
    },
    {
      "epoch": 42.827586206896555,
      "grad_norm": 0.008841722272336483,
      "learning_rate": 8.606896551724137e-06,
      "loss": 0.0006,
      "step": 2484
    },
    {
      "epoch": 42.8448275862069,
      "grad_norm": 0.01458203885704279,
      "learning_rate": 8.586206896551726e-06,
      "loss": 0.0013,
      "step": 2485
    },
    {
      "epoch": 42.86206896551724,
      "grad_norm": 0.015098110772669315,
      "learning_rate": 8.56551724137931e-06,
      "loss": 0.0014,
      "step": 2486
    },
    {
      "epoch": 42.87931034482759,
      "grad_norm": 0.026096472516655922,
      "learning_rate": 8.544827586206897e-06,
      "loss": 0.0014,
      "step": 2487
    },
    {
      "epoch": 42.89655172413793,
      "grad_norm": 0.00970320776104927,
      "learning_rate": 8.524137931034483e-06,
      "loss": 0.0008,
      "step": 2488
    },
    {
      "epoch": 42.91379310344828,
      "grad_norm": 0.012354167178273201,
      "learning_rate": 8.503448275862068e-06,
      "loss": 0.0011,
      "step": 2489
    },
    {
      "epoch": 42.93103448275862,
      "grad_norm": 0.021795544773340225,
      "learning_rate": 8.482758620689656e-06,
      "loss": 0.0009,
      "step": 2490
    },
    {
      "epoch": 42.94827586206897,
      "grad_norm": 0.02292311191558838,
      "learning_rate": 8.462068965517241e-06,
      "loss": 0.0016,
      "step": 2491
    },
    {
      "epoch": 42.96551724137931,
      "grad_norm": 0.016391314566135406,
      "learning_rate": 8.441379310344828e-06,
      "loss": 0.0014,
      "step": 2492
    },
    {
      "epoch": 42.98275862068966,
      "grad_norm": 0.014006884768605232,
      "learning_rate": 8.420689655172414e-06,
      "loss": 0.0013,
      "step": 2493
    },
    {
      "epoch": 43.0,
      "grad_norm": 0.017161834985017776,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.0008,
      "step": 2494
    },
    {
      "epoch": 43.01724137931034,
      "grad_norm": 0.017097679898142815,
      "learning_rate": 8.379310344827586e-06,
      "loss": 0.001,
      "step": 2495
    },
    {
      "epoch": 43.03448275862069,
      "grad_norm": 0.07784479111433029,
      "learning_rate": 8.358620689655172e-06,
      "loss": 0.0017,
      "step": 2496
    },
    {
      "epoch": 43.05172413793103,
      "grad_norm": 0.014605477452278137,
      "learning_rate": 8.337931034482759e-06,
      "loss": 0.0012,
      "step": 2497
    },
    {
      "epoch": 43.06896551724138,
      "grad_norm": 0.016634611412882805,
      "learning_rate": 8.317241379310345e-06,
      "loss": 0.0014,
      "step": 2498
    },
    {
      "epoch": 43.08620689655172,
      "grad_norm": 0.012494157068431377,
      "learning_rate": 8.296551724137932e-06,
      "loss": 0.0008,
      "step": 2499
    },
    {
      "epoch": 43.10344827586207,
      "grad_norm": 0.012797243893146515,
      "learning_rate": 8.275862068965517e-06,
      "loss": 0.0009,
      "step": 2500
    },
    {
      "epoch": 43.10344827586207,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001108831726014614,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.7975,
      "eval_samples_per_second": 3.296,
      "eval_steps_per_second": 1.705,
      "step": 2500
    },
    {
      "epoch": 43.12068965517241,
      "grad_norm": 0.04162373021245003,
      "learning_rate": 8.255172413793103e-06,
      "loss": 0.0014,
      "step": 2501
    },
    {
      "epoch": 43.13793103448276,
      "grad_norm": 0.09896302223205566,
      "learning_rate": 8.23448275862069e-06,
      "loss": 0.0038,
      "step": 2502
    },
    {
      "epoch": 43.1551724137931,
      "grad_norm": 0.014118839055299759,
      "learning_rate": 8.213793103448276e-06,
      "loss": 0.0009,
      "step": 2503
    },
    {
      "epoch": 43.172413793103445,
      "grad_norm": 0.0211008433252573,
      "learning_rate": 8.193103448275863e-06,
      "loss": 0.0019,
      "step": 2504
    },
    {
      "epoch": 43.189655172413794,
      "grad_norm": 0.029005782678723335,
      "learning_rate": 8.172413793103448e-06,
      "loss": 0.0012,
      "step": 2505
    },
    {
      "epoch": 43.206896551724135,
      "grad_norm": 0.014408297836780548,
      "learning_rate": 8.151724137931036e-06,
      "loss": 0.001,
      "step": 2506
    },
    {
      "epoch": 43.224137931034484,
      "grad_norm": 0.025589875876903534,
      "learning_rate": 8.13103448275862e-06,
      "loss": 0.0011,
      "step": 2507
    },
    {
      "epoch": 43.241379310344826,
      "grad_norm": 0.014127038419246674,
      "learning_rate": 8.110344827586207e-06,
      "loss": 0.0009,
      "step": 2508
    },
    {
      "epoch": 43.258620689655174,
      "grad_norm": 0.017610616981983185,
      "learning_rate": 8.089655172413794e-06,
      "loss": 0.0007,
      "step": 2509
    },
    {
      "epoch": 43.275862068965516,
      "grad_norm": 0.010811706073582172,
      "learning_rate": 8.068965517241378e-06,
      "loss": 0.0009,
      "step": 2510
    },
    {
      "epoch": 43.293103448275865,
      "grad_norm": 0.03251626342535019,
      "learning_rate": 8.048275862068967e-06,
      "loss": 0.0013,
      "step": 2511
    },
    {
      "epoch": 43.310344827586206,
      "grad_norm": 0.01895064115524292,
      "learning_rate": 8.027586206896552e-06,
      "loss": 0.001,
      "step": 2512
    },
    {
      "epoch": 43.327586206896555,
      "grad_norm": 0.04186628758907318,
      "learning_rate": 8.006896551724138e-06,
      "loss": 0.0017,
      "step": 2513
    },
    {
      "epoch": 43.3448275862069,
      "grad_norm": 0.015023300424218178,
      "learning_rate": 7.986206896551725e-06,
      "loss": 0.0008,
      "step": 2514
    },
    {
      "epoch": 43.36206896551724,
      "grad_norm": 0.021005360409617424,
      "learning_rate": 7.96551724137931e-06,
      "loss": 0.0011,
      "step": 2515
    },
    {
      "epoch": 43.37931034482759,
      "grad_norm": 0.012711480259895325,
      "learning_rate": 7.944827586206898e-06,
      "loss": 0.001,
      "step": 2516
    },
    {
      "epoch": 43.39655172413793,
      "grad_norm": 0.014980277046561241,
      "learning_rate": 7.924137931034482e-06,
      "loss": 0.0014,
      "step": 2517
    },
    {
      "epoch": 43.41379310344828,
      "grad_norm": 0.014821678400039673,
      "learning_rate": 7.903448275862069e-06,
      "loss": 0.0014,
      "step": 2518
    },
    {
      "epoch": 43.43103448275862,
      "grad_norm": 0.016853902488946915,
      "learning_rate": 7.882758620689655e-06,
      "loss": 0.0016,
      "step": 2519
    },
    {
      "epoch": 43.44827586206897,
      "grad_norm": 0.012070556171238422,
      "learning_rate": 7.862068965517242e-06,
      "loss": 0.001,
      "step": 2520
    },
    {
      "epoch": 43.44827586206897,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001149981515482068,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.4068,
      "eval_samples_per_second": 2.542,
      "eval_steps_per_second": 1.315,
      "step": 2520
    },
    {
      "epoch": 43.46551724137931,
      "grad_norm": 0.008214781060814857,
      "learning_rate": 7.841379310344829e-06,
      "loss": 0.0006,
      "step": 2521
    },
    {
      "epoch": 43.48275862068966,
      "grad_norm": 0.10509971529245377,
      "learning_rate": 7.820689655172413e-06,
      "loss": 0.0039,
      "step": 2522
    },
    {
      "epoch": 43.5,
      "grad_norm": 0.01615952141582966,
      "learning_rate": 7.8e-06,
      "loss": 0.0007,
      "step": 2523
    },
    {
      "epoch": 43.51724137931034,
      "grad_norm": 0.012449911795556545,
      "learning_rate": 7.779310344827586e-06,
      "loss": 0.0011,
      "step": 2524
    },
    {
      "epoch": 43.53448275862069,
      "grad_norm": 0.017145231366157532,
      "learning_rate": 7.758620689655173e-06,
      "loss": 0.0013,
      "step": 2525
    },
    {
      "epoch": 43.55172413793103,
      "grad_norm": 0.005749168805778027,
      "learning_rate": 7.73793103448276e-06,
      "loss": 0.0005,
      "step": 2526
    },
    {
      "epoch": 43.56896551724138,
      "grad_norm": 0.012169323861598969,
      "learning_rate": 7.717241379310346e-06,
      "loss": 0.0009,
      "step": 2527
    },
    {
      "epoch": 43.58620689655172,
      "grad_norm": 0.030396031215786934,
      "learning_rate": 7.69655172413793e-06,
      "loss": 0.0016,
      "step": 2528
    },
    {
      "epoch": 43.60344827586207,
      "grad_norm": 0.016364023089408875,
      "learning_rate": 7.675862068965517e-06,
      "loss": 0.0012,
      "step": 2529
    },
    {
      "epoch": 43.62068965517241,
      "grad_norm": 0.006542888469994068,
      "learning_rate": 7.655172413793104e-06,
      "loss": 0.0005,
      "step": 2530
    },
    {
      "epoch": 43.63793103448276,
      "grad_norm": 0.019549565389752388,
      "learning_rate": 7.634482758620689e-06,
      "loss": 0.0009,
      "step": 2531
    },
    {
      "epoch": 43.6551724137931,
      "grad_norm": 0.026726718991994858,
      "learning_rate": 7.613793103448277e-06,
      "loss": 0.0011,
      "step": 2532
    },
    {
      "epoch": 43.672413793103445,
      "grad_norm": 0.01476714015007019,
      "learning_rate": 7.5931034482758625e-06,
      "loss": 0.0013,
      "step": 2533
    },
    {
      "epoch": 43.689655172413794,
      "grad_norm": 0.01949077658355236,
      "learning_rate": 7.572413793103449e-06,
      "loss": 0.0014,
      "step": 2534
    },
    {
      "epoch": 43.706896551724135,
      "grad_norm": 0.04113928601145744,
      "learning_rate": 7.551724137931035e-06,
      "loss": 0.0013,
      "step": 2535
    },
    {
      "epoch": 43.724137931034484,
      "grad_norm": 0.024216072633862495,
      "learning_rate": 7.53103448275862e-06,
      "loss": 0.0012,
      "step": 2536
    },
    {
      "epoch": 43.741379310344826,
      "grad_norm": 0.012720849364995956,
      "learning_rate": 7.510344827586208e-06,
      "loss": 0.0008,
      "step": 2537
    },
    {
      "epoch": 43.758620689655174,
      "grad_norm": 0.04433736205101013,
      "learning_rate": 7.489655172413793e-06,
      "loss": 0.0017,
      "step": 2538
    },
    {
      "epoch": 43.775862068965516,
      "grad_norm": 0.013365731574594975,
      "learning_rate": 7.468965517241379e-06,
      "loss": 0.0012,
      "step": 2539
    },
    {
      "epoch": 43.793103448275865,
      "grad_norm": 0.017408577725291252,
      "learning_rate": 7.448275862068966e-06,
      "loss": 0.0016,
      "step": 2540
    },
    {
      "epoch": 43.793103448275865,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.001125230686739087,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.5438,
      "eval_samples_per_second": 2.75,
      "eval_steps_per_second": 1.423,
      "step": 2540
    },
    {
      "epoch": 43.810344827586206,
      "grad_norm": 0.01147378608584404,
      "learning_rate": 7.427586206896552e-06,
      "loss": 0.001,
      "step": 2541
    },
    {
      "epoch": 43.827586206896555,
      "grad_norm": 0.014873752370476723,
      "learning_rate": 7.406896551724138e-06,
      "loss": 0.0011,
      "step": 2542
    },
    {
      "epoch": 43.8448275862069,
      "grad_norm": 0.01346462219953537,
      "learning_rate": 7.386206896551724e-06,
      "loss": 0.001,
      "step": 2543
    },
    {
      "epoch": 43.86206896551724,
      "grad_norm": 0.010946310125291348,
      "learning_rate": 7.365517241379311e-06,
      "loss": 0.0008,
      "step": 2544
    },
    {
      "epoch": 43.87931034482759,
      "grad_norm": 0.017261583358049393,
      "learning_rate": 7.3448275862068966e-06,
      "loss": 0.0014,
      "step": 2545
    },
    {
      "epoch": 43.89655172413793,
      "grad_norm": 0.014128356240689754,
      "learning_rate": 7.324137931034483e-06,
      "loss": 0.0011,
      "step": 2546
    },
    {
      "epoch": 43.91379310344828,
      "grad_norm": 0.05649890750646591,
      "learning_rate": 7.303448275862069e-06,
      "loss": 0.0017,
      "step": 2547
    },
    {
      "epoch": 43.93103448275862,
      "grad_norm": 0.021821245551109314,
      "learning_rate": 7.282758620689655e-06,
      "loss": 0.0015,
      "step": 2548
    },
    {
      "epoch": 43.94827586206897,
      "grad_norm": 0.011436289176344872,
      "learning_rate": 7.262068965517242e-06,
      "loss": 0.0011,
      "step": 2549
    },
    {
      "epoch": 43.96551724137931,
      "grad_norm": 0.011853383854031563,
      "learning_rate": 7.241379310344828e-06,
      "loss": 0.001,
      "step": 2550
    },
    {
      "epoch": 43.98275862068966,
      "grad_norm": 0.040771484375,
      "learning_rate": 7.220689655172414e-06,
      "loss": 0.0018,
      "step": 2551
    },
    {
      "epoch": 44.0,
      "grad_norm": 0.013045971281826496,
      "learning_rate": 7.2e-06,
      "loss": 0.0012,
      "step": 2552
    },
    {
      "epoch": 44.01724137931034,
      "grad_norm": 0.031491201370954514,
      "learning_rate": 7.179310344827586e-06,
      "loss": 0.0011,
      "step": 2553
    },
    {
      "epoch": 44.03448275862069,
      "grad_norm": 0.016850290820002556,
      "learning_rate": 7.158620689655173e-06,
      "loss": 0.0015,
      "step": 2554
    },
    {
      "epoch": 44.05172413793103,
      "grad_norm": 0.021613335236907005,
      "learning_rate": 7.137931034482759e-06,
      "loss": 0.0013,
      "step": 2555
    },
    {
      "epoch": 44.06896551724138,
      "grad_norm": 0.005670681595802307,
      "learning_rate": 7.117241379310345e-06,
      "loss": 0.0004,
      "step": 2556
    },
    {
      "epoch": 44.08620689655172,
      "grad_norm": 0.012075059115886688,
      "learning_rate": 7.0965517241379314e-06,
      "loss": 0.0009,
      "step": 2557
    },
    {
      "epoch": 44.10344827586207,
      "grad_norm": 0.018046582117676735,
      "learning_rate": 7.075862068965517e-06,
      "loss": 0.0011,
      "step": 2558
    },
    {
      "epoch": 44.12068965517241,
      "grad_norm": 0.014100325293838978,
      "learning_rate": 7.055172413793104e-06,
      "loss": 0.0012,
      "step": 2559
    },
    {
      "epoch": 44.13793103448276,
      "grad_norm": 0.03184304013848305,
      "learning_rate": 7.03448275862069e-06,
      "loss": 0.0013,
      "step": 2560
    },
    {
      "epoch": 44.13793103448276,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0011064558057114482,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.1233,
      "eval_samples_per_second": 2.865,
      "eval_steps_per_second": 1.482,
      "step": 2560
    },
    {
      "epoch": 44.1551724137931,
      "grad_norm": 0.02206406183540821,
      "learning_rate": 7.013793103448276e-06,
      "loss": 0.0012,
      "step": 2561
    },
    {
      "epoch": 44.172413793103445,
      "grad_norm": 0.013632616028189659,
      "learning_rate": 6.993103448275862e-06,
      "loss": 0.0013,
      "step": 2562
    },
    {
      "epoch": 44.189655172413794,
      "grad_norm": 0.0185608621686697,
      "learning_rate": 6.972413793103449e-06,
      "loss": 0.0014,
      "step": 2563
    },
    {
      "epoch": 44.206896551724135,
      "grad_norm": 0.03733573108911514,
      "learning_rate": 6.951724137931035e-06,
      "loss": 0.001,
      "step": 2564
    },
    {
      "epoch": 44.224137931034484,
      "grad_norm": 0.05581073462963104,
      "learning_rate": 6.93103448275862e-06,
      "loss": 0.0015,
      "step": 2565
    },
    {
      "epoch": 44.241379310344826,
      "grad_norm": 0.020335868000984192,
      "learning_rate": 6.910344827586207e-06,
      "loss": 0.0016,
      "step": 2566
    },
    {
      "epoch": 44.258620689655174,
      "grad_norm": 0.01096285693347454,
      "learning_rate": 6.889655172413793e-06,
      "loss": 0.0009,
      "step": 2567
    },
    {
      "epoch": 44.275862068965516,
      "grad_norm": 0.013365436345338821,
      "learning_rate": 6.86896551724138e-06,
      "loss": 0.001,
      "step": 2568
    },
    {
      "epoch": 44.293103448275865,
      "grad_norm": 0.009857443161308765,
      "learning_rate": 6.848275862068966e-06,
      "loss": 0.0009,
      "step": 2569
    },
    {
      "epoch": 44.310344827586206,
      "grad_norm": 0.009670683182775974,
      "learning_rate": 6.827586206896552e-06,
      "loss": 0.0009,
      "step": 2570
    },
    {
      "epoch": 44.327586206896555,
      "grad_norm": 0.008246172219514847,
      "learning_rate": 6.806896551724138e-06,
      "loss": 0.0005,
      "step": 2571
    },
    {
      "epoch": 44.3448275862069,
      "grad_norm": 0.011437064036726952,
      "learning_rate": 6.786206896551724e-06,
      "loss": 0.001,
      "step": 2572
    },
    {
      "epoch": 44.36206896551724,
      "grad_norm": 0.019296903163194656,
      "learning_rate": 6.765517241379311e-06,
      "loss": 0.0007,
      "step": 2573
    },
    {
      "epoch": 44.37931034482759,
      "grad_norm": 0.01725100912153721,
      "learning_rate": 6.744827586206896e-06,
      "loss": 0.0013,
      "step": 2574
    },
    {
      "epoch": 44.39655172413793,
      "grad_norm": 0.010550577193498611,
      "learning_rate": 6.724137931034483e-06,
      "loss": 0.0008,
      "step": 2575
    },
    {
      "epoch": 44.41379310344828,
      "grad_norm": 0.017214182764291763,
      "learning_rate": 6.703448275862069e-06,
      "loss": 0.0016,
      "step": 2576
    },
    {
      "epoch": 44.43103448275862,
      "grad_norm": 0.046345777809619904,
      "learning_rate": 6.682758620689656e-06,
      "loss": 0.0014,
      "step": 2577
    },
    {
      "epoch": 44.44827586206897,
      "grad_norm": 0.0322934053838253,
      "learning_rate": 6.662068965517242e-06,
      "loss": 0.0014,
      "step": 2578
    },
    {
      "epoch": 44.46551724137931,
      "grad_norm": 0.010134479962289333,
      "learning_rate": 6.641379310344827e-06,
      "loss": 0.0007,
      "step": 2579
    },
    {
      "epoch": 44.48275862068966,
      "grad_norm": 0.03037002682685852,
      "learning_rate": 6.620689655172414e-06,
      "loss": 0.0015,
      "step": 2580
    },
    {
      "epoch": 44.48275862068966,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010424897773191333,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 8.8611,
      "eval_samples_per_second": 3.273,
      "eval_steps_per_second": 1.693,
      "step": 2580
    },
    {
      "epoch": 44.5,
      "grad_norm": 0.013356019742786884,
      "learning_rate": 6.6e-06,
      "loss": 0.001,
      "step": 2581
    },
    {
      "epoch": 44.51724137931034,
      "grad_norm": 0.01167416013777256,
      "learning_rate": 6.579310344827587e-06,
      "loss": 0.001,
      "step": 2582
    },
    {
      "epoch": 44.53448275862069,
      "grad_norm": 0.009770002216100693,
      "learning_rate": 6.5586206896551725e-06,
      "loss": 0.0009,
      "step": 2583
    },
    {
      "epoch": 44.55172413793103,
      "grad_norm": 0.013929077424108982,
      "learning_rate": 6.537931034482759e-06,
      "loss": 0.0014,
      "step": 2584
    },
    {
      "epoch": 44.56896551724138,
      "grad_norm": 0.013355433009564877,
      "learning_rate": 6.517241379310345e-06,
      "loss": 0.0013,
      "step": 2585
    },
    {
      "epoch": 44.58620689655172,
      "grad_norm": 0.016640346497297287,
      "learning_rate": 6.496551724137931e-06,
      "loss": 0.0015,
      "step": 2586
    },
    {
      "epoch": 44.60344827586207,
      "grad_norm": 0.012232327833771706,
      "learning_rate": 6.475862068965518e-06,
      "loss": 0.0008,
      "step": 2587
    },
    {
      "epoch": 44.62068965517241,
      "grad_norm": 0.019191071391105652,
      "learning_rate": 6.4551724137931034e-06,
      "loss": 0.0008,
      "step": 2588
    },
    {
      "epoch": 44.63793103448276,
      "grad_norm": 0.0631692036986351,
      "learning_rate": 6.43448275862069e-06,
      "loss": 0.0016,
      "step": 2589
    },
    {
      "epoch": 44.6551724137931,
      "grad_norm": 0.017441516742110252,
      "learning_rate": 6.4137931034482765e-06,
      "loss": 0.0014,
      "step": 2590
    },
    {
      "epoch": 44.672413793103445,
      "grad_norm": 0.012041900306940079,
      "learning_rate": 6.393103448275862e-06,
      "loss": 0.0006,
      "step": 2591
    },
    {
      "epoch": 44.689655172413794,
      "grad_norm": 0.013191659934818745,
      "learning_rate": 6.372413793103448e-06,
      "loss": 0.0013,
      "step": 2592
    },
    {
      "epoch": 44.706896551724135,
      "grad_norm": 0.015160039998590946,
      "learning_rate": 6.351724137931034e-06,
      "loss": 0.0012,
      "step": 2593
    },
    {
      "epoch": 44.724137931034484,
      "grad_norm": 0.03185274079442024,
      "learning_rate": 6.331034482758621e-06,
      "loss": 0.0012,
      "step": 2594
    },
    {
      "epoch": 44.741379310344826,
      "grad_norm": 0.02772790566086769,
      "learning_rate": 6.310344827586207e-06,
      "loss": 0.001,
      "step": 2595
    },
    {
      "epoch": 44.758620689655174,
      "grad_norm": 0.011163650080561638,
      "learning_rate": 6.289655172413794e-06,
      "loss": 0.001,
      "step": 2596
    },
    {
      "epoch": 44.775862068965516,
      "grad_norm": 0.009939565323293209,
      "learning_rate": 6.26896551724138e-06,
      "loss": 0.0009,
      "step": 2597
    },
    {
      "epoch": 44.793103448275865,
      "grad_norm": 0.013795644976198673,
      "learning_rate": 6.248275862068965e-06,
      "loss": 0.0013,
      "step": 2598
    },
    {
      "epoch": 44.810344827586206,
      "grad_norm": 0.01229114644229412,
      "learning_rate": 6.227586206896552e-06,
      "loss": 0.0009,
      "step": 2599
    },
    {
      "epoch": 44.827586206896555,
      "grad_norm": 0.02432125434279442,
      "learning_rate": 6.206896551724138e-06,
      "loss": 0.0013,
      "step": 2600
    },
    {
      "epoch": 44.827586206896555,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010665238369256258,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.091,
      "eval_samples_per_second": 2.215,
      "eval_steps_per_second": 1.146,
      "step": 2600
    },
    {
      "epoch": 44.8448275862069,
      "grad_norm": 0.0159049853682518,
      "learning_rate": 6.186206896551724e-06,
      "loss": 0.0014,
      "step": 2601
    },
    {
      "epoch": 44.86206896551724,
      "grad_norm": 0.028452163562178612,
      "learning_rate": 6.1655172413793105e-06,
      "loss": 0.0011,
      "step": 2602
    },
    {
      "epoch": 44.87931034482759,
      "grad_norm": 0.03032541461288929,
      "learning_rate": 6.144827586206897e-06,
      "loss": 0.0016,
      "step": 2603
    },
    {
      "epoch": 44.89655172413793,
      "grad_norm": 0.009613101370632648,
      "learning_rate": 6.1241379310344836e-06,
      "loss": 0.0009,
      "step": 2604
    },
    {
      "epoch": 44.91379310344828,
      "grad_norm": 0.01448756828904152,
      "learning_rate": 6.103448275862069e-06,
      "loss": 0.0014,
      "step": 2605
    },
    {
      "epoch": 44.93103448275862,
      "grad_norm": 0.013066442683339119,
      "learning_rate": 6.082758620689655e-06,
      "loss": 0.0012,
      "step": 2606
    },
    {
      "epoch": 44.94827586206897,
      "grad_norm": 0.011858316138386726,
      "learning_rate": 6.0620689655172414e-06,
      "loss": 0.0005,
      "step": 2607
    },
    {
      "epoch": 44.96551724137931,
      "grad_norm": 0.014357807114720345,
      "learning_rate": 6.041379310344828e-06,
      "loss": 0.0014,
      "step": 2608
    },
    {
      "epoch": 44.98275862068966,
      "grad_norm": 0.018563836812973022,
      "learning_rate": 6.0206896551724145e-06,
      "loss": 0.0013,
      "step": 2609
    },
    {
      "epoch": 45.0,
      "grad_norm": 0.012202093377709389,
      "learning_rate": 6e-06,
      "loss": 0.0008,
      "step": 2610
    },
    {
      "epoch": 45.01724137931034,
      "grad_norm": 0.013576512224972248,
      "learning_rate": 5.979310344827586e-06,
      "loss": 0.0013,
      "step": 2611
    },
    {
      "epoch": 45.03448275862069,
      "grad_norm": 0.02204911597073078,
      "learning_rate": 5.958620689655172e-06,
      "loss": 0.002,
      "step": 2612
    },
    {
      "epoch": 45.05172413793103,
      "grad_norm": 0.018951544538140297,
      "learning_rate": 5.937931034482759e-06,
      "loss": 0.0012,
      "step": 2613
    },
    {
      "epoch": 45.06896551724138,
      "grad_norm": 0.02411615289747715,
      "learning_rate": 5.917241379310345e-06,
      "loss": 0.0016,
      "step": 2614
    },
    {
      "epoch": 45.08620689655172,
      "grad_norm": 0.029075371101498604,
      "learning_rate": 5.896551724137931e-06,
      "loss": 0.0014,
      "step": 2615
    },
    {
      "epoch": 45.10344827586207,
      "grad_norm": 0.020666101947426796,
      "learning_rate": 5.875862068965518e-06,
      "loss": 0.0011,
      "step": 2616
    },
    {
      "epoch": 45.12068965517241,
      "grad_norm": 0.04826202243566513,
      "learning_rate": 5.855172413793104e-06,
      "loss": 0.0008,
      "step": 2617
    },
    {
      "epoch": 45.13793103448276,
      "grad_norm": 0.013517070561647415,
      "learning_rate": 5.83448275862069e-06,
      "loss": 0.0011,
      "step": 2618
    },
    {
      "epoch": 45.1551724137931,
      "grad_norm": 0.016215864568948746,
      "learning_rate": 5.8137931034482755e-06,
      "loss": 0.0011,
      "step": 2619
    },
    {
      "epoch": 45.172413793103445,
      "grad_norm": 0.014070414938032627,
      "learning_rate": 5.793103448275862e-06,
      "loss": 0.0013,
      "step": 2620
    },
    {
      "epoch": 45.172413793103445,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0011308548273518682,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 9.21,
      "eval_samples_per_second": 3.149,
      "eval_steps_per_second": 1.629,
      "step": 2620
    },
    {
      "epoch": 45.189655172413794,
      "grad_norm": 0.016756149008870125,
      "learning_rate": 5.7724137931034485e-06,
      "loss": 0.0015,
      "step": 2621
    },
    {
      "epoch": 45.206896551724135,
      "grad_norm": 0.015382152982056141,
      "learning_rate": 5.751724137931035e-06,
      "loss": 0.0011,
      "step": 2622
    },
    {
      "epoch": 45.224137931034484,
      "grad_norm": 0.019501065835356712,
      "learning_rate": 5.7310344827586215e-06,
      "loss": 0.001,
      "step": 2623
    },
    {
      "epoch": 45.241379310344826,
      "grad_norm": 0.01855490170419216,
      "learning_rate": 5.710344827586206e-06,
      "loss": 0.0015,
      "step": 2624
    },
    {
      "epoch": 45.258620689655174,
      "grad_norm": 0.013218700885772705,
      "learning_rate": 5.689655172413793e-06,
      "loss": 0.0012,
      "step": 2625
    },
    {
      "epoch": 45.275862068965516,
      "grad_norm": 0.02165742591023445,
      "learning_rate": 5.668965517241379e-06,
      "loss": 0.0013,
      "step": 2626
    },
    {
      "epoch": 45.293103448275865,
      "grad_norm": 0.010778135620057583,
      "learning_rate": 5.648275862068966e-06,
      "loss": 0.0009,
      "step": 2627
    },
    {
      "epoch": 45.310344827586206,
      "grad_norm": 0.013598757795989513,
      "learning_rate": 5.627586206896552e-06,
      "loss": 0.0012,
      "step": 2628
    },
    {
      "epoch": 45.327586206896555,
      "grad_norm": 0.02082759700715542,
      "learning_rate": 5.606896551724138e-06,
      "loss": 0.0012,
      "step": 2629
    },
    {
      "epoch": 45.3448275862069,
      "grad_norm": 0.010176314041018486,
      "learning_rate": 5.586206896551725e-06,
      "loss": 0.001,
      "step": 2630
    },
    {
      "epoch": 45.36206896551724,
      "grad_norm": 0.013311708346009254,
      "learning_rate": 5.56551724137931e-06,
      "loss": 0.0009,
      "step": 2631
    },
    {
      "epoch": 45.37931034482759,
      "grad_norm": 0.009046318009495735,
      "learning_rate": 5.544827586206897e-06,
      "loss": 0.0008,
      "step": 2632
    },
    {
      "epoch": 45.39655172413793,
      "grad_norm": 0.014188234694302082,
      "learning_rate": 5.5241379310344825e-06,
      "loss": 0.0011,
      "step": 2633
    },
    {
      "epoch": 45.41379310344828,
      "grad_norm": 0.01701010763645172,
      "learning_rate": 5.503448275862069e-06,
      "loss": 0.0014,
      "step": 2634
    },
    {
      "epoch": 45.43103448275862,
      "grad_norm": 0.020935866981744766,
      "learning_rate": 5.4827586206896556e-06,
      "loss": 0.0016,
      "step": 2635
    },
    {
      "epoch": 45.44827586206897,
      "grad_norm": 0.011669831350445747,
      "learning_rate": 5.462068965517242e-06,
      "loss": 0.0008,
      "step": 2636
    },
    {
      "epoch": 45.46551724137931,
      "grad_norm": 0.007426746655255556,
      "learning_rate": 5.441379310344828e-06,
      "loss": 0.0005,
      "step": 2637
    },
    {
      "epoch": 45.48275862068966,
      "grad_norm": 0.018308788537979126,
      "learning_rate": 5.4206896551724134e-06,
      "loss": 0.0015,
      "step": 2638
    },
    {
      "epoch": 45.5,
      "grad_norm": 0.040585506707429886,
      "learning_rate": 5.4e-06,
      "loss": 0.0012,
      "step": 2639
    },
    {
      "epoch": 45.51724137931034,
      "grad_norm": 0.016893019899725914,
      "learning_rate": 5.3793103448275865e-06,
      "loss": 0.0008,
      "step": 2640
    },
    {
      "epoch": 45.51724137931034,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010246383026242256,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.1001,
      "eval_samples_per_second": 2.613,
      "eval_steps_per_second": 1.351,
      "step": 2640
    },
    {
      "epoch": 45.53448275862069,
      "grad_norm": 0.024692818522453308,
      "learning_rate": 5.358620689655173e-06,
      "loss": 0.0015,
      "step": 2641
    },
    {
      "epoch": 45.55172413793103,
      "grad_norm": 0.012185433879494667,
      "learning_rate": 5.337931034482759e-06,
      "loss": 0.001,
      "step": 2642
    },
    {
      "epoch": 45.56896551724138,
      "grad_norm": 0.04598280414938927,
      "learning_rate": 5.317241379310345e-06,
      "loss": 0.0011,
      "step": 2643
    },
    {
      "epoch": 45.58620689655172,
      "grad_norm": 0.010246116667985916,
      "learning_rate": 5.296551724137931e-06,
      "loss": 0.0006,
      "step": 2644
    },
    {
      "epoch": 45.60344827586207,
      "grad_norm": 0.007747293449938297,
      "learning_rate": 5.275862068965517e-06,
      "loss": 0.0005,
      "step": 2645
    },
    {
      "epoch": 45.62068965517241,
      "grad_norm": 0.01353488676249981,
      "learning_rate": 5.255172413793103e-06,
      "loss": 0.001,
      "step": 2646
    },
    {
      "epoch": 45.63793103448276,
      "grad_norm": 0.02573573775589466,
      "learning_rate": 5.23448275862069e-06,
      "loss": 0.0009,
      "step": 2647
    },
    {
      "epoch": 45.6551724137931,
      "grad_norm": 0.03024262562394142,
      "learning_rate": 5.213793103448276e-06,
      "loss": 0.001,
      "step": 2648
    },
    {
      "epoch": 45.672413793103445,
      "grad_norm": 0.01781340502202511,
      "learning_rate": 5.193103448275863e-06,
      "loss": 0.0011,
      "step": 2649
    },
    {
      "epoch": 45.689655172413794,
      "grad_norm": 0.01930053159594536,
      "learning_rate": 5.172413793103449e-06,
      "loss": 0.0016,
      "step": 2650
    },
    {
      "epoch": 45.706896551724135,
      "grad_norm": 0.020830854773521423,
      "learning_rate": 5.151724137931034e-06,
      "loss": 0.0018,
      "step": 2651
    },
    {
      "epoch": 45.724137931034484,
      "grad_norm": 0.009470254182815552,
      "learning_rate": 5.1310344827586205e-06,
      "loss": 0.0009,
      "step": 2652
    },
    {
      "epoch": 45.741379310344826,
      "grad_norm": 0.03125688433647156,
      "learning_rate": 5.110344827586207e-06,
      "loss": 0.0012,
      "step": 2653
    },
    {
      "epoch": 45.758620689655174,
      "grad_norm": 0.031165963038802147,
      "learning_rate": 5.0896551724137936e-06,
      "loss": 0.0017,
      "step": 2654
    },
    {
      "epoch": 45.775862068965516,
      "grad_norm": 0.014100690372288227,
      "learning_rate": 5.068965517241379e-06,
      "loss": 0.001,
      "step": 2655
    },
    {
      "epoch": 45.793103448275865,
      "grad_norm": 0.034227240830659866,
      "learning_rate": 5.048275862068966e-06,
      "loss": 0.0015,
      "step": 2656
    },
    {
      "epoch": 45.810344827586206,
      "grad_norm": 0.019871126860380173,
      "learning_rate": 5.027586206896552e-06,
      "loss": 0.0013,
      "step": 2657
    },
    {
      "epoch": 45.827586206896555,
      "grad_norm": 0.02032747119665146,
      "learning_rate": 5.006896551724138e-06,
      "loss": 0.0012,
      "step": 2658
    },
    {
      "epoch": 45.8448275862069,
      "grad_norm": 0.010927741415798664,
      "learning_rate": 4.9862068965517245e-06,
      "loss": 0.0007,
      "step": 2659
    },
    {
      "epoch": 45.86206896551724,
      "grad_norm": 0.02740209549665451,
      "learning_rate": 4.96551724137931e-06,
      "loss": 0.0016,
      "step": 2660
    },
    {
      "epoch": 45.86206896551724,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0011301094200462103,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.5951,
      "eval_samples_per_second": 2.737,
      "eval_steps_per_second": 1.416,
      "step": 2660
    },
    {
      "epoch": 45.87931034482759,
      "grad_norm": 0.014072466641664505,
      "learning_rate": 4.944827586206897e-06,
      "loss": 0.0008,
      "step": 2661
    },
    {
      "epoch": 45.89655172413793,
      "grad_norm": 0.015354452654719353,
      "learning_rate": 4.924137931034483e-06,
      "loss": 0.0011,
      "step": 2662
    },
    {
      "epoch": 45.91379310344828,
      "grad_norm": 0.012786018662154675,
      "learning_rate": 4.90344827586207e-06,
      "loss": 0.0011,
      "step": 2663
    },
    {
      "epoch": 45.93103448275862,
      "grad_norm": 0.02521980181336403,
      "learning_rate": 4.8827586206896545e-06,
      "loss": 0.0009,
      "step": 2664
    },
    {
      "epoch": 45.94827586206897,
      "grad_norm": 0.0164699275046587,
      "learning_rate": 4.862068965517241e-06,
      "loss": 0.001,
      "step": 2665
    },
    {
      "epoch": 45.96551724137931,
      "grad_norm": 0.009605222381651402,
      "learning_rate": 4.841379310344828e-06,
      "loss": 0.0007,
      "step": 2666
    },
    {
      "epoch": 45.98275862068966,
      "grad_norm": 0.015095338225364685,
      "learning_rate": 4.820689655172414e-06,
      "loss": 0.0014,
      "step": 2667
    },
    {
      "epoch": 46.0,
      "grad_norm": 0.012060750275850296,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.0011,
      "step": 2668
    },
    {
      "epoch": 46.01724137931034,
      "grad_norm": 0.019203096628189087,
      "learning_rate": 4.779310344827586e-06,
      "loss": 0.0012,
      "step": 2669
    },
    {
      "epoch": 46.03448275862069,
      "grad_norm": 0.010068638250231743,
      "learning_rate": 4.758620689655173e-06,
      "loss": 0.0009,
      "step": 2670
    },
    {
      "epoch": 46.05172413793103,
      "grad_norm": 0.024953654035925865,
      "learning_rate": 4.7379310344827585e-06,
      "loss": 0.001,
      "step": 2671
    },
    {
      "epoch": 46.06896551724138,
      "grad_norm": 0.0286016333848238,
      "learning_rate": 4.717241379310345e-06,
      "loss": 0.0013,
      "step": 2672
    },
    {
      "epoch": 46.08620689655172,
      "grad_norm": 0.016054941341280937,
      "learning_rate": 4.696551724137931e-06,
      "loss": 0.0011,
      "step": 2673
    },
    {
      "epoch": 46.10344827586207,
      "grad_norm": 0.014949141070246696,
      "learning_rate": 4.675862068965517e-06,
      "loss": 0.0013,
      "step": 2674
    },
    {
      "epoch": 46.12068965517241,
      "grad_norm": 0.016469426453113556,
      "learning_rate": 4.655172413793104e-06,
      "loss": 0.0012,
      "step": 2675
    },
    {
      "epoch": 46.13793103448276,
      "grad_norm": 0.017490984871983528,
      "learning_rate": 4.63448275862069e-06,
      "loss": 0.0013,
      "step": 2676
    },
    {
      "epoch": 46.1551724137931,
      "grad_norm": 0.050434235483407974,
      "learning_rate": 4.613793103448277e-06,
      "loss": 0.0013,
      "step": 2677
    },
    {
      "epoch": 46.172413793103445,
      "grad_norm": 0.015309648588299751,
      "learning_rate": 4.593103448275862e-06,
      "loss": 0.001,
      "step": 2678
    },
    {
      "epoch": 46.189655172413794,
      "grad_norm": 0.01679728552699089,
      "learning_rate": 4.572413793103448e-06,
      "loss": 0.0013,
      "step": 2679
    },
    {
      "epoch": 46.206896551724135,
      "grad_norm": 0.022521333768963814,
      "learning_rate": 4.551724137931035e-06,
      "loss": 0.0009,
      "step": 2680
    },
    {
      "epoch": 46.206896551724135,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010846303775906563,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 12.7185,
      "eval_samples_per_second": 2.28,
      "eval_steps_per_second": 1.179,
      "step": 2680
    },
    {
      "epoch": 46.224137931034484,
      "grad_norm": 0.022787073627114296,
      "learning_rate": 4.531034482758621e-06,
      "loss": 0.001,
      "step": 2681
    },
    {
      "epoch": 46.241379310344826,
      "grad_norm": 0.006116871722042561,
      "learning_rate": 4.510344827586207e-06,
      "loss": 0.0005,
      "step": 2682
    },
    {
      "epoch": 46.258620689655174,
      "grad_norm": 0.008130417205393314,
      "learning_rate": 4.489655172413793e-06,
      "loss": 0.0007,
      "step": 2683
    },
    {
      "epoch": 46.275862068965516,
      "grad_norm": 0.011463725939393044,
      "learning_rate": 4.468965517241379e-06,
      "loss": 0.001,
      "step": 2684
    },
    {
      "epoch": 46.293103448275865,
      "grad_norm": 0.016076918691396713,
      "learning_rate": 4.4482758620689656e-06,
      "loss": 0.0013,
      "step": 2685
    },
    {
      "epoch": 46.310344827586206,
      "grad_norm": 0.008563085459172726,
      "learning_rate": 4.427586206896552e-06,
      "loss": 0.0007,
      "step": 2686
    },
    {
      "epoch": 46.327586206896555,
      "grad_norm": 0.009552675299346447,
      "learning_rate": 4.406896551724138e-06,
      "loss": 0.0008,
      "step": 2687
    },
    {
      "epoch": 46.3448275862069,
      "grad_norm": 0.02059020660817623,
      "learning_rate": 4.386206896551724e-06,
      "loss": 0.0013,
      "step": 2688
    },
    {
      "epoch": 46.36206896551724,
      "grad_norm": 0.0103343166410923,
      "learning_rate": 4.365517241379311e-06,
      "loss": 0.0009,
      "step": 2689
    },
    {
      "epoch": 46.37931034482759,
      "grad_norm": 0.01452209334820509,
      "learning_rate": 4.344827586206897e-06,
      "loss": 0.0011,
      "step": 2690
    },
    {
      "epoch": 46.39655172413793,
      "grad_norm": 0.018944423645734787,
      "learning_rate": 4.324137931034482e-06,
      "loss": 0.0014,
      "step": 2691
    },
    {
      "epoch": 46.41379310344828,
      "grad_norm": 0.01327041257172823,
      "learning_rate": 4.303448275862069e-06,
      "loss": 0.0012,
      "step": 2692
    },
    {
      "epoch": 46.43103448275862,
      "grad_norm": 0.009717914275825024,
      "learning_rate": 4.282758620689655e-06,
      "loss": 0.0008,
      "step": 2693
    },
    {
      "epoch": 46.44827586206897,
      "grad_norm": 0.019573790952563286,
      "learning_rate": 4.262068965517242e-06,
      "loss": 0.001,
      "step": 2694
    },
    {
      "epoch": 46.46551724137931,
      "grad_norm": 0.05446851998567581,
      "learning_rate": 4.241379310344828e-06,
      "loss": 0.002,
      "step": 2695
    },
    {
      "epoch": 46.48275862068966,
      "grad_norm": 0.017342017963528633,
      "learning_rate": 4.220689655172414e-06,
      "loss": 0.0014,
      "step": 2696
    },
    {
      "epoch": 46.5,
      "grad_norm": 0.011466354131698608,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.0011,
      "step": 2697
    },
    {
      "epoch": 46.51724137931034,
      "grad_norm": 0.017255887389183044,
      "learning_rate": 4.179310344827586e-06,
      "loss": 0.0013,
      "step": 2698
    },
    {
      "epoch": 46.53448275862069,
      "grad_norm": 0.013892465271055698,
      "learning_rate": 4.158620689655173e-06,
      "loss": 0.0006,
      "step": 2699
    },
    {
      "epoch": 46.55172413793103,
      "grad_norm": 0.018115416169166565,
      "learning_rate": 4.137931034482758e-06,
      "loss": 0.001,
      "step": 2700
    },
    {
      "epoch": 46.55172413793103,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010442285565659404,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 17.9206,
      "eval_samples_per_second": 1.618,
      "eval_steps_per_second": 0.837,
      "step": 2700
    },
    {
      "epoch": 46.56896551724138,
      "grad_norm": 0.008918387815356255,
      "learning_rate": 4.117241379310345e-06,
      "loss": 0.0007,
      "step": 2701
    },
    {
      "epoch": 46.58620689655172,
      "grad_norm": 0.02128436416387558,
      "learning_rate": 4.096551724137931e-06,
      "loss": 0.0013,
      "step": 2702
    },
    {
      "epoch": 46.60344827586207,
      "grad_norm": 0.016483156010508537,
      "learning_rate": 4.075862068965518e-06,
      "loss": 0.0016,
      "step": 2703
    },
    {
      "epoch": 46.62068965517241,
      "grad_norm": 0.043053533881902695,
      "learning_rate": 4.0551724137931036e-06,
      "loss": 0.0019,
      "step": 2704
    },
    {
      "epoch": 46.63793103448276,
      "grad_norm": 0.012905358336865902,
      "learning_rate": 4.034482758620689e-06,
      "loss": 0.0009,
      "step": 2705
    },
    {
      "epoch": 46.6551724137931,
      "grad_norm": 0.013561632484197617,
      "learning_rate": 4.013793103448276e-06,
      "loss": 0.0011,
      "step": 2706
    },
    {
      "epoch": 46.672413793103445,
      "grad_norm": 0.022895000874996185,
      "learning_rate": 3.993103448275862e-06,
      "loss": 0.0013,
      "step": 2707
    },
    {
      "epoch": 46.689655172413794,
      "grad_norm": 0.01259172335267067,
      "learning_rate": 3.972413793103449e-06,
      "loss": 0.0008,
      "step": 2708
    },
    {
      "epoch": 46.706896551724135,
      "grad_norm": 0.008268368430435658,
      "learning_rate": 3.9517241379310345e-06,
      "loss": 0.0006,
      "step": 2709
    },
    {
      "epoch": 46.724137931034484,
      "grad_norm": 0.018455855548381805,
      "learning_rate": 3.931034482758621e-06,
      "loss": 0.0016,
      "step": 2710
    },
    {
      "epoch": 46.741379310344826,
      "grad_norm": 0.012745870277285576,
      "learning_rate": 3.910344827586207e-06,
      "loss": 0.001,
      "step": 2711
    },
    {
      "epoch": 46.758620689655174,
      "grad_norm": 0.03115890733897686,
      "learning_rate": 3.889655172413793e-06,
      "loss": 0.0016,
      "step": 2712
    },
    {
      "epoch": 46.775862068965516,
      "grad_norm": 0.010649015195667744,
      "learning_rate": 3.86896551724138e-06,
      "loss": 0.0009,
      "step": 2713
    },
    {
      "epoch": 46.793103448275865,
      "grad_norm": 0.013183413073420525,
      "learning_rate": 3.848275862068965e-06,
      "loss": 0.0012,
      "step": 2714
    },
    {
      "epoch": 46.810344827586206,
      "grad_norm": 0.010882891714572906,
      "learning_rate": 3.827586206896552e-06,
      "loss": 0.0009,
      "step": 2715
    },
    {
      "epoch": 46.827586206896555,
      "grad_norm": 0.03352808207273483,
      "learning_rate": 3.8068965517241384e-06,
      "loss": 0.001,
      "step": 2716
    },
    {
      "epoch": 46.8448275862069,
      "grad_norm": 0.026638444513082504,
      "learning_rate": 3.7862068965517245e-06,
      "loss": 0.0015,
      "step": 2717
    },
    {
      "epoch": 46.86206896551724,
      "grad_norm": 0.018686901777982712,
      "learning_rate": 3.76551724137931e-06,
      "loss": 0.0015,
      "step": 2718
    },
    {
      "epoch": 46.87931034482759,
      "grad_norm": 0.05039864778518677,
      "learning_rate": 3.7448275862068963e-06,
      "loss": 0.0021,
      "step": 2719
    },
    {
      "epoch": 46.89655172413793,
      "grad_norm": 0.024410661309957504,
      "learning_rate": 3.724137931034483e-06,
      "loss": 0.0009,
      "step": 2720
    },
    {
      "epoch": 46.89655172413793,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0011784418020397425,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 16.06,
      "eval_samples_per_second": 1.806,
      "eval_steps_per_second": 0.934,
      "step": 2720
    },
    {
      "epoch": 46.91379310344828,
      "grad_norm": 0.013518029823899269,
      "learning_rate": 3.703448275862069e-06,
      "loss": 0.001,
      "step": 2721
    },
    {
      "epoch": 46.93103448275862,
      "grad_norm": 0.0095900297164917,
      "learning_rate": 3.6827586206896554e-06,
      "loss": 0.0008,
      "step": 2722
    },
    {
      "epoch": 46.94827586206897,
      "grad_norm": 0.016724517568945885,
      "learning_rate": 3.6620689655172415e-06,
      "loss": 0.0013,
      "step": 2723
    },
    {
      "epoch": 46.96551724137931,
      "grad_norm": 0.011203182861208916,
      "learning_rate": 3.6413793103448276e-06,
      "loss": 0.0009,
      "step": 2724
    },
    {
      "epoch": 46.98275862068966,
      "grad_norm": 0.010318833403289318,
      "learning_rate": 3.620689655172414e-06,
      "loss": 0.0009,
      "step": 2725
    },
    {
      "epoch": 47.0,
      "grad_norm": 0.037317246198654175,
      "learning_rate": 3.6e-06,
      "loss": 0.0012,
      "step": 2726
    },
    {
      "epoch": 47.01724137931034,
      "grad_norm": 0.010020030662417412,
      "learning_rate": 3.5793103448275864e-06,
      "loss": 0.0008,
      "step": 2727
    },
    {
      "epoch": 47.03448275862069,
      "grad_norm": 0.009262701496481895,
      "learning_rate": 3.5586206896551725e-06,
      "loss": 0.0007,
      "step": 2728
    },
    {
      "epoch": 47.05172413793103,
      "grad_norm": 0.01822611503303051,
      "learning_rate": 3.5379310344827586e-06,
      "loss": 0.0015,
      "step": 2729
    },
    {
      "epoch": 47.06896551724138,
      "grad_norm": 0.017617935314774513,
      "learning_rate": 3.517241379310345e-06,
      "loss": 0.0014,
      "step": 2730
    },
    {
      "epoch": 47.08620689655172,
      "grad_norm": 0.015137647278606892,
      "learning_rate": 3.496551724137931e-06,
      "loss": 0.0009,
      "step": 2731
    },
    {
      "epoch": 47.10344827586207,
      "grad_norm": 0.0434141643345356,
      "learning_rate": 3.4758620689655177e-06,
      "loss": 0.0015,
      "step": 2732
    },
    {
      "epoch": 47.12068965517241,
      "grad_norm": 0.012553523294627666,
      "learning_rate": 3.4551724137931034e-06,
      "loss": 0.0011,
      "step": 2733
    },
    {
      "epoch": 47.13793103448276,
      "grad_norm": 0.011613062582910061,
      "learning_rate": 3.43448275862069e-06,
      "loss": 0.0009,
      "step": 2734
    },
    {
      "epoch": 47.1551724137931,
      "grad_norm": 0.03644666448235512,
      "learning_rate": 3.413793103448276e-06,
      "loss": 0.0016,
      "step": 2735
    },
    {
      "epoch": 47.172413793103445,
      "grad_norm": 0.009546536952257156,
      "learning_rate": 3.393103448275862e-06,
      "loss": 0.0008,
      "step": 2736
    },
    {
      "epoch": 47.189655172413794,
      "grad_norm": 0.028263527899980545,
      "learning_rate": 3.372413793103448e-06,
      "loss": 0.0015,
      "step": 2737
    },
    {
      "epoch": 47.206896551724135,
      "grad_norm": 0.012197671458125114,
      "learning_rate": 3.3517241379310347e-06,
      "loss": 0.0009,
      "step": 2738
    },
    {
      "epoch": 47.224137931034484,
      "grad_norm": 0.01773311384022236,
      "learning_rate": 3.331034482758621e-06,
      "loss": 0.0009,
      "step": 2739
    },
    {
      "epoch": 47.241379310344826,
      "grad_norm": 0.022708650678396225,
      "learning_rate": 3.310344827586207e-06,
      "loss": 0.0009,
      "step": 2740
    },
    {
      "epoch": 47.241379310344826,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010369494557380676,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.6894,
      "eval_samples_per_second": 2.118,
      "eval_steps_per_second": 1.096,
      "step": 2740
    },
    {
      "epoch": 47.258620689655174,
      "grad_norm": 0.011218165047466755,
      "learning_rate": 3.2896551724137934e-06,
      "loss": 0.0009,
      "step": 2741
    },
    {
      "epoch": 47.275862068965516,
      "grad_norm": 0.01081379409879446,
      "learning_rate": 3.2689655172413795e-06,
      "loss": 0.001,
      "step": 2742
    },
    {
      "epoch": 47.293103448275865,
      "grad_norm": 0.019043806940317154,
      "learning_rate": 3.2482758620689656e-06,
      "loss": 0.0016,
      "step": 2743
    },
    {
      "epoch": 47.310344827586206,
      "grad_norm": 0.01835414581000805,
      "learning_rate": 3.2275862068965517e-06,
      "loss": 0.0014,
      "step": 2744
    },
    {
      "epoch": 47.327586206896555,
      "grad_norm": 0.034175340086221695,
      "learning_rate": 3.2068965517241382e-06,
      "loss": 0.0018,
      "step": 2745
    },
    {
      "epoch": 47.3448275862069,
      "grad_norm": 0.02319897711277008,
      "learning_rate": 3.186206896551724e-06,
      "loss": 0.0012,
      "step": 2746
    },
    {
      "epoch": 47.36206896551724,
      "grad_norm": 0.015625763684511185,
      "learning_rate": 3.1655172413793104e-06,
      "loss": 0.0007,
      "step": 2747
    },
    {
      "epoch": 47.37931034482759,
      "grad_norm": 0.008480004034936428,
      "learning_rate": 3.144827586206897e-06,
      "loss": 0.0008,
      "step": 2748
    },
    {
      "epoch": 47.39655172413793,
      "grad_norm": 0.009634128771722317,
      "learning_rate": 3.1241379310344826e-06,
      "loss": 0.0007,
      "step": 2749
    },
    {
      "epoch": 47.41379310344828,
      "grad_norm": 0.020904911682009697,
      "learning_rate": 3.103448275862069e-06,
      "loss": 0.0014,
      "step": 2750
    },
    {
      "epoch": 47.43103448275862,
      "grad_norm": 0.02527475915849209,
      "learning_rate": 3.0827586206896553e-06,
      "loss": 0.0015,
      "step": 2751
    },
    {
      "epoch": 47.44827586206897,
      "grad_norm": 0.008410586975514889,
      "learning_rate": 3.0620689655172418e-06,
      "loss": 0.0005,
      "step": 2752
    },
    {
      "epoch": 47.46551724137931,
      "grad_norm": 0.011787447147071362,
      "learning_rate": 3.0413793103448275e-06,
      "loss": 0.0009,
      "step": 2753
    },
    {
      "epoch": 47.48275862068966,
      "grad_norm": 0.019302280619740486,
      "learning_rate": 3.020689655172414e-06,
      "loss": 0.0012,
      "step": 2754
    },
    {
      "epoch": 47.5,
      "grad_norm": 0.0058467877097427845,
      "learning_rate": 3e-06,
      "loss": 0.0005,
      "step": 2755
    },
    {
      "epoch": 47.51724137931034,
      "grad_norm": 0.017694829031825066,
      "learning_rate": 2.979310344827586e-06,
      "loss": 0.0017,
      "step": 2756
    },
    {
      "epoch": 47.53448275862069,
      "grad_norm": 0.03650875762104988,
      "learning_rate": 2.9586206896551727e-06,
      "loss": 0.0017,
      "step": 2757
    },
    {
      "epoch": 47.55172413793103,
      "grad_norm": 0.021690085530281067,
      "learning_rate": 2.937931034482759e-06,
      "loss": 0.0014,
      "step": 2758
    },
    {
      "epoch": 47.56896551724138,
      "grad_norm": 0.011670297011733055,
      "learning_rate": 2.917241379310345e-06,
      "loss": 0.001,
      "step": 2759
    },
    {
      "epoch": 47.58620689655172,
      "grad_norm": 0.01319629792124033,
      "learning_rate": 2.896551724137931e-06,
      "loss": 0.0012,
      "step": 2760
    },
    {
      "epoch": 47.58620689655172,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010628342861309648,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.9662,
      "eval_samples_per_second": 2.076,
      "eval_steps_per_second": 1.074,
      "step": 2760
    },
    {
      "epoch": 47.60344827586207,
      "grad_norm": 0.014737647026777267,
      "learning_rate": 2.8758620689655175e-06,
      "loss": 0.0014,
      "step": 2761
    },
    {
      "epoch": 47.62068965517241,
      "grad_norm": 0.016288844868540764,
      "learning_rate": 2.855172413793103e-06,
      "loss": 0.0011,
      "step": 2762
    },
    {
      "epoch": 47.63793103448276,
      "grad_norm": 0.013030782341957092,
      "learning_rate": 2.8344827586206897e-06,
      "loss": 0.0011,
      "step": 2763
    },
    {
      "epoch": 47.6551724137931,
      "grad_norm": 0.009283638559281826,
      "learning_rate": 2.813793103448276e-06,
      "loss": 0.0007,
      "step": 2764
    },
    {
      "epoch": 47.672413793103445,
      "grad_norm": 0.011228869669139385,
      "learning_rate": 2.7931034482758623e-06,
      "loss": 0.0006,
      "step": 2765
    },
    {
      "epoch": 47.689655172413794,
      "grad_norm": 0.018251478672027588,
      "learning_rate": 2.7724137931034484e-06,
      "loss": 0.0012,
      "step": 2766
    },
    {
      "epoch": 47.706896551724135,
      "grad_norm": 0.009045383892953396,
      "learning_rate": 2.7517241379310345e-06,
      "loss": 0.0007,
      "step": 2767
    },
    {
      "epoch": 47.724137931034484,
      "grad_norm": 0.020150357857346535,
      "learning_rate": 2.731034482758621e-06,
      "loss": 0.0013,
      "step": 2768
    },
    {
      "epoch": 47.741379310344826,
      "grad_norm": 0.011436890810728073,
      "learning_rate": 2.7103448275862067e-06,
      "loss": 0.001,
      "step": 2769
    },
    {
      "epoch": 47.758620689655174,
      "grad_norm": 0.014181220903992653,
      "learning_rate": 2.6896551724137932e-06,
      "loss": 0.0015,
      "step": 2770
    },
    {
      "epoch": 47.775862068965516,
      "grad_norm": 0.011472421698272228,
      "learning_rate": 2.6689655172413793e-06,
      "loss": 0.0009,
      "step": 2771
    },
    {
      "epoch": 47.793103448275865,
      "grad_norm": 0.02522199973464012,
      "learning_rate": 2.6482758620689654e-06,
      "loss": 0.0009,
      "step": 2772
    },
    {
      "epoch": 47.810344827586206,
      "grad_norm": 0.014008312486112118,
      "learning_rate": 2.6275862068965515e-06,
      "loss": 0.0009,
      "step": 2773
    },
    {
      "epoch": 47.827586206896555,
      "grad_norm": 0.015039937570691109,
      "learning_rate": 2.606896551724138e-06,
      "loss": 0.0014,
      "step": 2774
    },
    {
      "epoch": 47.8448275862069,
      "grad_norm": 0.03037342242896557,
      "learning_rate": 2.5862068965517246e-06,
      "loss": 0.0013,
      "step": 2775
    },
    {
      "epoch": 47.86206896551724,
      "grad_norm": 0.02243322692811489,
      "learning_rate": 2.5655172413793103e-06,
      "loss": 0.0018,
      "step": 2776
    },
    {
      "epoch": 47.87931034482759,
      "grad_norm": 0.011103085242211819,
      "learning_rate": 2.5448275862068968e-06,
      "loss": 0.001,
      "step": 2777
    },
    {
      "epoch": 47.89655172413793,
      "grad_norm": 0.006381543818861246,
      "learning_rate": 2.524137931034483e-06,
      "loss": 0.0005,
      "step": 2778
    },
    {
      "epoch": 47.91379310344828,
      "grad_norm": 0.025070730596780777,
      "learning_rate": 2.503448275862069e-06,
      "loss": 0.0013,
      "step": 2779
    },
    {
      "epoch": 47.93103448275862,
      "grad_norm": 0.021425003185868263,
      "learning_rate": 2.482758620689655e-06,
      "loss": 0.0011,
      "step": 2780
    },
    {
      "epoch": 47.93103448275862,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010430555557832122,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 11.8606,
      "eval_samples_per_second": 2.445,
      "eval_steps_per_second": 1.265,
      "step": 2780
    },
    {
      "epoch": 47.94827586206897,
      "grad_norm": 0.017729436978697777,
      "learning_rate": 2.4620689655172416e-06,
      "loss": 0.0014,
      "step": 2781
    },
    {
      "epoch": 47.96551724137931,
      "grad_norm": 0.008995256386697292,
      "learning_rate": 2.4413793103448273e-06,
      "loss": 0.0008,
      "step": 2782
    },
    {
      "epoch": 47.98275862068966,
      "grad_norm": 0.038814060389995575,
      "learning_rate": 2.420689655172414e-06,
      "loss": 0.0011,
      "step": 2783
    },
    {
      "epoch": 48.0,
      "grad_norm": 0.017027031630277634,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.0013,
      "step": 2784
    },
    {
      "epoch": 48.01724137931034,
      "grad_norm": 0.01820952259004116,
      "learning_rate": 2.3793103448275864e-06,
      "loss": 0.0012,
      "step": 2785
    },
    {
      "epoch": 48.03448275862069,
      "grad_norm": 0.023578710854053497,
      "learning_rate": 2.3586206896551725e-06,
      "loss": 0.0015,
      "step": 2786
    },
    {
      "epoch": 48.05172413793103,
      "grad_norm": 0.022344307973980904,
      "learning_rate": 2.3379310344827586e-06,
      "loss": 0.0012,
      "step": 2787
    },
    {
      "epoch": 48.06896551724138,
      "grad_norm": 0.08048342913389206,
      "learning_rate": 2.317241379310345e-06,
      "loss": 0.0026,
      "step": 2788
    },
    {
      "epoch": 48.08620689655172,
      "grad_norm": 0.02259916625916958,
      "learning_rate": 2.296551724137931e-06,
      "loss": 0.0013,
      "step": 2789
    },
    {
      "epoch": 48.10344827586207,
      "grad_norm": 0.012237588874995708,
      "learning_rate": 2.2758620689655173e-06,
      "loss": 0.0008,
      "step": 2790
    },
    {
      "epoch": 48.12068965517241,
      "grad_norm": 0.01808641105890274,
      "learning_rate": 2.2551724137931034e-06,
      "loss": 0.0015,
      "step": 2791
    },
    {
      "epoch": 48.13793103448276,
      "grad_norm": 0.010061646811664104,
      "learning_rate": 2.2344827586206895e-06,
      "loss": 0.001,
      "step": 2792
    },
    {
      "epoch": 48.1551724137931,
      "grad_norm": 0.01477322168648243,
      "learning_rate": 2.213793103448276e-06,
      "loss": 0.001,
      "step": 2793
    },
    {
      "epoch": 48.172413793103445,
      "grad_norm": 0.03472783416509628,
      "learning_rate": 2.193103448275862e-06,
      "loss": 0.0009,
      "step": 2794
    },
    {
      "epoch": 48.189655172413794,
      "grad_norm": 0.006506962236016989,
      "learning_rate": 2.1724137931034487e-06,
      "loss": 0.0003,
      "step": 2795
    },
    {
      "epoch": 48.206896551724135,
      "grad_norm": 0.026161545887589455,
      "learning_rate": 2.1517241379310343e-06,
      "loss": 0.0016,
      "step": 2796
    },
    {
      "epoch": 48.224137931034484,
      "grad_norm": 0.01451309397816658,
      "learning_rate": 2.131034482758621e-06,
      "loss": 0.0014,
      "step": 2797
    },
    {
      "epoch": 48.241379310344826,
      "grad_norm": 0.016897033900022507,
      "learning_rate": 2.110344827586207e-06,
      "loss": 0.0014,
      "step": 2798
    },
    {
      "epoch": 48.258620689655174,
      "grad_norm": 0.013409378007054329,
      "learning_rate": 2.089655172413793e-06,
      "loss": 0.0013,
      "step": 2799
    },
    {
      "epoch": 48.275862068965516,
      "grad_norm": 0.019402185454964638,
      "learning_rate": 2.068965517241379e-06,
      "loss": 0.0011,
      "step": 2800
    },
    {
      "epoch": 48.275862068965516,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010580819798633456,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 14.9625,
      "eval_samples_per_second": 1.938,
      "eval_steps_per_second": 1.003,
      "step": 2800
    },
    {
      "epoch": 48.293103448275865,
      "grad_norm": 0.0358857735991478,
      "learning_rate": 2.0482758620689657e-06,
      "loss": 0.0024,
      "step": 2801
    },
    {
      "epoch": 48.310344827586206,
      "grad_norm": 0.036294762045145035,
      "learning_rate": 2.0275862068965518e-06,
      "loss": 0.001,
      "step": 2802
    },
    {
      "epoch": 48.327586206896555,
      "grad_norm": 0.01653273217380047,
      "learning_rate": 2.006896551724138e-06,
      "loss": 0.0008,
      "step": 2803
    },
    {
      "epoch": 48.3448275862069,
      "grad_norm": 0.03170902654528618,
      "learning_rate": 1.9862068965517244e-06,
      "loss": 0.0014,
      "step": 2804
    },
    {
      "epoch": 48.36206896551724,
      "grad_norm": 0.045188743621110916,
      "learning_rate": 1.9655172413793105e-06,
      "loss": 0.0011,
      "step": 2805
    },
    {
      "epoch": 48.37931034482759,
      "grad_norm": 0.009699976071715355,
      "learning_rate": 1.9448275862068966e-06,
      "loss": 0.0007,
      "step": 2806
    },
    {
      "epoch": 48.39655172413793,
      "grad_norm": 0.01441657543182373,
      "learning_rate": 1.9241379310344827e-06,
      "loss": 0.0013,
      "step": 2807
    },
    {
      "epoch": 48.41379310344828,
      "grad_norm": 0.01742757298052311,
      "learning_rate": 1.9034482758620692e-06,
      "loss": 0.0009,
      "step": 2808
    },
    {
      "epoch": 48.43103448275862,
      "grad_norm": 0.011022565886378288,
      "learning_rate": 1.882758620689655e-06,
      "loss": 0.001,
      "step": 2809
    },
    {
      "epoch": 48.44827586206897,
      "grad_norm": 0.01200212724506855,
      "learning_rate": 1.8620689655172414e-06,
      "loss": 0.0009,
      "step": 2810
    },
    {
      "epoch": 48.46551724137931,
      "grad_norm": 0.01959569938480854,
      "learning_rate": 1.8413793103448277e-06,
      "loss": 0.0012,
      "step": 2811
    },
    {
      "epoch": 48.48275862068966,
      "grad_norm": 0.011254341341555119,
      "learning_rate": 1.8206896551724138e-06,
      "loss": 0.001,
      "step": 2812
    },
    {
      "epoch": 48.5,
      "grad_norm": 0.0266579557210207,
      "learning_rate": 1.8e-06,
      "loss": 0.0011,
      "step": 2813
    },
    {
      "epoch": 48.51724137931034,
      "grad_norm": 0.013707473874092102,
      "learning_rate": 1.7793103448275862e-06,
      "loss": 0.0013,
      "step": 2814
    },
    {
      "epoch": 48.53448275862069,
      "grad_norm": 0.0126877436414361,
      "learning_rate": 1.7586206896551725e-06,
      "loss": 0.0011,
      "step": 2815
    },
    {
      "epoch": 48.55172413793103,
      "grad_norm": 0.014868263155221939,
      "learning_rate": 1.7379310344827588e-06,
      "loss": 0.0008,
      "step": 2816
    },
    {
      "epoch": 48.56896551724138,
      "grad_norm": 0.006053675431758165,
      "learning_rate": 1.717241379310345e-06,
      "loss": 0.0005,
      "step": 2817
    },
    {
      "epoch": 48.58620689655172,
      "grad_norm": 0.04942820593714714,
      "learning_rate": 1.696551724137931e-06,
      "loss": 0.0017,
      "step": 2818
    },
    {
      "epoch": 48.60344827586207,
      "grad_norm": 0.017482521012425423,
      "learning_rate": 1.6758620689655174e-06,
      "loss": 0.0014,
      "step": 2819
    },
    {
      "epoch": 48.62068965517241,
      "grad_norm": 0.019847145304083824,
      "learning_rate": 1.6551724137931035e-06,
      "loss": 0.0012,
      "step": 2820
    },
    {
      "epoch": 48.62068965517241,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010714340023696423,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.7465,
      "eval_samples_per_second": 2.699,
      "eval_steps_per_second": 1.396,
      "step": 2820
    },
    {
      "epoch": 48.63793103448276,
      "grad_norm": 0.029773201793432236,
      "learning_rate": 1.6344827586206898e-06,
      "loss": 0.0013,
      "step": 2821
    },
    {
      "epoch": 48.6551724137931,
      "grad_norm": 0.023122651502490044,
      "learning_rate": 1.6137931034482759e-06,
      "loss": 0.0011,
      "step": 2822
    },
    {
      "epoch": 48.672413793103445,
      "grad_norm": 0.04482334107160568,
      "learning_rate": 1.593103448275862e-06,
      "loss": 0.0013,
      "step": 2823
    },
    {
      "epoch": 48.689655172413794,
      "grad_norm": 0.010014762170612812,
      "learning_rate": 1.5724137931034485e-06,
      "loss": 0.0008,
      "step": 2824
    },
    {
      "epoch": 48.706896551724135,
      "grad_norm": 0.013204554095864296,
      "learning_rate": 1.5517241379310346e-06,
      "loss": 0.0012,
      "step": 2825
    },
    {
      "epoch": 48.724137931034484,
      "grad_norm": 0.012464690953493118,
      "learning_rate": 1.5310344827586209e-06,
      "loss": 0.0008,
      "step": 2826
    },
    {
      "epoch": 48.741379310344826,
      "grad_norm": 0.012583538889884949,
      "learning_rate": 1.510344827586207e-06,
      "loss": 0.0008,
      "step": 2827
    },
    {
      "epoch": 48.758620689655174,
      "grad_norm": 0.014070329256355762,
      "learning_rate": 1.489655172413793e-06,
      "loss": 0.0011,
      "step": 2828
    },
    {
      "epoch": 48.775862068965516,
      "grad_norm": 0.029801154509186745,
      "learning_rate": 1.4689655172413794e-06,
      "loss": 0.0012,
      "step": 2829
    },
    {
      "epoch": 48.793103448275865,
      "grad_norm": 0.012130724266171455,
      "learning_rate": 1.4482758620689655e-06,
      "loss": 0.001,
      "step": 2830
    },
    {
      "epoch": 48.810344827586206,
      "grad_norm": 0.01691380701959133,
      "learning_rate": 1.4275862068965516e-06,
      "loss": 0.0008,
      "step": 2831
    },
    {
      "epoch": 48.827586206896555,
      "grad_norm": 0.009545396082103252,
      "learning_rate": 1.406896551724138e-06,
      "loss": 0.0009,
      "step": 2832
    },
    {
      "epoch": 48.8448275862069,
      "grad_norm": 0.019189458340406418,
      "learning_rate": 1.3862068965517242e-06,
      "loss": 0.0013,
      "step": 2833
    },
    {
      "epoch": 48.86206896551724,
      "grad_norm": 0.026579443365335464,
      "learning_rate": 1.3655172413793105e-06,
      "loss": 0.0012,
      "step": 2834
    },
    {
      "epoch": 48.87931034482759,
      "grad_norm": 0.014147420413792133,
      "learning_rate": 1.3448275862068966e-06,
      "loss": 0.0012,
      "step": 2835
    },
    {
      "epoch": 48.89655172413793,
      "grad_norm": 0.019345169886946678,
      "learning_rate": 1.3241379310344827e-06,
      "loss": 0.0009,
      "step": 2836
    },
    {
      "epoch": 48.91379310344828,
      "grad_norm": 0.024599144235253334,
      "learning_rate": 1.303448275862069e-06,
      "loss": 0.0011,
      "step": 2837
    },
    {
      "epoch": 48.93103448275862,
      "grad_norm": 0.013750769197940826,
      "learning_rate": 1.2827586206896551e-06,
      "loss": 0.0011,
      "step": 2838
    },
    {
      "epoch": 48.94827586206897,
      "grad_norm": 0.019546328112483025,
      "learning_rate": 1.2620689655172414e-06,
      "loss": 0.0008,
      "step": 2839
    },
    {
      "epoch": 48.96551724137931,
      "grad_norm": 0.015313531272113323,
      "learning_rate": 1.2413793103448275e-06,
      "loss": 0.0013,
      "step": 2840
    },
    {
      "epoch": 48.96551724137931,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010499213822185993,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 10.0607,
      "eval_samples_per_second": 2.882,
      "eval_steps_per_second": 1.491,
      "step": 2840
    },
    {
      "epoch": 48.98275862068966,
      "grad_norm": 0.012083083391189575,
      "learning_rate": 1.2206896551724136e-06,
      "loss": 0.0011,
      "step": 2841
    },
    {
      "epoch": 49.0,
      "grad_norm": 0.012587308883666992,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.0009,
      "step": 2842
    },
    {
      "epoch": 49.01724137931034,
      "grad_norm": 0.03112100064754486,
      "learning_rate": 1.1793103448275863e-06,
      "loss": 0.0016,
      "step": 2843
    },
    {
      "epoch": 49.03448275862069,
      "grad_norm": 0.014655525796115398,
      "learning_rate": 1.1586206896551726e-06,
      "loss": 0.0013,
      "step": 2844
    },
    {
      "epoch": 49.05172413793103,
      "grad_norm": 0.01834186725318432,
      "learning_rate": 1.1379310344827587e-06,
      "loss": 0.0013,
      "step": 2845
    },
    {
      "epoch": 49.06896551724138,
      "grad_norm": 0.010923661291599274,
      "learning_rate": 1.1172413793103448e-06,
      "loss": 0.001,
      "step": 2846
    },
    {
      "epoch": 49.08620689655172,
      "grad_norm": 0.0125760268419981,
      "learning_rate": 1.096551724137931e-06,
      "loss": 0.0007,
      "step": 2847
    },
    {
      "epoch": 49.10344827586207,
      "grad_norm": 0.0225018709897995,
      "learning_rate": 1.0758620689655172e-06,
      "loss": 0.0017,
      "step": 2848
    },
    {
      "epoch": 49.12068965517241,
      "grad_norm": 0.015934638679027557,
      "learning_rate": 1.0551724137931035e-06,
      "loss": 0.0011,
      "step": 2849
    },
    {
      "epoch": 49.13793103448276,
      "grad_norm": 0.011200190521776676,
      "learning_rate": 1.0344827586206896e-06,
      "loss": 0.001,
      "step": 2850
    },
    {
      "epoch": 49.1551724137931,
      "grad_norm": 0.015327305532991886,
      "learning_rate": 1.0137931034482759e-06,
      "loss": 0.0014,
      "step": 2851
    },
    {
      "epoch": 49.172413793103445,
      "grad_norm": 0.01216582115739584,
      "learning_rate": 9.931034482758622e-07,
      "loss": 0.001,
      "step": 2852
    },
    {
      "epoch": 49.189655172413794,
      "grad_norm": 0.01492365077137947,
      "learning_rate": 9.724137931034483e-07,
      "loss": 0.0009,
      "step": 2853
    },
    {
      "epoch": 49.206896551724135,
      "grad_norm": 0.008147328160703182,
      "learning_rate": 9.517241379310346e-07,
      "loss": 0.0006,
      "step": 2854
    },
    {
      "epoch": 49.224137931034484,
      "grad_norm": 0.017090557143092155,
      "learning_rate": 9.310344827586207e-07,
      "loss": 0.0008,
      "step": 2855
    },
    {
      "epoch": 49.241379310344826,
      "grad_norm": 0.021607760339975357,
      "learning_rate": 9.103448275862069e-07,
      "loss": 0.0014,
      "step": 2856
    },
    {
      "epoch": 49.258620689655174,
      "grad_norm": 0.009102818556129932,
      "learning_rate": 8.896551724137931e-07,
      "loss": 0.0008,
      "step": 2857
    },
    {
      "epoch": 49.275862068965516,
      "grad_norm": 0.02151058241724968,
      "learning_rate": 8.689655172413794e-07,
      "loss": 0.001,
      "step": 2858
    },
    {
      "epoch": 49.293103448275865,
      "grad_norm": 0.012773661874234676,
      "learning_rate": 8.482758620689655e-07,
      "loss": 0.0012,
      "step": 2859
    },
    {
      "epoch": 49.310344827586206,
      "grad_norm": 0.01998947747051716,
      "learning_rate": 8.275862068965517e-07,
      "loss": 0.0014,
      "step": 2860
    },
    {
      "epoch": 49.310344827586206,
      "eval_accuracy_background": NaN,
      "eval_accuracy_document": NaN,
      "eval_accuracy_unknown": NaN,
      "eval_iou_background": 0.0,
      "eval_iou_document": 0.0,
      "eval_iou_unknown": 0.0,
      "eval_loss": 0.0010384604102000594,
      "eval_mean_accuracy": NaN,
      "eval_mean_iou": 0.0,
      "eval_overall_accuracy": NaN,
      "eval_runtime": 13.6215,
      "eval_samples_per_second": 2.129,
      "eval_steps_per_second": 1.101,
      "step": 2860
    }
  ],
  "logging_steps": 1,
  "max_steps": 2900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 50,
  "save_steps": 20,
  "total_flos": 1.002668421021696e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
